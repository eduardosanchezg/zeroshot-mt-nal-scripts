{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## test general zero-shot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "env: CODE_STORAGE=/storage/code\n"
     ]
    }
   ],
   "source": [
    "%env CODE_STORAGE = /storage/code "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "env: MODEL_PARAM=\"--user-dir /storage/code/fairseq-dynamic-routing-plugin/examples/dynamic_routing/dynamic_routing_src/\" #capsnet\n"
     ]
    }
   ],
   "source": [
    "#%env MODEL_PARAM = \"--seed 1\" # std transformer\n",
    "#%env MODEL_PARAM = \"--user-dir $CODE_STORAGE/fairseq/examples/residual_drop/residual_drop_src/\" #resdrop\n",
    "%env MODEL_PARAM = \"--user-dir /storage/code/fairseq-dynamic-routing-plugin/examples/dynamic_routing/dynamic_routing_src/\" #capsnet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install tokenizers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pip uninstall torch torchvision torchaudio -y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pip uninstall fairseq -y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install torch torchvision torchaudio --extra-index-url https://download.pytorch.org/whl/cu113"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install fairseq # --no-deps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! pip uninstall apex -y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rm -r apex"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! pip install -v --disable-pip-version-check --no-cache-dir apex"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install tensorboardX"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "env: MODEL_NAME=capsnet__nah-es_es-en\n",
      "env: LANG_PAIRS=nah-es,es-en\n",
      "env: TOKENIZER_LANGS=nah-es-en\n",
      "env: SRC_LANG=nah\n",
      "env: PIV_LANG=es\n",
      "env: TGT_LANG=en\n"
     ]
    }
   ],
   "source": [
    "%env MODEL_NAME = capsnet__nah-es_es-en\n",
    "%env LANG_PAIRS = nah-es,es-en\n",
    "%env TOKENIZER_LANGS = nah-es-en\n",
    "%env SRC_LANG = nah\n",
    "%env PIV_LANG = es\n",
    "%env TGT_LANG = en"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = \"capsnet__nah-es_es-en\"\n",
    "tokenizer_langs = \"nah-es-en\"\n",
    "src_lang = \"nah\"\n",
    "piv_lang = \"es\"\n",
    "tgt_lang = \"en\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "env: MODELS_DIR=/storage/master-thesis/models\n"
     ]
    }
   ],
   "source": [
    "%env MODELS_DIR = /storage/master-thesis/models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "models_dir = \"/storage/master-thesis/models/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "en_it_corpus_dir = \"/notebooks/master-thesis/corpora/iwslt17/en-it/\"\n",
    "en_nl_corpus_dir = \"/notebooks/master-thesis/corpora/iwslt17/en-nl/\"\n",
    "en_ro_corpus_dir = \"/notebooks/master-thesis/corpora/iwslt17/en-ro/\"\n",
    "it_nl_corpus_dir = \"/notebooks/master-thesis/corpora/iwslt17/it-nl/\"\n",
    "it_ro_corpus_dir = \"/notebooks/master-thesis/corpora/iwslt17/it-ro/\"\n",
    "nl_ro_corpus_dir = \"/notebooks/master-thesis/corpora/iwslt17/nl-ro/\"\n",
    "\n",
    "en_es_corpus_dir = \"/notebooks/master-thesis/corpora/tatoeba-challenge/en-es/\" #not needed\n",
    "\n",
    "aym_es_corpus_dir = \"/notebooks/master-thesis/corpora/americasnlp2021/data/aymara-spanish/\"\n",
    "cni_es_corpus_dir = \"/notebooks/master-thesis/corpora/americasnlp2021/data/ashaninka-spanish/\"\n",
    "bzd_es_corpus_dir = \"/notebooks/master-thesis/corpora/americasnlp2021/data/bribri-spanish/\"\n",
    "gn_es_corpus_dir = \"/notebooks/master-thesis/corpora/americasnlp2021/data/guarani-spanish/\"\n",
    "oto_es_corpus_dir = \"/notebooks/master-thesis/corpora/americasnlp2021/data/hnahnu-spanish/\"\n",
    "nah_es_corpus_dir = \"/notebooks/master-thesis/corpora/americasnlp2021/data/nahuatl-spanish/\"\n",
    "quy_es_corpus_dir = \"/notebooks/master-thesis/corpora/americasnlp2021/data/quechua-spanish/\"\n",
    "tar_es_corpus_dir = \"/notebooks/master-thesis/corpora/americasnlp2021/data/raramuri-spanish/\"\n",
    "shp_es_corpus_dir = \"/notebooks/master-thesis/corpora/americasnlp2021/data/shipibo_konibo-spanish/\"\n",
    "hch_es_corpus_dir = \"/notebooks/master-thesis/corpora/americasnlp2021/data/wixarika-spanish/\"\n",
    "\n",
    "quy_en_corpus_dir = \"/notebooks/master-thesis/corpora/jw300/en-quy/\"\n",
    "aym_en_corpus_dir = \"/notebooks/master-thesis/corpora/jw300/aym-en/\"\n",
    "nah_en_corpus_dir = \"/notebooks/master-thesis/corpora/tatoeba-challenge/en-nah/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "env: EN_IT_CORPUS_DIR=/notebooks/master-thesis/corpora/iwslt17/en-it\n",
      "env: EN_NL_CORPUS_DIR=/notebooks/master-thesis/corpora/iwslt17/en-nl\n",
      "env: EN_RO_CORPUS_DIR=/notebooks/master-thesis/corpora/iwslt17/en-ro\n",
      "env: IT_NL_CORPUS_DIR=/notebooks/master-thesis/corpora/iwslt17/it-nl\n",
      "env: IT_RO_CORPUS_DIR=/notebooks/master-thesis/corpora/iwslt17/it-ro\n",
      "env: NL_RO_CORPUS_DIR=/notebooks/master-thesis/corpora/iwslt17/nl-ro\n",
      "env: EN_ES_CORPUS_DIR=/notebooks/master-thesis/corpora/tatoeba-challenge/en-es\n",
      "env: AYM_ES_CORPUS_DIR=/notebooks/master-thesis/corpora/americasnlp2021/data/aymara-spanish\n",
      "env: CNI_ES_CORPUS_DIR=/notebooks/master-thesis/corpora/americasnlp2021/data/ashaninka-spanish\n",
      "env: BZD_ES_CORPUS_DIR=/notebooks/master-thesis/corpora/americasnlp2021/data/bribri-spanish\n",
      "env: GN_ES_CORPUS_DIR=/notebooks/master-thesis/corpora/americasnlp2021/data/guarani-spanish\n",
      "env: OTO_ES_CORPUS_DIR=/notebooks/master-thesis/corpora/americasnlp2021/data/hnahnu-spanish\n",
      "env: NAH_ES_CORPUS_DIR=/notebooks/master-thesis/corpora/americasnlp2021/data/nahuatl-spanish\n",
      "env: QUY_ES_CORPUS_DIR=/notebooks/master-thesis/corpora/americasnlp2021/data/quechua-spanish\n",
      "env: TAR_ES_CORPUS_DIR=/notebooks/master-thesis/corpora/americasnlp2021/data/raramuri-spanish\n",
      "env: SHP_ES_CORPUS_DIR=/notebooks/master-thesis/corpora/americasnlp2021/data/shipibo_konibo-spanish\n",
      "env: HCH_ES_CORPUS_DIR=/notebooks/master-thesis/corpora/americasnlp2021/data/wixarika-spanish\n",
      "env: QUY_EN_CORPUS_DIR=/notebooks/master-thesis/corpora/jw300/en-quy\n",
      "env: AYM_EN_CORPUS_DIR=/notebooks/master-thesis/corpora/jw300/aym-en\n",
      "env: NAH_EN_CORPUS_DIR=/notebooks/master-thesis/corpora/tatoeba-challenge/en-nah\n"
     ]
    }
   ],
   "source": [
    "%env EN_IT_CORPUS_DIR = /notebooks/master-thesis/corpora/iwslt17/en-it\n",
    "%env EN_NL_CORPUS_DIR = /notebooks/master-thesis/corpora/iwslt17/en-nl\n",
    "%env EN_RO_CORPUS_DIR = /notebooks/master-thesis/corpora/iwslt17/en-ro\n",
    "%env IT_NL_CORPUS_DIR = /notebooks/master-thesis/corpora/iwslt17/it-nl\n",
    "%env IT_RO_CORPUS_DIR = /notebooks/master-thesis/corpora/iwslt17/it-ro\n",
    "%env NL_RO_CORPUS_DIR = /notebooks/master-thesis/corpora/iwslt17/nl-ro\n",
    "\n",
    "%env EN_ES_CORPUS_DIR = /notebooks/master-thesis/corpora/tatoeba-challenge/en-es\n",
    "\n",
    "%env AYM_ES_CORPUS_DIR = /notebooks/master-thesis/corpora/americasnlp2021/data/aymara-spanish\n",
    "%env CNI_ES_CORPUS_DIR = /notebooks/master-thesis/corpora/americasnlp2021/data/ashaninka-spanish\n",
    "%env BZD_ES_CORPUS_DIR = /notebooks/master-thesis/corpora/americasnlp2021/data/bribri-spanish\n",
    "%env GN_ES_CORPUS_DIR = /notebooks/master-thesis/corpora/americasnlp2021/data/guarani-spanish\n",
    "%env OTO_ES_CORPUS_DIR = /notebooks/master-thesis/corpora/americasnlp2021/data/hnahnu-spanish\n",
    "%env NAH_ES_CORPUS_DIR = /notebooks/master-thesis/corpora/americasnlp2021/data/nahuatl-spanish\n",
    "%env QUY_ES_CORPUS_DIR = /notebooks/master-thesis/corpora/americasnlp2021/data/quechua-spanish\n",
    "%env TAR_ES_CORPUS_DIR = /notebooks/master-thesis/corpora/americasnlp2021/data/raramuri-spanish\n",
    "%env SHP_ES_CORPUS_DIR = /notebooks/master-thesis/corpora/americasnlp2021/data/shipibo_konibo-spanish\n",
    "%env HCH_ES_CORPUS_DIR = /notebooks/master-thesis/corpora/americasnlp2021/data/wixarika-spanish\n",
    "\n",
    "%env QUY_EN_CORPUS_DIR = /notebooks/master-thesis/corpora/jw300/en-quy\n",
    "\n",
    "%env AYM_EN_CORPUS_DIR = /notebooks/master-thesis/corpora/jw300/aym-en\n",
    "%env NAH_EN_CORPUS_DIR = /notebooks/master-thesis/corpora/tatoeba-challenge/en-nah"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "env: SRC_PIV_TEST_CORPUS=$NAH_ES_CORPUS_DIR\n",
      "env: SRC_TGT_TEST_CORPUS=$NAH_EN_CORPUS_DIR\n"
     ]
    }
   ],
   "source": [
    "%env SRC_PIV_TEST_CORPUS = $NAH_ES_CORPUS_DIR\n",
    "#%env PIV_TGT_TEST_CORPUS = $EN_ES_CORPUS_DIR\n",
    "%env SRC_TGT_TEST_CORPUS = $NAH_EN_CORPUS_DIR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "src_piv_test_corpus = nah_es_corpus_dir\n",
    "#piv_tgt_test_corpus = en_es_corpus_dir\n",
    "src_tgt_test_corpus = nah_en_corpus_dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer_path = models_dir + model_name + \"/tokenizers/\" + tokenizer_langs + \"/\"\n",
    "tokenizer_name = tokenizer_langs + \"-tokenizer.json\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/storage/master-thesis/models/capsnet__nah-es_es-en/tokenizers/nah-es-en/nah-es-en-tokenizer.json\n"
     ]
    }
   ],
   "source": [
    "print(tokenizer_path + tokenizer_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "env: TOKENIZER_PATH=${MODELS_DIR}/${MODEL_NAME}/tokenizers/${TOKENIZER_LANGS}\n"
     ]
    }
   ],
   "source": [
    "%env TOKENIZER_PATH = ${MODELS_DIR}/${MODEL_NAME}/tokenizers/${TOKENIZER_LANGS}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "env: MODEL_DIR=${MODELS_DIR}/${MODEL_NAME}\n"
     ]
    }
   ],
   "source": [
    "%env MODEL_DIR = ${MODELS_DIR}/${MODEL_NAME}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_dir = models_dir+model_name+\"/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/storage/master-thesis/models/capsnet__nah-es_es-en/tokenizers/nah-es-en/nah-es-en-tokenizer.json\n"
     ]
    }
   ],
   "source": [
    "print(tokenizer_path + tokenizer_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tokenizers import Tokenizer\n",
    "from tokenizers.models import WordPiece\n",
    "\n",
    "tokenizer = Tokenizer.from_file(tokenizer_path + tokenizer_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "def tokenize_files(tokenizer, files, extension, output_path):\n",
    "    for file in files:\n",
    "        print(f\"Reading file {file}\")\n",
    "        with open(file, encoding='utf8') as f:\n",
    "          lines = f.readlines()\n",
    "          tokenized_lines = tokenizer.encode_batch(lines)\n",
    "          tokenized_name = Path(file).stem\n",
    "          tokenized_name = output_path + tokenized_name + \".\" + extension\n",
    "          print(tokenized_name)\n",
    "          with open(tokenized_name, 'w', encoding='utf8') as wf:\n",
    "\n",
    "            wf.writelines([\" \".join(t.tokens) + \"\\n\" for t in tokenized_lines])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Una', '-', 'una', '##y', 'wat', '##a', '##ña', 'chu', '##ras', '##q', '##a', 'kas', '##pant', '##in', 'sar', '##ata', 'tar', '##is', '##q', '##ank', '##um', '(', 'han', '##ay', '##pi', 'ri', '##ku', '##ris', '##q', '##an', '##man', 'hin', '##a', ')', 'q', '##aw', '##achin', ',', 'ka', '##y', 'nac', '##ion', '##pa', 'norte', 'lawn', '##in', '##pi', 'run', '##ak', '##una', '##q', '##a', '3', '.', '000', 'wat', '##a', 'ñ', '##aw', '##pa', '##q', '##ta', '##ra', '##q', 'sar', '##aman', '##ta', 'harina', '##ta', 'hin', '##as', '##pa', 'ham', '##kat', '##a', 'mi', '##ku', '##s', '##q', '##ank', '##uta', '.']\n"
     ]
    }
   ],
   "source": [
    "tok = tokenizer.encode(\"Una - unay wataña churasqa kaspantin sarata tarisqankum (hanaypi rikurisqanman hina) qawachin, kay nacionpa norte lawninpi runakunaqa 3.000 wata ñawpaqtaraq saramanta harinata hinaspa hamkata mikusqankuta.\"\n",
    ")\n",
    "print(tok.tokens)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testing src->piv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading file /notebooks/master-thesis/corpora/americasnlp2021/data/nahuatl-spanish/test.nah\n",
      "/storage/master-thesis/models/capsnet__nah-es_es-en/tokenizers/nah-es-en/test.nah\n"
     ]
    }
   ],
   "source": [
    "tokenize_files(tokenizer, [src_piv_test_corpus + 'test.' + src_lang], src_lang, tokenizer_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-10-31 15:51:19 | INFO | fairseq_cli.preprocess | Namespace(aim_repo=None, aim_run_hash=None, align_suffix=None, alignfile=None, all_gather_list_size=16384, amp=False, amp_batch_retries=2, amp_init_scale=128, amp_scale_window=None, azureml_logging=False, bf16=False, bpe=None, cpu=False, criterion='cross_entropy', dataset_impl='mmap', destdir='/storage/master-thesis/models/capsnet__nah-es_es-en/tokenizers/nah-es-en/bin/', dict_only=False, empty_cache_freq=0, fp16=False, fp16_init_scale=128, fp16_no_flatten_grads=False, fp16_scale_tolerance=0.0, fp16_scale_window=None, joined_dictionary=True, log_file=None, log_format=None, log_interval=100, lr_scheduler='fixed', memory_efficient_bf16=False, memory_efficient_fp16=False, min_loss_scale=0.0001, model_parallel_size=1, no_progress_bar=False, nwordssrc=-1, nwordstgt=-1, on_cpu_convert_precision=False, only_source=True, optimizer=None, padding_factor=8, plasma_path='/tmp/plasma', profile=False, quantization_config_path=None, reset_logging=False, scoring='bleu', seed=1, source_lang='nah', srcdict='/storage/master-thesis/models/capsnet__nah-es_es-en/tokenizers/nah-es-en/bin/dict.all.txt', suppress_crashes=False, target_lang='es', task='translation_multi_simple_epoch', tensorboard_logdir=None, testpref='/storage/master-thesis/models/capsnet__nah-es_es-en/tokenizers/nah-es-en/test', tgtdict=None, threshold_loss_scale=None, thresholdsrc=0, thresholdtgt=0, tokenizer=None, tpu=False, trainpref=None, use_plasma_view=False, user_dir=None, validpref=None, wandb_project=None, workers=20)\n",
      "2022-10-31 15:51:20 | INFO | fairseq_cli.preprocess | [nah] Dictionary: 28912 types\n",
      "2022-10-31 15:51:20 | INFO | fairseq_cli.preprocess | [nah] /storage/master-thesis/models/capsnet__nah-es_es-en/tokenizers/nah-es-en/test.nah: 1003 sents, 15201 tokens, 0.224% replaced (by <unk>)\n",
      "2022-10-31 15:51:20 | INFO | fairseq_cli.preprocess | Wrote preprocessed data to /storage/master-thesis/models/capsnet__nah-es_es-en/tokenizers/nah-es-en/bin/\n"
     ]
    }
   ],
   "source": [
    "! fairseq-preprocess --source-lang $SRC_LANG --target-lang $PIV_LANG \\\n",
    "    --testpref $(eval echo $TOKENIZER_PATH)/test \\\n",
    "    --destdir $(eval echo $TOKENIZER_PATH)/bin/ \\\n",
    "    --workers 20 \\\n",
    "    --srcdict $(eval echo $TOKENIZER_PATH)/bin/dict.all.txt \\\n",
    "    --task translation_multi_simple_epoch \\\n",
    "    --joined-dictionary \\\n",
    "    --only-source"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-10-31 15:51:24 | INFO | fairseq_cli.generate | {'_name': None, 'common': {'_name': None, 'no_progress_bar': False, 'log_interval': 100, 'log_format': None, 'log_file': None, 'aim_repo': None, 'aim_run_hash': None, 'tensorboard_logdir': None, 'wandb_project': None, 'azureml_logging': False, 'seed': 1, 'cpu': False, 'tpu': False, 'bf16': False, 'memory_efficient_bf16': False, 'fp16': False, 'memory_efficient_fp16': False, 'fp16_no_flatten_grads': False, 'fp16_init_scale': 128, 'fp16_scale_window': None, 'fp16_scale_tolerance': 0.0, 'on_cpu_convert_precision': False, 'min_loss_scale': 0.0001, 'threshold_loss_scale': None, 'amp': False, 'amp_batch_retries': 2, 'amp_init_scale': 128, 'amp_scale_window': None, 'user_dir': '/storage/code/fairseq-dynamic-routing-plugin/examples/dynamic_routing/dynamic_routing_src/', 'empty_cache_freq': 0, 'all_gather_list_size': 16384, 'model_parallel_size': 1, 'quantization_config_path': None, 'profile': False, 'reset_logging': False, 'suppress_crashes': False, 'use_plasma_view': False, 'plasma_path': '/tmp/plasma'}, 'common_eval': {'_name': None, 'path': '/storage/master-thesis/models/capsnet__nah-es_es-en/checkpoint_best.pt', 'post_process': None, 'quiet': False, 'model_overrides': '{}', 'results_path': None}, 'distributed_training': {'_name': None, 'distributed_world_size': 1, 'distributed_num_procs': 1, 'distributed_rank': 0, 'distributed_backend': 'nccl', 'distributed_init_method': None, 'distributed_port': -1, 'device_id': 0, 'distributed_no_spawn': False, 'ddp_backend': 'pytorch_ddp', 'ddp_comm_hook': 'none', 'bucket_cap_mb': 25, 'fix_batches_to_gpus': False, 'find_unused_parameters': False, 'gradient_as_bucket_view': False, 'fast_stat_sync': False, 'heartbeat_timeout': -1, 'broadcast_buffers': False, 'slowmo_momentum': None, 'slowmo_base_algorithm': 'localsgd', 'localsgd_frequency': 3, 'nprocs_per_node': 1, 'pipeline_model_parallel': False, 'pipeline_balance': None, 'pipeline_devices': None, 'pipeline_chunks': 0, 'pipeline_encoder_balance': None, 'pipeline_encoder_devices': None, 'pipeline_decoder_balance': None, 'pipeline_decoder_devices': None, 'pipeline_checkpoint': 'never', 'zero_sharding': 'none', 'fp16': False, 'memory_efficient_fp16': False, 'tpu': False, 'no_reshard_after_forward': False, 'fp32_reduce_scatter': False, 'cpu_offload': False, 'use_sharded_state': False, 'not_fsdp_flatten_parameters': False}, 'dataset': {'_name': None, 'num_workers': 1, 'skip_invalid_size_inputs_valid_test': False, 'max_tokens': 6000, 'batch_size': None, 'required_batch_size_multiple': 8, 'required_seq_len_multiple': 1, 'dataset_impl': None, 'data_buffer_size': 10, 'train_subset': 'train', 'valid_subset': 'valid', 'combine_valid_subsets': None, 'ignore_unused_valid_subsets': False, 'validate_interval': 1, 'validate_interval_updates': 0, 'validate_after_updates': 0, 'fixed_validation_seed': None, 'disable_validation': False, 'max_tokens_valid': 6000, 'batch_size_valid': None, 'max_valid_steps': None, 'curriculum': 0, 'gen_subset': 'test', 'num_shards': 1, 'shard_id': 0, 'grouped_shuffling': False, 'update_epoch_batch_itr': False, 'update_ordered_indices_seed': False}, 'optimization': {'_name': None, 'max_epoch': 0, 'max_update': 0, 'stop_time_hours': 0.0, 'clip_norm': 0.0, 'sentence_avg': False, 'update_freq': [1], 'lr': [0.25], 'stop_min_lr': -1.0, 'use_bmuf': False, 'skip_remainder_batch': False}, 'checkpoint': {'_name': None, 'save_dir': 'checkpoints', 'restore_file': 'checkpoint_last.pt', 'continue_once': None, 'finetune_from_model': None, 'reset_dataloader': False, 'reset_lr_scheduler': False, 'reset_meters': False, 'reset_optimizer': False, 'optimizer_overrides': '{}', 'save_interval': 1, 'save_interval_updates': 0, 'keep_interval_updates': -1, 'keep_interval_updates_pattern': -1, 'keep_last_epochs': -1, 'keep_best_checkpoints': -1, 'no_save': False, 'no_epoch_checkpoints': False, 'no_last_checkpoints': False, 'no_save_optimizer_state': False, 'best_checkpoint_metric': 'loss', 'maximize_best_checkpoint_metric': False, 'patience': -1, 'checkpoint_suffix': '', 'checkpoint_shard_count': 1, 'load_checkpoint_on_all_dp_ranks': False, 'write_checkpoints_asynchronously': False, 'model_parallel_size': 1}, 'bmuf': {'_name': None, 'block_lr': 1.0, 'block_momentum': 0.875, 'global_sync_iter': 50, 'warmup_iterations': 500, 'use_nbm': False, 'average_sync': False, 'distributed_world_size': 1}, 'generation': {'_name': None, 'beam': 5, 'nbest': 1, 'max_len_a': 0.0, 'max_len_b': 200, 'min_len': 1, 'match_source_len': False, 'unnormalized': False, 'no_early_stop': False, 'no_beamable_mm': False, 'lenpen': 1.0, 'unkpen': 0.0, 'replace_unk': None, 'sacrebleu': False, 'score_reference': False, 'prefix_size': 0, 'no_repeat_ngram_size': 0, 'sampling': False, 'sampling_topk': -1, 'sampling_topp': -1.0, 'constraints': None, 'temperature': 1.0, 'diverse_beam_groups': -1, 'diverse_beam_strength': 0.5, 'diversity_rate': -1.0, 'print_alignment': 'hard', 'print_step': False, 'lm_path': None, 'lm_weight': 0.0, 'iter_decode_eos_penalty': 0.0, 'iter_decode_max_iter': 10, 'iter_decode_force_max_iter': False, 'iter_decode_with_beam': 1, 'iter_decode_with_external_reranker': False, 'retain_iter_history': False, 'retain_dropout': False, 'retain_dropout_modules': None, 'decoding_format': None, 'no_seed_provided': False, 'eos_token': None}, 'eval_lm': {'_name': None, 'output_word_probs': False, 'output_word_stats': False, 'context_window': 0, 'softmax_batch': 9223372036854775807}, 'interactive': {'_name': None, 'buffer_size': 0, 'input': '-'}, 'model': {'_name': 'wav2vec2', 'extractor_mode': 'default', 'encoder_layers': 12, 'encoder_embed_dim': 768, 'encoder_ffn_embed_dim': 3072, 'encoder_attention_heads': 12, 'activation_fn': 'gelu', 'layer_type': 'transformer', 'dropout': 0.1, 'attention_dropout': 0.1, 'activation_dropout': 0.0, 'encoder_layerdrop': 0.0, 'dropout_input': 0.0, 'dropout_features': 0.0, 'final_dim': 0, 'layer_norm_first': False, 'conv_feature_layers': '[(512, 10, 5)] + [(512, 3, 2)] * 4 + [(512,2,2)] + [(512,2,2)]', 'conv_bias': False, 'logit_temp': 0.1, 'quantize_targets': False, 'quantize_input': False, 'same_quantizer': False, 'target_glu': False, 'feature_grad_mult': 1.0, 'quantizer_depth': 1, 'quantizer_factor': 3, 'latent_vars': 320, 'latent_groups': 2, 'latent_dim': 0, 'mask_length': 10, 'mask_prob': 0.65, 'mask_selection': 'static', 'mask_other': 0.0, 'no_mask_overlap': False, 'mask_min_space': 1, 'require_same_masks': True, 'mask_dropout': 0.0, 'mask_channel_length': 10, 'mask_channel_prob': 0.0, 'mask_channel_before': False, 'mask_channel_selection': 'static', 'mask_channel_other': 0.0, 'no_mask_channel_overlap': False, 'mask_channel_min_space': 1, 'num_negatives': 100, 'negatives_from_everywhere': False, 'cross_sample_negatives': 0, 'codebook_negatives': 0, 'conv_pos': 128, 'conv_pos_groups': 16, 'pos_conv_depth': 1, 'latent_temp': [2.0, 0.5, 0.999995], 'max_positions': 100000, 'checkpoint_activations': False, 'required_seq_len_multiple': 1, 'crop_seq_to_multiple': 1, 'depthwise_conv_kernel_size': 31, 'attn_type': '', 'pos_enc_type': 'abs', 'fp16': False}, 'task': Namespace(_name='translation_multi_simple_epoch', aim_repo=None, aim_run_hash=None, all_gather_list_size=16384, amp=False, amp_batch_retries=2, amp_init_scale=128, amp_scale_window=None, arch='wav2vec2', azureml_logging=False, batch_size=None, batch_size_valid=None, beam=5, best_checkpoint_metric='loss', bf16=False, bpe=None, broadcast_buffers=False, bucket_cap_mb=25, checkpoint_shard_count=1, checkpoint_suffix='', combine_valid_subsets=None, constraints=None, continue_once=None, cpu=False, cpu_offload=False, criterion='cross_entropy', curriculum=0, data='/storage/master-thesis/models/capsnet__nah-es_es-en/tokenizers/nah-es-en/bin', data_buffer_size=10, dataset_impl=None, ddp_backend='pytorch_ddp', ddp_comm_hook='none', decoder_langtok=True, decoding_format=None, device_id=0, disable_validation=False, distributed_backend='nccl', distributed_init_method=None, distributed_no_spawn=False, distributed_num_procs=1, distributed_port=-1, distributed_rank=0, distributed_world_size=1, diverse_beam_groups=-1, diverse_beam_strength=0.5, diversity_rate=-1.0, empty_cache_freq=0, enable_lang_ids=False, enable_reservsed_directions_shared_datasets=False, encoder_langtok='src', eos=2, eos_token=None, extra_data=None, extra_lang_pairs=None, fast_stat_sync=False, find_unused_parameters=False, finetune_from_model=None, fix_batches_to_gpus=False, fixed_dictionary=None, fixed_validation_seed=None, force_anneal=None, fp16=False, fp16_init_scale=128, fp16_no_flatten_grads=False, fp16_scale_tolerance=0.0, fp16_scale_window=None, fp32_reduce_scatter=False, gen_subset='test', gradient_as_bucket_view=False, grouped_shuffling=False, heartbeat_timeout=-1, ignore_unused_valid_subsets=False, iter_decode_eos_penalty=0.0, iter_decode_force_max_iter=False, iter_decode_max_iter=10, iter_decode_with_beam=1, iter_decode_with_external_reranker=False, keep_best_checkpoints=-1, keep_inference_langtok=False, keep_interval_updates=-1, keep_interval_updates_pattern=-1, keep_last_epochs=-1, lang_dict=None, lang_pairs='nah-es,es-en', lang_tok_replacing_bos_eos=False, lang_tok_style='multilingual', langs=None, langtoks=None, langtoks_specs=['main'], left_pad_source='True', left_pad_target='False', lenpen=1, lm_path=None, lm_weight=0.0, load_alignments=False, load_checkpoint_on_all_dp_ranks=False, localsgd_frequency=3, log_file=None, log_format=None, log_interval=100, lr_scheduler='fixed', lr_shrink=0.1, match_source_len=False, max_len_a=0, max_len_b=200, max_source_positions=1024, max_target_positions=1024, max_tokens=6000, max_tokens_valid=6000, max_valid_steps=None, maximize_best_checkpoint_metric=False, memory_efficient_bf16=False, memory_efficient_fp16=False, min_len=1, min_loss_scale=0.0001, model_overrides='{}', model_parallel_size=1, nbest=1, no_beamable_mm=False, no_early_stop=False, no_epoch_checkpoints=False, no_last_checkpoints=False, no_progress_bar=False, no_repeat_ngram_size=0, no_reshard_after_forward=False, no_save=False, no_save_optimizer_state=False, no_seed_provided=False, not_fsdp_flatten_parameters=False, nprocs_per_node=1, num_shards=1, num_workers=1, on_cpu_convert_precision=False, optimizer=None, optimizer_overrides='{}', pad=1, path='/storage/master-thesis/models/capsnet__nah-es_es-en/checkpoint_best.pt', patience=-1, pipeline_balance=None, pipeline_checkpoint='never', pipeline_chunks=0, pipeline_decoder_balance=None, pipeline_decoder_devices=None, pipeline_devices=None, pipeline_encoder_balance=None, pipeline_encoder_devices=None, pipeline_model_parallel=False, plasma_path='/tmp/plasma', post_process=None, prefix_size=0, print_alignment='hard', print_step=False, profile=False, quantization_config_path=None, quiet=False, replace_unk=None, required_batch_size_multiple=8, required_seq_len_multiple=1, reset_dataloader=False, reset_logging=False, reset_lr_scheduler=False, reset_meters=False, reset_optimizer=False, restore_file='checkpoint_last.pt', results_path=None, retain_dropout=False, retain_dropout_modules=None, retain_iter_history=False, sacrebleu=False, sampling=False, sampling_method='concat', sampling_temperature=1.5, sampling_topk=-1, sampling_topp=-1.0, sampling_weights=None, sampling_weights_from_file=None, save_dir='checkpoints', save_interval=1, save_interval_updates=0, score_reference=False, scoring='bleu', seed=1, shard_id=0, skip_invalid_size_inputs_valid_test=False, slowmo_base_algorithm='localsgd', slowmo_momentum=None, source_dict=None, source_lang='nah', suppress_crashes=False, target_dict=None, target_lang='es', task='translation_multi_simple_epoch', temperature=1.0, tensorboard_logdir=None, threshold_loss_scale=None, tokenizer=None, tpu=False, train_subset='train', truncate_source=False, unk=3, unkpen=0, unnormalized=False, update_epoch_batch_itr=False, update_ordered_indices_seed=False, upsample_primary=1, use_plasma_view=False, use_sharded_state=False, user_dir='/storage/code/fairseq-dynamic-routing-plugin/examples/dynamic_routing/dynamic_routing_src/', valid_subset='valid', validate_after_updates=0, validate_interval=1, validate_interval_updates=0, virtual_data_size=None, virtual_epoch_size=None, wandb_project=None, warmup_updates=0, write_checkpoints_asynchronously=False, zero_sharding='none'), 'criterion': {'_name': 'cross_entropy', 'sentence_avg': True}, 'optimizer': None, 'lr_scheduler': {'_name': 'fixed', 'force_anneal': None, 'lr_shrink': 0.1, 'warmup_updates': 0, 'lr': [0.25]}, 'scoring': {'_name': 'bleu', 'pad': 1, 'eos': 2, 'unk': 3}, 'bpe': None, 'tokenizer': None, 'ema': {'_name': None, 'store_ema': False, 'ema_decay': 0.9999, 'ema_start_update': 0, 'ema_seed_model': None, 'ema_update_freq': 1, 'ema_fp32': False}}\n",
      "2022-10-31 15:51:24 | WARNING | fairseq.data.multilingual.multilingual_data_manager | External language dictionary is not provided; use lang-pairs to infer the set of supported languages. The language ordering is not stable which might cause misalignment in pretraining and finetuning.\n",
      "2022-10-31 15:51:24 | INFO | fairseq.data.multilingual.multilingual_data_manager | inferred language list: ['en', 'es', 'nah']\n",
      "2022-10-31 15:51:24 | INFO | fairseq.data.multilingual.multilingual_data_manager | [nah] dictionary: 28915 types\n",
      "2022-10-31 15:51:24 | INFO | fairseq.data.multilingual.multilingual_data_manager | [es] dictionary: 28915 types\n",
      "2022-10-31 15:51:24 | INFO | fairseq_cli.generate | loading model(s) from /storage/master-thesis/models/capsnet__nah-es_es-en/checkpoint_best.pt\n",
      "2022-10-31 15:51:25 | INFO | fairseq.tasks.translation_multi_simple_epoch | loading data for test epoch=1/None\n",
      "2022-10-31 15:51:25 | INFO | fairseq.tasks.translation_multi_simple_epoch | mem usage: N/A\n",
      "2022-10-31 15:51:25 | INFO | fairseq.data.multilingual.multilingual_data_manager | langtoks settings: {'main': ('src', 'tgt')}\n",
      "2022-10-31 15:51:25 | INFO | fairseq.data.multilingual.multilingual_data_manager | [test] num of shards: {'main:nah-es': 1}\n",
      "2022-10-31 15:51:25 | INFO | fairseq.data.multilingual.multilingual_data_manager | main:nah-es src_langtok: 28914; tgt_langtok: 28913\n",
      "2022-10-31 15:51:25 | INFO | fairseq.data.data_utils | loaded 1,003 examples from: /storage/master-thesis/models/capsnet__nah-es_es-en/tokenizers/nah-es-en/bin/test.nah-es.nah\n",
      "2022-10-31 15:51:25 | INFO | fairseq.data.multilingual.multilingual_data_manager | /storage/master-thesis/models/capsnet__nah-es_es-en/tokenizers/nah-es-en/bin test nah-es 1003 examples\n",
      "2022-10-31 15:51:30 | INFO | fairseq.tasks.translation_multi_simple_epoch | start batch sampler: mem usage: N/A\n",
      "2022-10-31 15:51:30 | INFO | fairseq.tasks.translation_multi_simple_epoch | [test] @batch_sampler order indices time: 0:00:00.000581\n",
      "2022-10-31 15:51:30 | INFO | fairseq.tasks.translation_multi_simple_epoch | mem usage: N/A\n",
      "2022-10-31 15:51:30 | INFO | fairseq.tasks.translation_multi_simple_epoch | [test] @batch_sampler filter_by_size time: 0:00:00.005887\n",
      "2022-10-31 15:51:30 | INFO | fairseq.tasks.translation_multi_simple_epoch | mem usage: N/A\n",
      "2022-10-31 15:51:30 | INFO | fairseq.tasks.translation_multi_simple_epoch | [test] @batch_sampler batch_by_size time: 0:00:00.006001\n",
      "2022-10-31 15:51:30 | INFO | fairseq.tasks.translation_multi_simple_epoch | [test] per epoch batch_sampler set-up time: 0:00:00.013021\n",
      "2022-10-31 15:51:30 | INFO | fairseq.tasks.translation_multi_simple_epoch | mem usage: N/A\n",
      "2022-10-31 15:51:39 | INFO | fairseq_cli.generate | NOTE: hypothesis and token scores are output in base 2����| 5/5 [00:08<00:00,  1.58s/it, wps=1480]\n",
      "2022-10-31 15:51:39 | INFO | fairseq_cli.generate | Translated 1,003 sentences (12,965 tokens) in 6.5s (154.20 sentences/s, 1993.20 tokens/s)\n"
     ]
    }
   ],
   "source": [
    "! PYTHONIOENCODING=utf-8 fairseq-generate $(eval echo $TOKENIZER_PATH)/bin \\\n",
    "    $(eval echo $MODEL_PARAM) \\\n",
    "    --path $(eval echo $MODEL_DIR)/checkpoint_best.pt  \\\n",
    "    --source-lang $SRC_LANG --target-lang $PIV_LANG \\\n",
    "    --max-tokens 6000 \\\n",
    "    --task translation_multi_simple_epoch \\\n",
    "    --encoder-langtok \"src\" \\\n",
    "    --decoder-langtok \\\n",
    "    --lang-pairs $LANG_PAIRS \\\n",
    "    --print-alignment > $(eval echo $MODEL_DIR)/${SRC_LANG}_${PIV_LANG}.${PIV_LANG}.out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "!cat $(eval echo $MODEL_DIR)/${SRC_LANG}_${PIV_LANG}.${PIV_LANG}.out | grep -P \"^H\" |sort -V |cut -f 3- | sed \"s/ ##//g\" > $(eval echo $MODEL_DIR)/${SRC_LANG}_${PIV_LANG}.${PIV_LANG}.hyp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sacrebleu\n",
    "import argparse\n",
    "\n",
    "\n",
    "def calculate_score_report(sys, ref, score_only):\n",
    "\n",
    "    chrf = sacrebleu.corpus_chrf(sys, ref)\n",
    "    bleu = sacrebleu.corpus_bleu(sys, ref)\n",
    "\n",
    "    prefix = 'BLEU = ' if score_only else ''\n",
    "\n",
    "    print('#### Score Report ####')\n",
    "    print(chrf)\n",
    "    print('{}{}'.format(prefix, bleu.format(score_only=score_only)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "gold_lines=[]\n",
    "with open(src_piv_test_corpus + \"test.\" + piv_lang, encoding='utf8') as f:\n",
    "  gold_lines = f.readlines()\n",
    "  gold_lines = [x.strip(\"\\n\") for x in gold_lines]\n",
    "\n",
    "\n",
    "system_lines = []\n",
    "with open(model_dir + src_lang + \"_\" + piv_lang + \".\" + piv_lang + \".hyp\", encoding='utf8') as f:\n",
    "  system_lines = f.readlines()\n",
    "  system_lines = [x.strip(\"\\n\") for x in system_lines]\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "blanks = []\n",
    "for i in range(0,len(gold_lines)):\n",
    "    if gold_lines[i] == \"\":\n",
    "        blanks.append(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[]\n",
      "[]\n"
     ]
    }
   ],
   "source": [
    "print(blanks)\n",
    "blanks.reverse()\n",
    "print(blanks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in blanks:\n",
    "    del gold_lines[i]\n",
    "    del system_lines[i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1003\n",
      "1003\n"
     ]
    }
   ],
   "source": [
    "print(len(gold_lines))\n",
    "print(len(system_lines))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "La comprobación de antecedentes no se puede hacer tan rápido.\n",
      "\n",
      "La mayor mayor de los ancianos no se hacía nada\n"
     ]
    }
   ],
   "source": [
    "print(gold_lines[500])\n",
    "print()\n",
    "print(system_lines[500])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SCORE SRC->PIV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "That's 100 lines that end in a tokenized period ('.')\n",
      "It looks like you forgot to detokenize your test data, which may hurt your score.\n",
      "If you insist your data is detokenized, or don't care, you can suppress this message with the `force` parameter.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#### Score Report ####\n",
      "chrF2 = 17.74\n",
      "BLEU = 2.14 23.7/3.9/1.1/0.3 (BP = 0.882 ratio = 0.888 hyp_len = 10258 ref_len = 11550)\n"
     ]
    }
   ],
   "source": [
    "calculate_score_report(system_lines, [gold_lines], score_only=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## generating src->piv->tgt\n",
    "### src->piv sub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading file /notebooks/master-thesis/corpora/tatoeba-challenge/en-nah/test.nah\n",
      "/storage/master-thesis/models/capsnet__nah-es_es-en/tokenizers/nah-es-en/test.nah\n"
     ]
    }
   ],
   "source": [
    "tokenize_files(tokenizer, [src_tgt_test_corpus + 'test.' + src_lang], src_lang, tokenizer_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-10-31 15:51:43 | INFO | fairseq_cli.preprocess | Namespace(aim_repo=None, aim_run_hash=None, align_suffix=None, alignfile=None, all_gather_list_size=16384, amp=False, amp_batch_retries=2, amp_init_scale=128, amp_scale_window=None, azureml_logging=False, bf16=False, bpe=None, cpu=False, criterion='cross_entropy', dataset_impl='mmap', destdir='/storage/master-thesis/models/capsnet__nah-es_es-en/tokenizers/nah-es-en/bin/', dict_only=False, empty_cache_freq=0, fp16=False, fp16_init_scale=128, fp16_no_flatten_grads=False, fp16_scale_tolerance=0.0, fp16_scale_window=None, joined_dictionary=True, log_file=None, log_format=None, log_interval=100, lr_scheduler='fixed', memory_efficient_bf16=False, memory_efficient_fp16=False, min_loss_scale=0.0001, model_parallel_size=1, no_progress_bar=False, nwordssrc=-1, nwordstgt=-1, on_cpu_convert_precision=False, only_source=True, optimizer=None, padding_factor=8, plasma_path='/tmp/plasma', profile=False, quantization_config_path=None, reset_logging=False, scoring='bleu', seed=1, source_lang='nah', srcdict='/storage/master-thesis/models/capsnet__nah-es_es-en/tokenizers/nah-es-en/bin/dict.all.txt', suppress_crashes=False, target_lang='es', task='translation_multi_simple_epoch', tensorboard_logdir=None, testpref='/storage/master-thesis/models/capsnet__nah-es_es-en/tokenizers/nah-es-en/test', tgtdict=None, threshold_loss_scale=None, thresholdsrc=0, thresholdtgt=0, tokenizer=None, tpu=False, trainpref=None, use_plasma_view=False, user_dir=None, validpref=None, wandb_project=None, workers=20)\n",
      "2022-10-31 15:51:43 | INFO | fairseq_cli.preprocess | [nah] Dictionary: 28912 types\n",
      "2022-10-31 15:51:43 | INFO | fairseq_cli.preprocess | [nah] /storage/master-thesis/models/capsnet__nah-es_es-en/tokenizers/nah-es-en/test.nah: 1000 sents, 32924 tokens, 0.115% replaced (by <unk>)\n",
      "2022-10-31 15:51:43 | INFO | fairseq_cli.preprocess | Wrote preprocessed data to /storage/master-thesis/models/capsnet__nah-es_es-en/tokenizers/nah-es-en/bin/\n"
     ]
    }
   ],
   "source": [
    "! fairseq-preprocess --source-lang $SRC_LANG --target-lang $PIV_LANG \\\n",
    "    --testpref $(eval echo $TOKENIZER_PATH)/test \\\n",
    "    --destdir $(eval echo $TOKENIZER_PATH)/bin/ \\\n",
    "    --workers 20 \\\n",
    "    --srcdict $(eval echo $TOKENIZER_PATH)/bin/dict.all.txt \\\n",
    "    --task translation_multi_simple_epoch \\\n",
    "    --joined-dictionary \\\n",
    "    --only-source"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-10-31 15:51:47 | INFO | fairseq_cli.generate | {'_name': None, 'common': {'_name': None, 'no_progress_bar': False, 'log_interval': 100, 'log_format': None, 'log_file': None, 'aim_repo': None, 'aim_run_hash': None, 'tensorboard_logdir': None, 'wandb_project': None, 'azureml_logging': False, 'seed': 1, 'cpu': False, 'tpu': False, 'bf16': False, 'memory_efficient_bf16': False, 'fp16': False, 'memory_efficient_fp16': False, 'fp16_no_flatten_grads': False, 'fp16_init_scale': 128, 'fp16_scale_window': None, 'fp16_scale_tolerance': 0.0, 'on_cpu_convert_precision': False, 'min_loss_scale': 0.0001, 'threshold_loss_scale': None, 'amp': False, 'amp_batch_retries': 2, 'amp_init_scale': 128, 'amp_scale_window': None, 'user_dir': '/storage/code/fairseq-dynamic-routing-plugin/examples/dynamic_routing/dynamic_routing_src/', 'empty_cache_freq': 0, 'all_gather_list_size': 16384, 'model_parallel_size': 1, 'quantization_config_path': None, 'profile': False, 'reset_logging': False, 'suppress_crashes': False, 'use_plasma_view': False, 'plasma_path': '/tmp/plasma'}, 'common_eval': {'_name': None, 'path': '/storage/master-thesis/models/capsnet__nah-es_es-en/checkpoint_best.pt', 'post_process': None, 'quiet': False, 'model_overrides': '{}', 'results_path': None}, 'distributed_training': {'_name': None, 'distributed_world_size': 1, 'distributed_num_procs': 1, 'distributed_rank': 0, 'distributed_backend': 'nccl', 'distributed_init_method': None, 'distributed_port': -1, 'device_id': 0, 'distributed_no_spawn': False, 'ddp_backend': 'pytorch_ddp', 'ddp_comm_hook': 'none', 'bucket_cap_mb': 25, 'fix_batches_to_gpus': False, 'find_unused_parameters': False, 'gradient_as_bucket_view': False, 'fast_stat_sync': False, 'heartbeat_timeout': -1, 'broadcast_buffers': False, 'slowmo_momentum': None, 'slowmo_base_algorithm': 'localsgd', 'localsgd_frequency': 3, 'nprocs_per_node': 1, 'pipeline_model_parallel': False, 'pipeline_balance': None, 'pipeline_devices': None, 'pipeline_chunks': 0, 'pipeline_encoder_balance': None, 'pipeline_encoder_devices': None, 'pipeline_decoder_balance': None, 'pipeline_decoder_devices': None, 'pipeline_checkpoint': 'never', 'zero_sharding': 'none', 'fp16': False, 'memory_efficient_fp16': False, 'tpu': False, 'no_reshard_after_forward': False, 'fp32_reduce_scatter': False, 'cpu_offload': False, 'use_sharded_state': False, 'not_fsdp_flatten_parameters': False}, 'dataset': {'_name': None, 'num_workers': 1, 'skip_invalid_size_inputs_valid_test': False, 'max_tokens': 6000, 'batch_size': None, 'required_batch_size_multiple': 8, 'required_seq_len_multiple': 1, 'dataset_impl': None, 'data_buffer_size': 10, 'train_subset': 'train', 'valid_subset': 'valid', 'combine_valid_subsets': None, 'ignore_unused_valid_subsets': False, 'validate_interval': 1, 'validate_interval_updates': 0, 'validate_after_updates': 0, 'fixed_validation_seed': None, 'disable_validation': False, 'max_tokens_valid': 6000, 'batch_size_valid': None, 'max_valid_steps': None, 'curriculum': 0, 'gen_subset': 'test', 'num_shards': 1, 'shard_id': 0, 'grouped_shuffling': False, 'update_epoch_batch_itr': False, 'update_ordered_indices_seed': False}, 'optimization': {'_name': None, 'max_epoch': 0, 'max_update': 0, 'stop_time_hours': 0.0, 'clip_norm': 0.0, 'sentence_avg': False, 'update_freq': [1], 'lr': [0.25], 'stop_min_lr': -1.0, 'use_bmuf': False, 'skip_remainder_batch': False}, 'checkpoint': {'_name': None, 'save_dir': 'checkpoints', 'restore_file': 'checkpoint_last.pt', 'continue_once': None, 'finetune_from_model': None, 'reset_dataloader': False, 'reset_lr_scheduler': False, 'reset_meters': False, 'reset_optimizer': False, 'optimizer_overrides': '{}', 'save_interval': 1, 'save_interval_updates': 0, 'keep_interval_updates': -1, 'keep_interval_updates_pattern': -1, 'keep_last_epochs': -1, 'keep_best_checkpoints': -1, 'no_save': False, 'no_epoch_checkpoints': False, 'no_last_checkpoints': False, 'no_save_optimizer_state': False, 'best_checkpoint_metric': 'loss', 'maximize_best_checkpoint_metric': False, 'patience': -1, 'checkpoint_suffix': '', 'checkpoint_shard_count': 1, 'load_checkpoint_on_all_dp_ranks': False, 'write_checkpoints_asynchronously': False, 'model_parallel_size': 1}, 'bmuf': {'_name': None, 'block_lr': 1.0, 'block_momentum': 0.875, 'global_sync_iter': 50, 'warmup_iterations': 500, 'use_nbm': False, 'average_sync': False, 'distributed_world_size': 1}, 'generation': {'_name': None, 'beam': 5, 'nbest': 1, 'max_len_a': 0.0, 'max_len_b': 200, 'min_len': 1, 'match_source_len': False, 'unnormalized': False, 'no_early_stop': False, 'no_beamable_mm': False, 'lenpen': 1.0, 'unkpen': 0.0, 'replace_unk': None, 'sacrebleu': False, 'score_reference': False, 'prefix_size': 0, 'no_repeat_ngram_size': 0, 'sampling': False, 'sampling_topk': -1, 'sampling_topp': -1.0, 'constraints': None, 'temperature': 1.0, 'diverse_beam_groups': -1, 'diverse_beam_strength': 0.5, 'diversity_rate': -1.0, 'print_alignment': 'hard', 'print_step': False, 'lm_path': None, 'lm_weight': 0.0, 'iter_decode_eos_penalty': 0.0, 'iter_decode_max_iter': 10, 'iter_decode_force_max_iter': False, 'iter_decode_with_beam': 1, 'iter_decode_with_external_reranker': False, 'retain_iter_history': False, 'retain_dropout': False, 'retain_dropout_modules': None, 'decoding_format': None, 'no_seed_provided': False, 'eos_token': None}, 'eval_lm': {'_name': None, 'output_word_probs': False, 'output_word_stats': False, 'context_window': 0, 'softmax_batch': 9223372036854775807}, 'interactive': {'_name': None, 'buffer_size': 0, 'input': '-'}, 'model': {'_name': 'wav2vec2', 'extractor_mode': 'default', 'encoder_layers': 12, 'encoder_embed_dim': 768, 'encoder_ffn_embed_dim': 3072, 'encoder_attention_heads': 12, 'activation_fn': 'gelu', 'layer_type': 'transformer', 'dropout': 0.1, 'attention_dropout': 0.1, 'activation_dropout': 0.0, 'encoder_layerdrop': 0.0, 'dropout_input': 0.0, 'dropout_features': 0.0, 'final_dim': 0, 'layer_norm_first': False, 'conv_feature_layers': '[(512, 10, 5)] + [(512, 3, 2)] * 4 + [(512,2,2)] + [(512,2,2)]', 'conv_bias': False, 'logit_temp': 0.1, 'quantize_targets': False, 'quantize_input': False, 'same_quantizer': False, 'target_glu': False, 'feature_grad_mult': 1.0, 'quantizer_depth': 1, 'quantizer_factor': 3, 'latent_vars': 320, 'latent_groups': 2, 'latent_dim': 0, 'mask_length': 10, 'mask_prob': 0.65, 'mask_selection': 'static', 'mask_other': 0.0, 'no_mask_overlap': False, 'mask_min_space': 1, 'require_same_masks': True, 'mask_dropout': 0.0, 'mask_channel_length': 10, 'mask_channel_prob': 0.0, 'mask_channel_before': False, 'mask_channel_selection': 'static', 'mask_channel_other': 0.0, 'no_mask_channel_overlap': False, 'mask_channel_min_space': 1, 'num_negatives': 100, 'negatives_from_everywhere': False, 'cross_sample_negatives': 0, 'codebook_negatives': 0, 'conv_pos': 128, 'conv_pos_groups': 16, 'pos_conv_depth': 1, 'latent_temp': [2.0, 0.5, 0.999995], 'max_positions': 100000, 'checkpoint_activations': False, 'required_seq_len_multiple': 1, 'crop_seq_to_multiple': 1, 'depthwise_conv_kernel_size': 31, 'attn_type': '', 'pos_enc_type': 'abs', 'fp16': False}, 'task': Namespace(_name='translation_multi_simple_epoch', aim_repo=None, aim_run_hash=None, all_gather_list_size=16384, amp=False, amp_batch_retries=2, amp_init_scale=128, amp_scale_window=None, arch='wav2vec2', azureml_logging=False, batch_size=None, batch_size_valid=None, beam=5, best_checkpoint_metric='loss', bf16=False, bpe=None, broadcast_buffers=False, bucket_cap_mb=25, checkpoint_shard_count=1, checkpoint_suffix='', combine_valid_subsets=None, constraints=None, continue_once=None, cpu=False, cpu_offload=False, criterion='cross_entropy', curriculum=0, data='/storage/master-thesis/models/capsnet__nah-es_es-en/tokenizers/nah-es-en/bin', data_buffer_size=10, dataset_impl=None, ddp_backend='pytorch_ddp', ddp_comm_hook='none', decoder_langtok=True, decoding_format=None, device_id=0, disable_validation=False, distributed_backend='nccl', distributed_init_method=None, distributed_no_spawn=False, distributed_num_procs=1, distributed_port=-1, distributed_rank=0, distributed_world_size=1, diverse_beam_groups=-1, diverse_beam_strength=0.5, diversity_rate=-1.0, empty_cache_freq=0, enable_lang_ids=False, enable_reservsed_directions_shared_datasets=False, encoder_langtok='src', eos=2, eos_token=None, extra_data=None, extra_lang_pairs=None, fast_stat_sync=False, find_unused_parameters=False, finetune_from_model=None, fix_batches_to_gpus=False, fixed_dictionary=None, fixed_validation_seed=None, force_anneal=None, fp16=False, fp16_init_scale=128, fp16_no_flatten_grads=False, fp16_scale_tolerance=0.0, fp16_scale_window=None, fp32_reduce_scatter=False, gen_subset='test', gradient_as_bucket_view=False, grouped_shuffling=False, heartbeat_timeout=-1, ignore_unused_valid_subsets=False, iter_decode_eos_penalty=0.0, iter_decode_force_max_iter=False, iter_decode_max_iter=10, iter_decode_with_beam=1, iter_decode_with_external_reranker=False, keep_best_checkpoints=-1, keep_inference_langtok=False, keep_interval_updates=-1, keep_interval_updates_pattern=-1, keep_last_epochs=-1, lang_dict=None, lang_pairs='nah-es,es-en', lang_tok_replacing_bos_eos=False, lang_tok_style='multilingual', langs=None, langtoks=None, langtoks_specs=['main'], left_pad_source='True', left_pad_target='False', lenpen=1, lm_path=None, lm_weight=0.0, load_alignments=False, load_checkpoint_on_all_dp_ranks=False, localsgd_frequency=3, log_file=None, log_format=None, log_interval=100, lr_scheduler='fixed', lr_shrink=0.1, match_source_len=False, max_len_a=0, max_len_b=200, max_source_positions=1024, max_target_positions=1024, max_tokens=6000, max_tokens_valid=6000, max_valid_steps=None, maximize_best_checkpoint_metric=False, memory_efficient_bf16=False, memory_efficient_fp16=False, min_len=1, min_loss_scale=0.0001, model_overrides='{}', model_parallel_size=1, nbest=1, no_beamable_mm=False, no_early_stop=False, no_epoch_checkpoints=False, no_last_checkpoints=False, no_progress_bar=False, no_repeat_ngram_size=0, no_reshard_after_forward=False, no_save=False, no_save_optimizer_state=False, no_seed_provided=False, not_fsdp_flatten_parameters=False, nprocs_per_node=1, num_shards=1, num_workers=1, on_cpu_convert_precision=False, optimizer=None, optimizer_overrides='{}', pad=1, path='/storage/master-thesis/models/capsnet__nah-es_es-en/checkpoint_best.pt', patience=-1, pipeline_balance=None, pipeline_checkpoint='never', pipeline_chunks=0, pipeline_decoder_balance=None, pipeline_decoder_devices=None, pipeline_devices=None, pipeline_encoder_balance=None, pipeline_encoder_devices=None, pipeline_model_parallel=False, plasma_path='/tmp/plasma', post_process=None, prefix_size=0, print_alignment='hard', print_step=False, profile=False, quantization_config_path=None, quiet=False, replace_unk=None, required_batch_size_multiple=8, required_seq_len_multiple=1, reset_dataloader=False, reset_logging=False, reset_lr_scheduler=False, reset_meters=False, reset_optimizer=False, restore_file='checkpoint_last.pt', results_path=None, retain_dropout=False, retain_dropout_modules=None, retain_iter_history=False, sacrebleu=False, sampling=False, sampling_method='concat', sampling_temperature=1.5, sampling_topk=-1, sampling_topp=-1.0, sampling_weights=None, sampling_weights_from_file=None, save_dir='checkpoints', save_interval=1, save_interval_updates=0, score_reference=False, scoring='bleu', seed=1, shard_id=0, skip_invalid_size_inputs_valid_test=False, slowmo_base_algorithm='localsgd', slowmo_momentum=None, source_dict=None, source_lang='nah', suppress_crashes=False, target_dict=None, target_lang='es', task='translation_multi_simple_epoch', temperature=1.0, tensorboard_logdir=None, threshold_loss_scale=None, tokenizer=None, tpu=False, train_subset='train', truncate_source=False, unk=3, unkpen=0, unnormalized=False, update_epoch_batch_itr=False, update_ordered_indices_seed=False, upsample_primary=1, use_plasma_view=False, use_sharded_state=False, user_dir='/storage/code/fairseq-dynamic-routing-plugin/examples/dynamic_routing/dynamic_routing_src/', valid_subset='valid', validate_after_updates=0, validate_interval=1, validate_interval_updates=0, virtual_data_size=None, virtual_epoch_size=None, wandb_project=None, warmup_updates=0, write_checkpoints_asynchronously=False, zero_sharding='none'), 'criterion': {'_name': 'cross_entropy', 'sentence_avg': True}, 'optimizer': None, 'lr_scheduler': {'_name': 'fixed', 'force_anneal': None, 'lr_shrink': 0.1, 'warmup_updates': 0, 'lr': [0.25]}, 'scoring': {'_name': 'bleu', 'pad': 1, 'eos': 2, 'unk': 3}, 'bpe': None, 'tokenizer': None, 'ema': {'_name': None, 'store_ema': False, 'ema_decay': 0.9999, 'ema_start_update': 0, 'ema_seed_model': None, 'ema_update_freq': 1, 'ema_fp32': False}}\n",
      "2022-10-31 15:51:47 | WARNING | fairseq.data.multilingual.multilingual_data_manager | External language dictionary is not provided; use lang-pairs to infer the set of supported languages. The language ordering is not stable which might cause misalignment in pretraining and finetuning.\n",
      "2022-10-31 15:51:47 | INFO | fairseq.data.multilingual.multilingual_data_manager | inferred language list: ['en', 'es', 'nah']\n",
      "2022-10-31 15:51:47 | INFO | fairseq.data.multilingual.multilingual_data_manager | [nah] dictionary: 28915 types\n",
      "2022-10-31 15:51:47 | INFO | fairseq.data.multilingual.multilingual_data_manager | [es] dictionary: 28915 types\n",
      "2022-10-31 15:51:47 | INFO | fairseq_cli.generate | loading model(s) from /storage/master-thesis/models/capsnet__nah-es_es-en/checkpoint_best.pt\n",
      "2022-10-31 15:51:48 | INFO | fairseq.tasks.translation_multi_simple_epoch | loading data for test epoch=1/None\n",
      "2022-10-31 15:51:48 | INFO | fairseq.tasks.translation_multi_simple_epoch | mem usage: N/A\n",
      "2022-10-31 15:51:48 | INFO | fairseq.data.multilingual.multilingual_data_manager | langtoks settings: {'main': ('src', 'tgt')}\n",
      "2022-10-31 15:51:48 | INFO | fairseq.data.multilingual.multilingual_data_manager | [test] num of shards: {'main:nah-es': 1}\n",
      "2022-10-31 15:51:48 | INFO | fairseq.data.multilingual.multilingual_data_manager | main:nah-es src_langtok: 28914; tgt_langtok: 28913\n",
      "2022-10-31 15:51:48 | INFO | fairseq.data.data_utils | loaded 1,000 examples from: /storage/master-thesis/models/capsnet__nah-es_es-en/tokenizers/nah-es-en/bin/test.nah-es.nah\n",
      "2022-10-31 15:51:48 | INFO | fairseq.data.multilingual.multilingual_data_manager | /storage/master-thesis/models/capsnet__nah-es_es-en/tokenizers/nah-es-en/bin test nah-es 1000 examples\n",
      "2022-10-31 15:51:54 | INFO | fairseq.tasks.translation_multi_simple_epoch | start batch sampler: mem usage: N/A\n",
      "2022-10-31 15:51:54 | INFO | fairseq.tasks.translation_multi_simple_epoch | [test] @batch_sampler order indices time: 0:00:00.000536\n",
      "2022-10-31 15:51:54 | INFO | fairseq.tasks.translation_multi_simple_epoch | mem usage: N/A\n",
      "2022-10-31 15:51:54 | INFO | fairseq.tasks.translation_multi_simple_epoch | [test] @batch_sampler filter_by_size time: 0:00:00.005477\n",
      "2022-10-31 15:51:54 | INFO | fairseq.tasks.translation_multi_simple_epoch | mem usage: N/A\n",
      "2022-10-31 15:51:54 | INFO | fairseq.tasks.translation_multi_simple_epoch | [test] @batch_sampler batch_by_size time: 0:00:00.007197\n",
      "2022-10-31 15:51:54 | INFO | fairseq.tasks.translation_multi_simple_epoch | [test] per epoch batch_sampler set-up time: 0:00:00.013743\n",
      "2022-10-31 15:51:54 | INFO | fairseq.tasks.translation_multi_simple_epoch | mem usage: N/A\n",
      "2022-10-31 15:52:08 | INFO | fairseq_cli.generate | NOTE: hypothesis and token scores are output in base 2����| 7/7 [00:14<00:00,  1.97s/it, wps=1525]\n",
      "2022-10-31 15:52:08 | INFO | fairseq_cli.generate | Translated 1,000 sentences (21,426 tokens) in 10.9s (91.94 sentences/s, 1970.00 tokens/s)\n"
     ]
    }
   ],
   "source": [
    "! PYTHONIOENCODING=utf-8 fairseq-generate $(eval echo $TOKENIZER_PATH)/bin \\\n",
    "    --path $(eval echo $MODEL_DIR)/checkpoint_best.pt  \\\n",
    "    $(eval echo $MODEL_PARAM) \\\n",
    "    --source-lang $SRC_LANG --target-lang $PIV_LANG \\\n",
    "    --max-tokens 6000 \\\n",
    "    --task translation_multi_simple_epoch \\\n",
    "    --encoder-langtok \"src\" \\\n",
    "    --decoder-langtok \\\n",
    "    --lang-pairs $LANG_PAIRS \\\n",
    "    --print-alignment > $(eval echo $MODEL_DIR)/${SRC_LANG}_${PIV_LANG}.${PIV_LANG}.out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "!cat $(eval echo $MODEL_DIR)/${SRC_LANG}_${PIV_LANG}.${PIV_LANG}.out | grep -P \"^H\" |sort -V |cut -f 3- | sed \"s/ ##//g\" > $(eval echo $MODEL_DIR)/${SRC_LANG}_${PIV_LANG}.${PIV_LANG}.hyp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### piv->tgt sub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading file /storage/master-thesis/models/capsnet__nah-es_es-en/nah_es.es.hyp\n",
      "/storage/master-thesis/models/capsnet__nah-es_es-en/tokenizers/nah-es-en/nah_es.es.es\n"
     ]
    }
   ],
   "source": [
    "tokenize_files(tokenizer, [model_dir + src_lang + \"_\" + piv_lang + \".\" + piv_lang + \".hyp\"], piv_lang, tokenizer_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "mv $(eval echo $TOKENIZER_PATH)/${SRC_LANG}_${PIV_LANG}.${PIV_LANG}.${PIV_LANG} $(eval echo $TOKENIZER_PATH)/test.${PIV_LANG}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-10-31 15:52:11 | INFO | fairseq_cli.preprocess | Namespace(aim_repo=None, aim_run_hash=None, align_suffix=None, alignfile=None, all_gather_list_size=16384, amp=False, amp_batch_retries=2, amp_init_scale=128, amp_scale_window=None, azureml_logging=False, bf16=False, bpe=None, cpu=False, criterion='cross_entropy', dataset_impl='mmap', destdir='/storage/master-thesis/models/capsnet__nah-es_es-en/tokenizers/nah-es-en/bin/', dict_only=False, empty_cache_freq=0, fp16=False, fp16_init_scale=128, fp16_no_flatten_grads=False, fp16_scale_tolerance=0.0, fp16_scale_window=None, joined_dictionary=True, log_file=None, log_format=None, log_interval=100, lr_scheduler='fixed', memory_efficient_bf16=False, memory_efficient_fp16=False, min_loss_scale=0.0001, model_parallel_size=1, no_progress_bar=False, nwordssrc=-1, nwordstgt=-1, on_cpu_convert_precision=False, only_source=True, optimizer=None, padding_factor=8, plasma_path='/tmp/plasma', profile=False, quantization_config_path=None, reset_logging=False, scoring='bleu', seed=1, source_lang='es', srcdict='/storage/master-thesis/models/capsnet__nah-es_es-en/tokenizers/nah-es-en/bin/dict.all.txt', suppress_crashes=False, target_lang='en', task='translation_multi_simple_epoch', tensorboard_logdir=None, testpref='/storage/master-thesis/models/capsnet__nah-es_es-en/tokenizers/nah-es-en/test', tgtdict=None, threshold_loss_scale=None, thresholdsrc=0, thresholdtgt=0, tokenizer=None, tpu=False, trainpref=None, use_plasma_view=False, user_dir=None, validpref=None, wandb_project=None, workers=20)\n",
      "2022-10-31 15:52:11 | INFO | fairseq_cli.preprocess | [es] Dictionary: 28912 types\n",
      "2022-10-31 15:52:12 | INFO | fairseq_cli.preprocess | [es] /storage/master-thesis/models/capsnet__nah-es_es-en/tokenizers/nah-es-en/test.es: 1000 sents, 20340 tokens, 0.00492% replaced (by <unk>)\n",
      "2022-10-31 15:52:12 | INFO | fairseq_cli.preprocess | Wrote preprocessed data to /storage/master-thesis/models/capsnet__nah-es_es-en/tokenizers/nah-es-en/bin/\n"
     ]
    }
   ],
   "source": [
    "! fairseq-preprocess --source-lang $PIV_LANG --target-lang $TGT_LANG \\\n",
    "    --testpref $(eval echo $TOKENIZER_PATH)/test \\\n",
    "    --destdir $(eval echo $TOKENIZER_PATH)/bin/ \\\n",
    "    --workers 20 \\\n",
    "    --srcdict $(eval echo $TOKENIZER_PATH)/bin/dict.all.txt \\\n",
    "    --task translation_multi_simple_epoch \\\n",
    "    --joined-dictionary \\\n",
    "    --only-source"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-10-31 15:52:15 | INFO | fairseq_cli.generate | {'_name': None, 'common': {'_name': None, 'no_progress_bar': False, 'log_interval': 100, 'log_format': None, 'log_file': None, 'aim_repo': None, 'aim_run_hash': None, 'tensorboard_logdir': None, 'wandb_project': None, 'azureml_logging': False, 'seed': 1, 'cpu': False, 'tpu': False, 'bf16': False, 'memory_efficient_bf16': False, 'fp16': False, 'memory_efficient_fp16': False, 'fp16_no_flatten_grads': False, 'fp16_init_scale': 128, 'fp16_scale_window': None, 'fp16_scale_tolerance': 0.0, 'on_cpu_convert_precision': False, 'min_loss_scale': 0.0001, 'threshold_loss_scale': None, 'amp': False, 'amp_batch_retries': 2, 'amp_init_scale': 128, 'amp_scale_window': None, 'user_dir': '/storage/code/fairseq-dynamic-routing-plugin/examples/dynamic_routing/dynamic_routing_src/', 'empty_cache_freq': 0, 'all_gather_list_size': 16384, 'model_parallel_size': 1, 'quantization_config_path': None, 'profile': False, 'reset_logging': False, 'suppress_crashes': False, 'use_plasma_view': False, 'plasma_path': '/tmp/plasma'}, 'common_eval': {'_name': None, 'path': '/storage/master-thesis/models/capsnet__nah-es_es-en/checkpoint_best.pt', 'post_process': None, 'quiet': False, 'model_overrides': '{}', 'results_path': None}, 'distributed_training': {'_name': None, 'distributed_world_size': 1, 'distributed_num_procs': 1, 'distributed_rank': 0, 'distributed_backend': 'nccl', 'distributed_init_method': None, 'distributed_port': -1, 'device_id': 0, 'distributed_no_spawn': False, 'ddp_backend': 'pytorch_ddp', 'ddp_comm_hook': 'none', 'bucket_cap_mb': 25, 'fix_batches_to_gpus': False, 'find_unused_parameters': False, 'gradient_as_bucket_view': False, 'fast_stat_sync': False, 'heartbeat_timeout': -1, 'broadcast_buffers': False, 'slowmo_momentum': None, 'slowmo_base_algorithm': 'localsgd', 'localsgd_frequency': 3, 'nprocs_per_node': 1, 'pipeline_model_parallel': False, 'pipeline_balance': None, 'pipeline_devices': None, 'pipeline_chunks': 0, 'pipeline_encoder_balance': None, 'pipeline_encoder_devices': None, 'pipeline_decoder_balance': None, 'pipeline_decoder_devices': None, 'pipeline_checkpoint': 'never', 'zero_sharding': 'none', 'fp16': False, 'memory_efficient_fp16': False, 'tpu': False, 'no_reshard_after_forward': False, 'fp32_reduce_scatter': False, 'cpu_offload': False, 'use_sharded_state': False, 'not_fsdp_flatten_parameters': False}, 'dataset': {'_name': None, 'num_workers': 1, 'skip_invalid_size_inputs_valid_test': False, 'max_tokens': 6000, 'batch_size': None, 'required_batch_size_multiple': 8, 'required_seq_len_multiple': 1, 'dataset_impl': None, 'data_buffer_size': 10, 'train_subset': 'train', 'valid_subset': 'valid', 'combine_valid_subsets': None, 'ignore_unused_valid_subsets': False, 'validate_interval': 1, 'validate_interval_updates': 0, 'validate_after_updates': 0, 'fixed_validation_seed': None, 'disable_validation': False, 'max_tokens_valid': 6000, 'batch_size_valid': None, 'max_valid_steps': None, 'curriculum': 0, 'gen_subset': 'test', 'num_shards': 1, 'shard_id': 0, 'grouped_shuffling': False, 'update_epoch_batch_itr': False, 'update_ordered_indices_seed': False}, 'optimization': {'_name': None, 'max_epoch': 0, 'max_update': 0, 'stop_time_hours': 0.0, 'clip_norm': 0.0, 'sentence_avg': False, 'update_freq': [1], 'lr': [0.25], 'stop_min_lr': -1.0, 'use_bmuf': False, 'skip_remainder_batch': False}, 'checkpoint': {'_name': None, 'save_dir': 'checkpoints', 'restore_file': 'checkpoint_last.pt', 'continue_once': None, 'finetune_from_model': None, 'reset_dataloader': False, 'reset_lr_scheduler': False, 'reset_meters': False, 'reset_optimizer': False, 'optimizer_overrides': '{}', 'save_interval': 1, 'save_interval_updates': 0, 'keep_interval_updates': -1, 'keep_interval_updates_pattern': -1, 'keep_last_epochs': -1, 'keep_best_checkpoints': -1, 'no_save': False, 'no_epoch_checkpoints': False, 'no_last_checkpoints': False, 'no_save_optimizer_state': False, 'best_checkpoint_metric': 'loss', 'maximize_best_checkpoint_metric': False, 'patience': -1, 'checkpoint_suffix': '', 'checkpoint_shard_count': 1, 'load_checkpoint_on_all_dp_ranks': False, 'write_checkpoints_asynchronously': False, 'model_parallel_size': 1}, 'bmuf': {'_name': None, 'block_lr': 1.0, 'block_momentum': 0.875, 'global_sync_iter': 50, 'warmup_iterations': 500, 'use_nbm': False, 'average_sync': False, 'distributed_world_size': 1}, 'generation': {'_name': None, 'beam': 5, 'nbest': 1, 'max_len_a': 0.0, 'max_len_b': 200, 'min_len': 1, 'match_source_len': False, 'unnormalized': False, 'no_early_stop': False, 'no_beamable_mm': False, 'lenpen': 1.0, 'unkpen': 0.0, 'replace_unk': None, 'sacrebleu': False, 'score_reference': False, 'prefix_size': 0, 'no_repeat_ngram_size': 0, 'sampling': False, 'sampling_topk': -1, 'sampling_topp': -1.0, 'constraints': None, 'temperature': 1.0, 'diverse_beam_groups': -1, 'diverse_beam_strength': 0.5, 'diversity_rate': -1.0, 'print_alignment': 'hard', 'print_step': False, 'lm_path': None, 'lm_weight': 0.0, 'iter_decode_eos_penalty': 0.0, 'iter_decode_max_iter': 10, 'iter_decode_force_max_iter': False, 'iter_decode_with_beam': 1, 'iter_decode_with_external_reranker': False, 'retain_iter_history': False, 'retain_dropout': False, 'retain_dropout_modules': None, 'decoding_format': None, 'no_seed_provided': False, 'eos_token': None}, 'eval_lm': {'_name': None, 'output_word_probs': False, 'output_word_stats': False, 'context_window': 0, 'softmax_batch': 9223372036854775807}, 'interactive': {'_name': None, 'buffer_size': 0, 'input': '-'}, 'model': {'_name': 'wav2vec2', 'extractor_mode': 'default', 'encoder_layers': 12, 'encoder_embed_dim': 768, 'encoder_ffn_embed_dim': 3072, 'encoder_attention_heads': 12, 'activation_fn': 'gelu', 'layer_type': 'transformer', 'dropout': 0.1, 'attention_dropout': 0.1, 'activation_dropout': 0.0, 'encoder_layerdrop': 0.0, 'dropout_input': 0.0, 'dropout_features': 0.0, 'final_dim': 0, 'layer_norm_first': False, 'conv_feature_layers': '[(512, 10, 5)] + [(512, 3, 2)] * 4 + [(512,2,2)] + [(512,2,2)]', 'conv_bias': False, 'logit_temp': 0.1, 'quantize_targets': False, 'quantize_input': False, 'same_quantizer': False, 'target_glu': False, 'feature_grad_mult': 1.0, 'quantizer_depth': 1, 'quantizer_factor': 3, 'latent_vars': 320, 'latent_groups': 2, 'latent_dim': 0, 'mask_length': 10, 'mask_prob': 0.65, 'mask_selection': 'static', 'mask_other': 0.0, 'no_mask_overlap': False, 'mask_min_space': 1, 'require_same_masks': True, 'mask_dropout': 0.0, 'mask_channel_length': 10, 'mask_channel_prob': 0.0, 'mask_channel_before': False, 'mask_channel_selection': 'static', 'mask_channel_other': 0.0, 'no_mask_channel_overlap': False, 'mask_channel_min_space': 1, 'num_negatives': 100, 'negatives_from_everywhere': False, 'cross_sample_negatives': 0, 'codebook_negatives': 0, 'conv_pos': 128, 'conv_pos_groups': 16, 'pos_conv_depth': 1, 'latent_temp': [2.0, 0.5, 0.999995], 'max_positions': 100000, 'checkpoint_activations': False, 'required_seq_len_multiple': 1, 'crop_seq_to_multiple': 1, 'depthwise_conv_kernel_size': 31, 'attn_type': '', 'pos_enc_type': 'abs', 'fp16': False}, 'task': Namespace(_name='translation_multi_simple_epoch', aim_repo=None, aim_run_hash=None, all_gather_list_size=16384, amp=False, amp_batch_retries=2, amp_init_scale=128, amp_scale_window=None, arch='wav2vec2', azureml_logging=False, batch_size=None, batch_size_valid=None, beam=5, best_checkpoint_metric='loss', bf16=False, bpe=None, broadcast_buffers=False, bucket_cap_mb=25, checkpoint_shard_count=1, checkpoint_suffix='', combine_valid_subsets=None, constraints=None, continue_once=None, cpu=False, cpu_offload=False, criterion='cross_entropy', curriculum=0, data='/storage/master-thesis/models/capsnet__nah-es_es-en/tokenizers/nah-es-en/bin', data_buffer_size=10, dataset_impl=None, ddp_backend='pytorch_ddp', ddp_comm_hook='none', decoder_langtok=True, decoding_format=None, device_id=0, disable_validation=False, distributed_backend='nccl', distributed_init_method=None, distributed_no_spawn=False, distributed_num_procs=1, distributed_port=-1, distributed_rank=0, distributed_world_size=1, diverse_beam_groups=-1, diverse_beam_strength=0.5, diversity_rate=-1.0, empty_cache_freq=0, enable_lang_ids=False, enable_reservsed_directions_shared_datasets=False, encoder_langtok='src', eos=2, eos_token=None, extra_data=None, extra_lang_pairs=None, fast_stat_sync=False, find_unused_parameters=False, finetune_from_model=None, fix_batches_to_gpus=False, fixed_dictionary=None, fixed_validation_seed=None, force_anneal=None, fp16=False, fp16_init_scale=128, fp16_no_flatten_grads=False, fp16_scale_tolerance=0.0, fp16_scale_window=None, fp32_reduce_scatter=False, gen_subset='test', gradient_as_bucket_view=False, grouped_shuffling=False, heartbeat_timeout=-1, ignore_unused_valid_subsets=False, iter_decode_eos_penalty=0.0, iter_decode_force_max_iter=False, iter_decode_max_iter=10, iter_decode_with_beam=1, iter_decode_with_external_reranker=False, keep_best_checkpoints=-1, keep_inference_langtok=False, keep_interval_updates=-1, keep_interval_updates_pattern=-1, keep_last_epochs=-1, lang_dict=None, lang_pairs='nah-es,es-en', lang_tok_replacing_bos_eos=False, lang_tok_style='multilingual', langs=None, langtoks=None, langtoks_specs=['main'], left_pad_source='True', left_pad_target='False', lenpen=1, lm_path=None, lm_weight=0.0, load_alignments=False, load_checkpoint_on_all_dp_ranks=False, localsgd_frequency=3, log_file=None, log_format=None, log_interval=100, lr_scheduler='fixed', lr_shrink=0.1, match_source_len=False, max_len_a=0, max_len_b=200, max_source_positions=1024, max_target_positions=1024, max_tokens=6000, max_tokens_valid=6000, max_valid_steps=None, maximize_best_checkpoint_metric=False, memory_efficient_bf16=False, memory_efficient_fp16=False, min_len=1, min_loss_scale=0.0001, model_overrides='{}', model_parallel_size=1, nbest=1, no_beamable_mm=False, no_early_stop=False, no_epoch_checkpoints=False, no_last_checkpoints=False, no_progress_bar=False, no_repeat_ngram_size=0, no_reshard_after_forward=False, no_save=False, no_save_optimizer_state=False, no_seed_provided=False, not_fsdp_flatten_parameters=False, nprocs_per_node=1, num_shards=1, num_workers=1, on_cpu_convert_precision=False, optimizer=None, optimizer_overrides='{}', pad=1, path='/storage/master-thesis/models/capsnet__nah-es_es-en/checkpoint_best.pt', patience=-1, pipeline_balance=None, pipeline_checkpoint='never', pipeline_chunks=0, pipeline_decoder_balance=None, pipeline_decoder_devices=None, pipeline_devices=None, pipeline_encoder_balance=None, pipeline_encoder_devices=None, pipeline_model_parallel=False, plasma_path='/tmp/plasma', post_process=None, prefix_size=0, print_alignment='hard', print_step=False, profile=False, quantization_config_path=None, quiet=False, replace_unk=None, required_batch_size_multiple=8, required_seq_len_multiple=1, reset_dataloader=False, reset_logging=False, reset_lr_scheduler=False, reset_meters=False, reset_optimizer=False, restore_file='checkpoint_last.pt', results_path=None, retain_dropout=False, retain_dropout_modules=None, retain_iter_history=False, sacrebleu=False, sampling=False, sampling_method='concat', sampling_temperature=1.5, sampling_topk=-1, sampling_topp=-1.0, sampling_weights=None, sampling_weights_from_file=None, save_dir='checkpoints', save_interval=1, save_interval_updates=0, score_reference=False, scoring='bleu', seed=1, shard_id=0, skip_invalid_size_inputs_valid_test=False, slowmo_base_algorithm='localsgd', slowmo_momentum=None, source_dict=None, source_lang='es', suppress_crashes=False, target_dict=None, target_lang='en', task='translation_multi_simple_epoch', temperature=1.0, tensorboard_logdir=None, threshold_loss_scale=None, tokenizer=None, tpu=False, train_subset='train', truncate_source=False, unk=3, unkpen=0, unnormalized=False, update_epoch_batch_itr=False, update_ordered_indices_seed=False, upsample_primary=1, use_plasma_view=False, use_sharded_state=False, user_dir='/storage/code/fairseq-dynamic-routing-plugin/examples/dynamic_routing/dynamic_routing_src/', valid_subset='valid', validate_after_updates=0, validate_interval=1, validate_interval_updates=0, virtual_data_size=None, virtual_epoch_size=None, wandb_project=None, warmup_updates=0, write_checkpoints_asynchronously=False, zero_sharding='none'), 'criterion': {'_name': 'cross_entropy', 'sentence_avg': True}, 'optimizer': None, 'lr_scheduler': {'_name': 'fixed', 'force_anneal': None, 'lr_shrink': 0.1, 'warmup_updates': 0, 'lr': [0.25]}, 'scoring': {'_name': 'bleu', 'pad': 1, 'eos': 2, 'unk': 3}, 'bpe': None, 'tokenizer': None, 'ema': {'_name': None, 'store_ema': False, 'ema_decay': 0.9999, 'ema_start_update': 0, 'ema_seed_model': None, 'ema_update_freq': 1, 'ema_fp32': False}}\n",
      "2022-10-31 15:52:15 | WARNING | fairseq.data.multilingual.multilingual_data_manager | External language dictionary is not provided; use lang-pairs to infer the set of supported languages. The language ordering is not stable which might cause misalignment in pretraining and finetuning.\n",
      "2022-10-31 15:52:15 | INFO | fairseq.data.multilingual.multilingual_data_manager | inferred language list: ['en', 'es', 'nah']\n",
      "2022-10-31 15:52:15 | INFO | fairseq.data.multilingual.multilingual_data_manager | [es] dictionary: 28915 types\n",
      "2022-10-31 15:52:15 | INFO | fairseq.data.multilingual.multilingual_data_manager | [en] dictionary: 28915 types\n",
      "2022-10-31 15:52:15 | INFO | fairseq_cli.generate | loading model(s) from /storage/master-thesis/models/capsnet__nah-es_es-en/checkpoint_best.pt\n",
      "2022-10-31 15:52:17 | INFO | fairseq.tasks.translation_multi_simple_epoch | loading data for test epoch=1/None\n",
      "2022-10-31 15:52:17 | INFO | fairseq.tasks.translation_multi_simple_epoch | mem usage: N/A\n",
      "2022-10-31 15:52:17 | INFO | fairseq.data.multilingual.multilingual_data_manager | langtoks settings: {'main': ('src', 'tgt')}\n",
      "2022-10-31 15:52:17 | INFO | fairseq.data.multilingual.multilingual_data_manager | [test] num of shards: {'main:es-en': 1}\n",
      "2022-10-31 15:52:17 | INFO | fairseq.data.multilingual.multilingual_data_manager | main:es-en src_langtok: 28913; tgt_langtok: 28912\n",
      "2022-10-31 15:52:17 | INFO | fairseq.data.data_utils | loaded 1,000 examples from: /storage/master-thesis/models/capsnet__nah-es_es-en/tokenizers/nah-es-en/bin/test.es-en.es\n",
      "2022-10-31 15:52:17 | INFO | fairseq.data.multilingual.multilingual_data_manager | /storage/master-thesis/models/capsnet__nah-es_es-en/tokenizers/nah-es-en/bin test es-en 1000 examples\n",
      "2022-10-31 15:52:22 | INFO | fairseq.tasks.translation_multi_simple_epoch | start batch sampler: mem usage: N/A\n",
      "2022-10-31 15:52:22 | INFO | fairseq.tasks.translation_multi_simple_epoch | [test] @batch_sampler order indices time: 0:00:00.000520\n",
      "2022-10-31 15:52:22 | INFO | fairseq.tasks.translation_multi_simple_epoch | mem usage: N/A\n",
      "2022-10-31 15:52:22 | INFO | fairseq.tasks.translation_multi_simple_epoch | [test] @batch_sampler filter_by_size time: 0:00:00.005579\n",
      "2022-10-31 15:52:22 | INFO | fairseq.tasks.translation_multi_simple_epoch | mem usage: N/A\n",
      "2022-10-31 15:52:22 | INFO | fairseq.tasks.translation_multi_simple_epoch | [test] @batch_sampler batch_by_size time: 0:00:00.005924\n",
      "2022-10-31 15:52:22 | INFO | fairseq.tasks.translation_multi_simple_epoch | [test] per epoch batch_sampler set-up time: 0:00:00.012527\n",
      "2022-10-31 15:52:22 | INFO | fairseq.tasks.translation_multi_simple_epoch | mem usage: N/A\n",
      "2022-10-31 15:52:34 | INFO | fairseq_cli.generate | NOTE: hypothesis and token scores are output in base 2����| 5/5 [00:11<00:00,  2.29s/it, wps=1723]\n",
      "2022-10-31 15:52:34 | INFO | fairseq_cli.generate | Translated 1,000 sentences (20,391 tokens) in 9.2s (108.87 sentences/s, 2220.05 tokens/s)\n"
     ]
    }
   ],
   "source": [
    "! PYTHONIOENCODING=utf-8 fairseq-generate $(eval echo $TOKENIZER_PATH)/bin \\\n",
    "    --path $(eval echo $MODEL_DIR)/checkpoint_best.pt  \\\n",
    "    $(eval echo $MODEL_PARAM) \\\n",
    "    --source-lang $PIV_LANG --target-lang $TGT_LANG \\\n",
    "    --max-tokens 6000 \\\n",
    "    --task translation_multi_simple_epoch \\\n",
    "    --encoder-langtok \"src\" \\\n",
    "    --decoder-langtok \\\n",
    "    --lang-pairs $LANG_PAIRS \\\n",
    "    --print-alignment > $(eval echo $MODEL_DIR)/${PIV_LANG}_${TGT_LANG}.${TGT_LANG}.out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "!cat $(eval echo $MODEL_DIR)/${PIV_LANG}_${TGT_LANG}.${TGT_LANG}.out | grep -P \"^H\" |sort -V |cut -f 3- | sed \"s/ ##//g\" > $(eval echo $MODEL_DIR)/${PIV_LANG}_${TGT_LANG}.${TGT_LANG}.hyp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "gold_lines=[]\n",
    "with open(src_tgt_test_corpus + \"test.\" + tgt_lang, encoding='utf8') as f:\n",
    "  gold_lines = f.readlines()\n",
    "  gold_lines = [x.strip(\"\\n\") for x in gold_lines]\n",
    "\n",
    "\n",
    "system_lines = []\n",
    "with open(model_dir + piv_lang + \"_\" + tgt_lang + \".\" + tgt_lang + \".hyp\", encoding='utf8') as f:\n",
    "  system_lines = f.readlines()\n",
    "  system_lines = [x.strip(\"\\n\") for x in system_lines]\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "blanks = []\n",
    "for i in range(0,len(gold_lines)):\n",
    "    if gold_lines[i] == \"\":\n",
    "        blanks.append(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[]\n",
      "[]\n"
     ]
    }
   ],
   "source": [
    "print(blanks)\n",
    "blanks.reverse()\n",
    "print(blanks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in blanks:\n",
    "    del gold_lines[i]\n",
    "    del system_lines[i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000\n",
      "1000\n"
     ]
    }
   ],
   "source": [
    "print(len(gold_lines))\n",
    "print(len(system_lines))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "They will be judged.\n",
      "\n",
      "Then Jesus gives everyone to eat .\n"
     ]
    }
   ],
   "source": [
    "print(gold_lines[200])\n",
    "print()\n",
    "print(system_lines[200])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SCORE SRC->PIV->TGT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "That's 100 lines that end in a tokenized period ('.')\n",
      "It looks like you forgot to detokenize your test data, which may hurt your score.\n",
      "If you insist your data is detokenized, or don't care, you can suppress this message with the `force` parameter.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#### Score Report ####\n",
      "chrF2 = 15.52\n",
      "BLEU = 0.95 19.8/1.9/0.3/0.1 (BP = 0.908 ratio = 0.912 hyp_len = 17216 ref_len = 18871)\n"
     ]
    }
   ],
   "source": [
    "calculate_score_report(system_lines, [gold_lines], score_only=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## generating src->tgt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading file /notebooks/master-thesis/corpora/tatoeba-challenge/en-nah/test.nah\n",
      "/storage/master-thesis/models/capsnet__nah-es_es-en/tokenizers/nah-es-en/test.nah\n"
     ]
    }
   ],
   "source": [
    "tokenize_files(tokenizer, [src_tgt_test_corpus + 'test.' + src_lang], src_lang, tokenizer_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-10-31 15:52:37 | INFO | fairseq_cli.preprocess | Namespace(aim_repo=None, aim_run_hash=None, align_suffix=None, alignfile=None, all_gather_list_size=16384, amp=False, amp_batch_retries=2, amp_init_scale=128, amp_scale_window=None, azureml_logging=False, bf16=False, bpe=None, cpu=False, criterion='cross_entropy', dataset_impl='mmap', destdir='/storage/master-thesis/models/capsnet__nah-es_es-en/tokenizers/nah-es-en/bin/', dict_only=False, empty_cache_freq=0, fp16=False, fp16_init_scale=128, fp16_no_flatten_grads=False, fp16_scale_tolerance=0.0, fp16_scale_window=None, joined_dictionary=True, log_file=None, log_format=None, log_interval=100, lr_scheduler='fixed', memory_efficient_bf16=False, memory_efficient_fp16=False, min_loss_scale=0.0001, model_parallel_size=1, no_progress_bar=False, nwordssrc=-1, nwordstgt=-1, on_cpu_convert_precision=False, only_source=True, optimizer=None, padding_factor=8, plasma_path='/tmp/plasma', profile=False, quantization_config_path=None, reset_logging=False, scoring='bleu', seed=1, source_lang='nah', srcdict='/storage/master-thesis/models/capsnet__nah-es_es-en/tokenizers/nah-es-en/bin/dict.all.txt', suppress_crashes=False, target_lang='en', task='translation_multi_simple_epoch', tensorboard_logdir=None, testpref='/storage/master-thesis/models/capsnet__nah-es_es-en/tokenizers/nah-es-en/test', tgtdict=None, threshold_loss_scale=None, thresholdsrc=0, thresholdtgt=0, tokenizer=None, tpu=False, trainpref=None, use_plasma_view=False, user_dir=None, validpref=None, wandb_project=None, workers=20)\n",
      "2022-10-31 15:52:37 | INFO | fairseq_cli.preprocess | [nah] Dictionary: 28912 types\n",
      "2022-10-31 15:52:38 | INFO | fairseq_cli.preprocess | [nah] /storage/master-thesis/models/capsnet__nah-es_es-en/tokenizers/nah-es-en/test.nah: 1000 sents, 32924 tokens, 0.115% replaced (by <unk>)\n",
      "2022-10-31 15:52:38 | INFO | fairseq_cli.preprocess | Wrote preprocessed data to /storage/master-thesis/models/capsnet__nah-es_es-en/tokenizers/nah-es-en/bin/\n"
     ]
    }
   ],
   "source": [
    "! fairseq-preprocess --source-lang $SRC_LANG --target-lang $TGT_LANG \\\n",
    "    --testpref $(eval echo $TOKENIZER_PATH)/test \\\n",
    "    --destdir $(eval echo $TOKENIZER_PATH)/bin/ \\\n",
    "    --workers 20 \\\n",
    "    --srcdict $(eval echo $TOKENIZER_PATH)/bin/dict.all.txt \\\n",
    "    --task translation_multi_simple_epoch \\\n",
    "    --joined-dictionary \\\n",
    "    --only-source"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-10-31 15:52:41 | INFO | fairseq_cli.generate | {'_name': None, 'common': {'_name': None, 'no_progress_bar': False, 'log_interval': 100, 'log_format': None, 'log_file': None, 'aim_repo': None, 'aim_run_hash': None, 'tensorboard_logdir': None, 'wandb_project': None, 'azureml_logging': False, 'seed': 1, 'cpu': False, 'tpu': False, 'bf16': False, 'memory_efficient_bf16': False, 'fp16': False, 'memory_efficient_fp16': False, 'fp16_no_flatten_grads': False, 'fp16_init_scale': 128, 'fp16_scale_window': None, 'fp16_scale_tolerance': 0.0, 'on_cpu_convert_precision': False, 'min_loss_scale': 0.0001, 'threshold_loss_scale': None, 'amp': False, 'amp_batch_retries': 2, 'amp_init_scale': 128, 'amp_scale_window': None, 'user_dir': '/storage/code/fairseq-dynamic-routing-plugin/examples/dynamic_routing/dynamic_routing_src/', 'empty_cache_freq': 0, 'all_gather_list_size': 16384, 'model_parallel_size': 1, 'quantization_config_path': None, 'profile': False, 'reset_logging': False, 'suppress_crashes': False, 'use_plasma_view': False, 'plasma_path': '/tmp/plasma'}, 'common_eval': {'_name': None, 'path': '/storage/master-thesis/models/capsnet__nah-es_es-en/checkpoint_best.pt', 'post_process': None, 'quiet': False, 'model_overrides': '{}', 'results_path': None}, 'distributed_training': {'_name': None, 'distributed_world_size': 1, 'distributed_num_procs': 1, 'distributed_rank': 0, 'distributed_backend': 'nccl', 'distributed_init_method': None, 'distributed_port': -1, 'device_id': 0, 'distributed_no_spawn': False, 'ddp_backend': 'pytorch_ddp', 'ddp_comm_hook': 'none', 'bucket_cap_mb': 25, 'fix_batches_to_gpus': False, 'find_unused_parameters': False, 'gradient_as_bucket_view': False, 'fast_stat_sync': False, 'heartbeat_timeout': -1, 'broadcast_buffers': False, 'slowmo_momentum': None, 'slowmo_base_algorithm': 'localsgd', 'localsgd_frequency': 3, 'nprocs_per_node': 1, 'pipeline_model_parallel': False, 'pipeline_balance': None, 'pipeline_devices': None, 'pipeline_chunks': 0, 'pipeline_encoder_balance': None, 'pipeline_encoder_devices': None, 'pipeline_decoder_balance': None, 'pipeline_decoder_devices': None, 'pipeline_checkpoint': 'never', 'zero_sharding': 'none', 'fp16': False, 'memory_efficient_fp16': False, 'tpu': False, 'no_reshard_after_forward': False, 'fp32_reduce_scatter': False, 'cpu_offload': False, 'use_sharded_state': False, 'not_fsdp_flatten_parameters': False}, 'dataset': {'_name': None, 'num_workers': 1, 'skip_invalid_size_inputs_valid_test': False, 'max_tokens': 6000, 'batch_size': None, 'required_batch_size_multiple': 8, 'required_seq_len_multiple': 1, 'dataset_impl': None, 'data_buffer_size': 10, 'train_subset': 'train', 'valid_subset': 'valid', 'combine_valid_subsets': None, 'ignore_unused_valid_subsets': False, 'validate_interval': 1, 'validate_interval_updates': 0, 'validate_after_updates': 0, 'fixed_validation_seed': None, 'disable_validation': False, 'max_tokens_valid': 6000, 'batch_size_valid': None, 'max_valid_steps': None, 'curriculum': 0, 'gen_subset': 'test', 'num_shards': 1, 'shard_id': 0, 'grouped_shuffling': False, 'update_epoch_batch_itr': False, 'update_ordered_indices_seed': False}, 'optimization': {'_name': None, 'max_epoch': 0, 'max_update': 0, 'stop_time_hours': 0.0, 'clip_norm': 0.0, 'sentence_avg': False, 'update_freq': [1], 'lr': [0.25], 'stop_min_lr': -1.0, 'use_bmuf': False, 'skip_remainder_batch': False}, 'checkpoint': {'_name': None, 'save_dir': 'checkpoints', 'restore_file': 'checkpoint_last.pt', 'continue_once': None, 'finetune_from_model': None, 'reset_dataloader': False, 'reset_lr_scheduler': False, 'reset_meters': False, 'reset_optimizer': False, 'optimizer_overrides': '{}', 'save_interval': 1, 'save_interval_updates': 0, 'keep_interval_updates': -1, 'keep_interval_updates_pattern': -1, 'keep_last_epochs': -1, 'keep_best_checkpoints': -1, 'no_save': False, 'no_epoch_checkpoints': False, 'no_last_checkpoints': False, 'no_save_optimizer_state': False, 'best_checkpoint_metric': 'loss', 'maximize_best_checkpoint_metric': False, 'patience': -1, 'checkpoint_suffix': '', 'checkpoint_shard_count': 1, 'load_checkpoint_on_all_dp_ranks': False, 'write_checkpoints_asynchronously': False, 'model_parallel_size': 1}, 'bmuf': {'_name': None, 'block_lr': 1.0, 'block_momentum': 0.875, 'global_sync_iter': 50, 'warmup_iterations': 500, 'use_nbm': False, 'average_sync': False, 'distributed_world_size': 1}, 'generation': {'_name': None, 'beam': 5, 'nbest': 1, 'max_len_a': 0.0, 'max_len_b': 200, 'min_len': 1, 'match_source_len': False, 'unnormalized': False, 'no_early_stop': False, 'no_beamable_mm': False, 'lenpen': 1.0, 'unkpen': 0.0, 'replace_unk': None, 'sacrebleu': False, 'score_reference': False, 'prefix_size': 0, 'no_repeat_ngram_size': 0, 'sampling': False, 'sampling_topk': -1, 'sampling_topp': -1.0, 'constraints': None, 'temperature': 1.0, 'diverse_beam_groups': -1, 'diverse_beam_strength': 0.5, 'diversity_rate': -1.0, 'print_alignment': 'hard', 'print_step': False, 'lm_path': None, 'lm_weight': 0.0, 'iter_decode_eos_penalty': 0.0, 'iter_decode_max_iter': 10, 'iter_decode_force_max_iter': False, 'iter_decode_with_beam': 1, 'iter_decode_with_external_reranker': False, 'retain_iter_history': False, 'retain_dropout': False, 'retain_dropout_modules': None, 'decoding_format': None, 'no_seed_provided': False, 'eos_token': None}, 'eval_lm': {'_name': None, 'output_word_probs': False, 'output_word_stats': False, 'context_window': 0, 'softmax_batch': 9223372036854775807}, 'interactive': {'_name': None, 'buffer_size': 0, 'input': '-'}, 'model': {'_name': 'wav2vec2', 'extractor_mode': 'default', 'encoder_layers': 12, 'encoder_embed_dim': 768, 'encoder_ffn_embed_dim': 3072, 'encoder_attention_heads': 12, 'activation_fn': 'gelu', 'layer_type': 'transformer', 'dropout': 0.1, 'attention_dropout': 0.1, 'activation_dropout': 0.0, 'encoder_layerdrop': 0.0, 'dropout_input': 0.0, 'dropout_features': 0.0, 'final_dim': 0, 'layer_norm_first': False, 'conv_feature_layers': '[(512, 10, 5)] + [(512, 3, 2)] * 4 + [(512,2,2)] + [(512,2,2)]', 'conv_bias': False, 'logit_temp': 0.1, 'quantize_targets': False, 'quantize_input': False, 'same_quantizer': False, 'target_glu': False, 'feature_grad_mult': 1.0, 'quantizer_depth': 1, 'quantizer_factor': 3, 'latent_vars': 320, 'latent_groups': 2, 'latent_dim': 0, 'mask_length': 10, 'mask_prob': 0.65, 'mask_selection': 'static', 'mask_other': 0.0, 'no_mask_overlap': False, 'mask_min_space': 1, 'require_same_masks': True, 'mask_dropout': 0.0, 'mask_channel_length': 10, 'mask_channel_prob': 0.0, 'mask_channel_before': False, 'mask_channel_selection': 'static', 'mask_channel_other': 0.0, 'no_mask_channel_overlap': False, 'mask_channel_min_space': 1, 'num_negatives': 100, 'negatives_from_everywhere': False, 'cross_sample_negatives': 0, 'codebook_negatives': 0, 'conv_pos': 128, 'conv_pos_groups': 16, 'pos_conv_depth': 1, 'latent_temp': [2.0, 0.5, 0.999995], 'max_positions': 100000, 'checkpoint_activations': False, 'required_seq_len_multiple': 1, 'crop_seq_to_multiple': 1, 'depthwise_conv_kernel_size': 31, 'attn_type': '', 'pos_enc_type': 'abs', 'fp16': False}, 'task': Namespace(_name='translation_multi_simple_epoch', aim_repo=None, aim_run_hash=None, all_gather_list_size=16384, amp=False, amp_batch_retries=2, amp_init_scale=128, amp_scale_window=None, arch='wav2vec2', azureml_logging=False, batch_size=None, batch_size_valid=None, beam=5, best_checkpoint_metric='loss', bf16=False, bpe=None, broadcast_buffers=False, bucket_cap_mb=25, checkpoint_shard_count=1, checkpoint_suffix='', combine_valid_subsets=None, constraints=None, continue_once=None, cpu=False, cpu_offload=False, criterion='cross_entropy', curriculum=0, data='/storage/master-thesis/models/capsnet__nah-es_es-en/tokenizers/nah-es-en/bin', data_buffer_size=10, dataset_impl=None, ddp_backend='pytorch_ddp', ddp_comm_hook='none', decoder_langtok=True, decoding_format=None, device_id=0, disable_validation=False, distributed_backend='nccl', distributed_init_method=None, distributed_no_spawn=False, distributed_num_procs=1, distributed_port=-1, distributed_rank=0, distributed_world_size=1, diverse_beam_groups=-1, diverse_beam_strength=0.5, diversity_rate=-1.0, empty_cache_freq=0, enable_lang_ids=False, enable_reservsed_directions_shared_datasets=False, encoder_langtok='src', eos=2, eos_token=None, extra_data=None, extra_lang_pairs=None, fast_stat_sync=False, find_unused_parameters=False, finetune_from_model=None, fix_batches_to_gpus=False, fixed_dictionary=None, fixed_validation_seed=None, force_anneal=None, fp16=False, fp16_init_scale=128, fp16_no_flatten_grads=False, fp16_scale_tolerance=0.0, fp16_scale_window=None, fp32_reduce_scatter=False, gen_subset='test', gradient_as_bucket_view=False, grouped_shuffling=False, heartbeat_timeout=-1, ignore_unused_valid_subsets=False, iter_decode_eos_penalty=0.0, iter_decode_force_max_iter=False, iter_decode_max_iter=10, iter_decode_with_beam=1, iter_decode_with_external_reranker=False, keep_best_checkpoints=-1, keep_inference_langtok=False, keep_interval_updates=-1, keep_interval_updates_pattern=-1, keep_last_epochs=-1, lang_dict=None, lang_pairs='nah-es,es-en', lang_tok_replacing_bos_eos=False, lang_tok_style='multilingual', langs=None, langtoks=None, langtoks_specs=['main'], left_pad_source='True', left_pad_target='False', lenpen=1, lm_path=None, lm_weight=0.0, load_alignments=False, load_checkpoint_on_all_dp_ranks=False, localsgd_frequency=3, log_file=None, log_format=None, log_interval=100, lr_scheduler='fixed', lr_shrink=0.1, match_source_len=False, max_len_a=0, max_len_b=200, max_source_positions=1024, max_target_positions=1024, max_tokens=6000, max_tokens_valid=6000, max_valid_steps=None, maximize_best_checkpoint_metric=False, memory_efficient_bf16=False, memory_efficient_fp16=False, min_len=1, min_loss_scale=0.0001, model_overrides='{}', model_parallel_size=1, nbest=1, no_beamable_mm=False, no_early_stop=False, no_epoch_checkpoints=False, no_last_checkpoints=False, no_progress_bar=False, no_repeat_ngram_size=0, no_reshard_after_forward=False, no_save=False, no_save_optimizer_state=False, no_seed_provided=False, not_fsdp_flatten_parameters=False, nprocs_per_node=1, num_shards=1, num_workers=1, on_cpu_convert_precision=False, optimizer=None, optimizer_overrides='{}', pad=1, path='/storage/master-thesis/models/capsnet__nah-es_es-en/checkpoint_best.pt', patience=-1, pipeline_balance=None, pipeline_checkpoint='never', pipeline_chunks=0, pipeline_decoder_balance=None, pipeline_decoder_devices=None, pipeline_devices=None, pipeline_encoder_balance=None, pipeline_encoder_devices=None, pipeline_model_parallel=False, plasma_path='/tmp/plasma', post_process=None, prefix_size=0, print_alignment='hard', print_step=False, profile=False, quantization_config_path=None, quiet=False, replace_unk=None, required_batch_size_multiple=8, required_seq_len_multiple=1, reset_dataloader=False, reset_logging=False, reset_lr_scheduler=False, reset_meters=False, reset_optimizer=False, restore_file='checkpoint_last.pt', results_path=None, retain_dropout=False, retain_dropout_modules=None, retain_iter_history=False, sacrebleu=False, sampling=False, sampling_method='concat', sampling_temperature=1.5, sampling_topk=-1, sampling_topp=-1.0, sampling_weights=None, sampling_weights_from_file=None, save_dir='checkpoints', save_interval=1, save_interval_updates=0, score_reference=False, scoring='bleu', seed=1, shard_id=0, skip_invalid_size_inputs_valid_test=False, slowmo_base_algorithm='localsgd', slowmo_momentum=None, source_dict=None, source_lang='nah', suppress_crashes=False, target_dict=None, target_lang='en', task='translation_multi_simple_epoch', temperature=1.0, tensorboard_logdir=None, threshold_loss_scale=None, tokenizer=None, tpu=False, train_subset='train', truncate_source=False, unk=3, unkpen=0, unnormalized=False, update_epoch_batch_itr=False, update_ordered_indices_seed=False, upsample_primary=1, use_plasma_view=False, use_sharded_state=False, user_dir='/storage/code/fairseq-dynamic-routing-plugin/examples/dynamic_routing/dynamic_routing_src/', valid_subset='valid', validate_after_updates=0, validate_interval=1, validate_interval_updates=0, virtual_data_size=None, virtual_epoch_size=None, wandb_project=None, warmup_updates=0, write_checkpoints_asynchronously=False, zero_sharding='none'), 'criterion': {'_name': 'cross_entropy', 'sentence_avg': True}, 'optimizer': None, 'lr_scheduler': {'_name': 'fixed', 'force_anneal': None, 'lr_shrink': 0.1, 'warmup_updates': 0, 'lr': [0.25]}, 'scoring': {'_name': 'bleu', 'pad': 1, 'eos': 2, 'unk': 3}, 'bpe': None, 'tokenizer': None, 'ema': {'_name': None, 'store_ema': False, 'ema_decay': 0.9999, 'ema_start_update': 0, 'ema_seed_model': None, 'ema_update_freq': 1, 'ema_fp32': False}}\n",
      "2022-10-31 15:52:41 | WARNING | fairseq.data.multilingual.multilingual_data_manager | External language dictionary is not provided; use lang-pairs to infer the set of supported languages. The language ordering is not stable which might cause misalignment in pretraining and finetuning.\n",
      "2022-10-31 15:52:41 | INFO | fairseq.data.multilingual.multilingual_data_manager | inferred language list: ['en', 'es', 'nah']\n",
      "2022-10-31 15:52:41 | INFO | fairseq.data.multilingual.multilingual_data_manager | [nah] dictionary: 28915 types\n",
      "2022-10-31 15:52:41 | INFO | fairseq.data.multilingual.multilingual_data_manager | [en] dictionary: 28915 types\n",
      "2022-10-31 15:52:41 | INFO | fairseq_cli.generate | loading model(s) from /storage/master-thesis/models/capsnet__nah-es_es-en/checkpoint_best.pt\n",
      "2022-10-31 15:52:43 | INFO | fairseq.tasks.translation_multi_simple_epoch | loading data for test epoch=1/None\n",
      "2022-10-31 15:52:43 | INFO | fairseq.tasks.translation_multi_simple_epoch | mem usage: N/A\n",
      "2022-10-31 15:52:43 | INFO | fairseq.data.multilingual.multilingual_data_manager | langtoks settings: {'main': ('src', 'tgt')}\n",
      "2022-10-31 15:52:43 | INFO | fairseq.data.multilingual.multilingual_data_manager | [test] num of shards: {'main:nah-en': 1}\n",
      "2022-10-31 15:52:43 | INFO | fairseq.data.multilingual.multilingual_data_manager | main:nah-en src_langtok: 28914; tgt_langtok: 28912\n",
      "2022-10-31 15:52:43 | INFO | fairseq.data.data_utils | loaded 1,000 examples from: /storage/master-thesis/models/capsnet__nah-es_es-en/tokenizers/nah-es-en/bin/test.nah-en.nah\n",
      "2022-10-31 15:52:43 | INFO | fairseq.data.multilingual.multilingual_data_manager | /storage/master-thesis/models/capsnet__nah-es_es-en/tokenizers/nah-es-en/bin test nah-en 1000 examples\n",
      "2022-10-31 15:52:48 | INFO | fairseq.tasks.translation_multi_simple_epoch | start batch sampler: mem usage: N/A\n",
      "2022-10-31 15:52:48 | INFO | fairseq.tasks.translation_multi_simple_epoch | [test] @batch_sampler order indices time: 0:00:00.000546\n",
      "2022-10-31 15:52:48 | INFO | fairseq.tasks.translation_multi_simple_epoch | mem usage: N/A\n",
      "2022-10-31 15:52:48 | INFO | fairseq.tasks.translation_multi_simple_epoch | [test] @batch_sampler filter_by_size time: 0:00:00.005409\n",
      "2022-10-31 15:52:48 | INFO | fairseq.tasks.translation_multi_simple_epoch | mem usage: N/A\n",
      "2022-10-31 15:52:48 | INFO | fairseq.tasks.translation_multi_simple_epoch | [test] @batch_sampler batch_by_size time: 0:00:00.005954\n",
      "2022-10-31 15:52:48 | INFO | fairseq.tasks.translation_multi_simple_epoch | [test] per epoch batch_sampler set-up time: 0:00:00.012373\n",
      "2022-10-31 15:52:48 | INFO | fairseq.tasks.translation_multi_simple_epoch | mem usage: N/A\n",
      "2022-10-31 15:53:03 | INFO | fairseq_cli.generate | NOTE: hypothesis and token scores are output in base 2����| 7/7 [00:14<00:00,  2.20s/it, wps=1531]\n",
      "2022-10-31 15:53:03 | INFO | fairseq_cli.generate | Translated 1,000 sentences (22,601 tokens) in 11.5s (87.23 sentences/s, 1971.49 tokens/s)\n"
     ]
    }
   ],
   "source": [
    "! PYTHONIOENCODING=utf-8 fairseq-generate $(eval echo $TOKENIZER_PATH)/bin \\\n",
    "    --path $(eval echo $MODEL_DIR)/checkpoint_best.pt  \\\n",
    "    $(eval echo $MODEL_PARAM) \\\n",
    "    --source-lang $SRC_LANG --target-lang $TGT_LANG \\\n",
    "    --max-tokens 6000 \\\n",
    "    --task translation_multi_simple_epoch \\\n",
    "    --encoder-langtok \"src\" \\\n",
    "    --decoder-langtok \\\n",
    "    --lang-pairs $LANG_PAIRS \\\n",
    "    --print-alignment > $(eval echo $MODEL_DIR)/${SRC_LANG}_${TGT_LANG}.${TGT_LANG}.out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "!cat $(eval echo $MODEL_DIR)/${SRC_LANG}_${TGT_LANG}.${TGT_LANG}.out | grep -P \"^H\" |sort -V |cut -f 3- | sed \"s/ ##//g\" > $(eval echo $MODEL_DIR)/${SRC_LANG}_${TGT_LANG}.${TGT_LANG}.hyp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "gold_lines=[]\n",
    "with open(src_tgt_test_corpus + \"test.\" + tgt_lang, encoding='utf8') as f:\n",
    "  gold_lines = f.readlines()\n",
    "  gold_lines = [x.strip(\"\\n\") for x in gold_lines]\n",
    "\n",
    "\n",
    "system_lines = []\n",
    "with open(model_dir + src_lang + \"_\" + tgt_lang + \".\" + tgt_lang + \".hyp\", encoding='utf8') as f:\n",
    "  system_lines = f.readlines()\n",
    "  system_lines = [x.strip(\"\\n\") for x in system_lines]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "blanks = []\n",
    "for i in range(0,len(gold_lines)):\n",
    "    if gold_lines[i] == \"\":\n",
    "        blanks.append(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[]\n",
      "[]\n"
     ]
    }
   ],
   "source": [
    "print(blanks)\n",
    "blanks.reverse()\n",
    "print(blanks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in blanks:\n",
    "    del gold_lines[i]\n",
    "    del system_lines[i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000\n",
      "1000\n"
     ]
    }
   ],
   "source": [
    "print(len(gold_lines))\n",
    "print(len(system_lines))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Countless millions, their number known only to God, will live again.\n",
      "\n",
      "Después mucho tu corazón se expresa , y nomás se lo deja con su corazón .\n"
     ]
    }
   ],
   "source": [
    "print(gold_lines[100])\n",
    "print()\n",
    "print(system_lines[100])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SCORE SRC->TGT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "That's 100 lines that end in a tokenized period ('.')\n",
      "It looks like you forgot to detokenize your test data, which may hurt your score.\n",
      "If you insist your data is detokenized, or don't care, you can suppress this message with the `force` parameter.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#### Score Report ####\n",
      "chrF2 = 13.18\n",
      "BLEU = 0.76 12.7/1.0/0.3/0.1 (BP = 0.945 ratio = 0.947 hyp_len = 17863 ref_len = 18871)\n"
     ]
    }
   ],
   "source": [
    "calculate_score_report(system_lines, [gold_lines], score_only=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
