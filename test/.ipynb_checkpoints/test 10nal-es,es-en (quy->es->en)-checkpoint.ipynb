{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## test general zero-shot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: tokenizers in /usr/local/lib/python3.6/dist-packages (0.10.3)\n",
      "\u001b[33mWARNING: You are using pip version 20.2.4; however, version 21.3.1 is available.\n",
      "You should consider upgrading via the '/usr/bin/python3 -m pip install --upgrade pip' command.\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install tokenizers\n",
    "pip uninstall torch torchvision torchaudio -y\n",
    "pip uninstall fairseq -y\n",
    "pip install torch torchvision torchaudio --extra-index-url https://download.pytorch.org/whl/cu113\n",
    "pip install fairseq # --no-deps\n",
    "! pip uninstall apex -y\n",
    "rm -r apex\n",
    "! pip install -v --disable-pip-version-check --no-cache-dir apex\n",
    "pip install tensorboardX"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "env: CODE_STORAGE=/storage/code\n"
     ]
    }
   ],
   "source": [
    "%env CODE_STORAGE = /storage/code "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "env: MODEL_PARAM=\"--seed 1\" # std transformer\n"
     ]
    }
   ],
   "source": [
    "%env MODEL_PARAM = \"--seed 1\" # std transformer\n",
    "#%env MODEL_PARAM = \"--user-dir $CODE_STORAGE/fairseq/examples/residual_drop/residual_drop_src/\" #resdrop\n",
    "#%env MODEL_PARAM = \"--user-dir /storage/code/fairseq-dynamic-routing-plugin/examples/dynamic_routing/dynamic_routing_src/\" #capsnet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "env: MODEL_NAME=10nal-es_es-en\n",
      "env: LANG_PAIRS=quy-es,cni-es,aym-es,bzd-es,gn-es,oto-es,nah-es,tar-es,shp-es,hch-es,es-en\n",
      "env: TOKENIZER_LANGS=10nal-es-en\n",
      "env: SRC_LANG=nah\n",
      "env: PIV_LANG=es\n",
      "env: TGT_LANG=en\n"
     ]
    }
   ],
   "source": [
    "%env MODEL_NAME = 10nal-es_es-en\n",
    "%env LANG_PAIRS = quy-es,cni-es,aym-es,bzd-es,gn-es,oto-es,nah-es,tar-es,shp-es,hch-es,es-en\n",
    "%env TOKENIZER_LANGS = 10nal-es-en\n",
    "%env SRC_LANG = nah\n",
    "%env PIV_LANG = es\n",
    "%env TGT_LANG = en"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = \"10nal-es_es-en\"\n",
    "tokenizer_langs = \"10nal-es-en\"\n",
    "src_lang = \"nah\"\n",
    "piv_lang = \"es\"\n",
    "tgt_lang = \"en\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "env: MODELS_DIR=/storage/master-thesis/models\n"
     ]
    }
   ],
   "source": [
    "%env MODELS_DIR = /storage/master-thesis/models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "models_dir = \"/storage/master-thesis/models/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpora = {}\n",
    "\n",
    "corpora[('en','de')] = \"/notebooks/master-thesis/corpora/iwslt17/de-en/\"\n",
    "corpora[('it','de')] = \"/notebooks/master-thesis/corpora/iwslt17/de-it/\"\n",
    "corpora[('nl','de')] = \"/notebooks/master-thesis/corpora/iwslt17/de-nl/\"\n",
    "corpora[('ro','de')] = \"/notebooks/master-thesis/corpora/iwslt17/de-ro/\"\n",
    "corpora[('it','en')] = \"/notebooks/master-thesis/corpora/iwslt17/en-it/\"\n",
    "corpora[('nl','en')] = \"/notebooks/master-thesis/corpora/iwslt17/en-nl/\"\n",
    "corpora[('ro','en')] = \"/notebooks/master-thesis/corpora/iwslt17/en-ro/\"\n",
    "#corpora[('it','nl')] = \"/notebooks/master-thesis/corpora/iwslt17/it-nl/\"\n",
    "#corpora[('it','ro')] = \"/notebooks/master-thesis/corpora/iwslt17/it-ro/\"\n",
    "#corpora[('nl','ro')] = \"/notebooks/master-thesis/corpora/iwslt17/nl-ro/\"\n",
    "\n",
    "\n",
    "\n",
    "#en_es_corpus_dir = \"/notebooks/master-thesis/corpora/tatoeba-challenge/en-es/\" #not needed\n",
    "\n",
    "corpora[('aym','es')] = \"/notebooks/master-thesis/corpora/americasnlp2021/data/aymara-spanish/\"\n",
    "corpora[('cni','es')] = \"/notebooks/master-thesis/corpora/americasnlp2021/data/ashaninka-spanish/\"\n",
    "corpora[('bzd','es')] = \"/notebooks/master-thesis/corpora/americasnlp2021/data/bribri-spanish/\"\n",
    "corpora[('gn','es')] = \"/notebooks/master-thesis/corpora/americasnlp2021/data/guarani-spanish/\"\n",
    "corpora[('oto','es')] = \"/notebooks/master-thesis/corpora/americasnlp2021/data/hnahnu-spanish/\"\n",
    "corpora[('nah','es')] = \"/notebooks/master-thesis/corpora/americasnlp2021/data/nahuatl-spanish/\"\n",
    "corpora[('quy','es')] = \"/notebooks/master-thesis/corpora/americasnlp2021/data/quechua-spanish/\"\n",
    "corpora[('tar','es')] = \"/notebooks/master-thesis/corpora/americasnlp2021/data/raramuri-spanish/\"\n",
    "corpora[('shp','es')] = \"/notebooks/master-thesis/corpora/americasnlp2021/data/shipibo_konibo-spanish/\"\n",
    "corpora[('hch','es')] = \"/notebooks/master-thesis/corpora/americasnlp2021/data/wixarika-spanish/\"\n",
    "\n",
    "corpora[('quy','en')] = \"/notebooks/master-thesis/corpora/jw300/en-quy/\"\n",
    "corpora[('aym','en')] = \"/notebooks/master-thesis/corpora/jw300/aym-en/\"\n",
    "corpora[('nah','en')] = \"/notebooks/master-thesis/corpora/tatoeba-challenge/en-nah/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%env DE_EN_CORPUS_DIR = /notebooks/master-thesis/corpora/iwslt17/de-en\n",
    "#%env DE_IT_CORPUS_DIR = /notebooks/master-thesis/corpora/iwslt17/de-it\n",
    "#%env DE_NL_CORPUS_DIR = /notebooks/master-thesis/corpora/iwslt17/de-nl\n",
    "#%env DE_RO_CORPUS_DIR = /notebooks/master-thesis/corpora/iwslt17/de-ro\n",
    "#%env EN_IT_CORPUS_DIR = /notebooks/master-thesis/corpora/iwslt17/en-it\n",
    "#%env EN_NL_CORPUS_DIR = /notebooks/master-thesis/corpora/iwslt17/en-nl\n",
    "#%env EN_RO_CORPUS_DIR = /notebooks/master-thesis/corpora/iwslt17/en-ro\n",
    "#%env IT_NL_CORPUS_DIR = /notebooks/master-thesis/corpora/iwslt17/it-nl\n",
    "#%env IT_RO_CORPUS_DIR = /notebooks/master-thesis/corpora/iwslt17/it-ro\n",
    "#%env NL_RO_CORPUS_DIR = /notebooks/master-thesis/corpora/iwslt17/nl-ro\n",
    "\n",
    "#%env EN_ES_CORPUS_DIR = /notebooks/master-thesis/corpora/tatoeba-challenge/en-es\n",
    "\n",
    "#%env AYM_ES_CORPUS_DIR = /notebooks/master-thesis/corpora/americasnlp2021/data/aymara-spanish\n",
    "#%env CNI_ES_CORPUS_DIR = /notebooks/master-thesis/corpora/americasnlp2021/data/ashaninka-spanish\n",
    "#%env BZD_ES_CORPUS_DIR = /notebooks/master-thesis/corpora/americasnlp2021/data/bribri-spanish\n",
    "#%env GN_ES_CORPUS_DIR = /notebooks/master-thesis/corpora/americasnlp2021/data/guarani-spanish\n",
    "#%env OTO_ES_CORPUS_DIR = /notebooks/master-thesis/corpora/americasnlp2021/data/hnahnu-spanish\n",
    "#%env NAH_ES_CORPUS_DIR = /notebooks/master-thesis/corpora/americasnlp2021/data/nahuatl-spanish\n",
    "#%env QUY_ES_CORPUS_DIR = /notebooks/master-thesis/corpora/americasnlp2021/data/quechua-spanish\n",
    "#%env TAR_ES_CORPUS_DIR = /notebooks/master-thesis/corpora/americasnlp2021/data/raramuri-spanish\n",
    "#%env SHP_ES_CORPUS_DIR = /notebooks/master-thesis/corpora/americasnlp2021/data/shipibo_konibo-spanish\n",
    "#%env HCH_ES_CORPUS_DIR = /notebooks/master-thesis/corpora/americasnlp2021/data/wixarika-spanish\n",
    "\n",
    "#%env QUY_EN_CORPUS_DIR = /notebooks/master-thesis/corpora/jw300/en-quy\n",
    "\n",
    "#%env AYM_EN_CORPUS_DIR = /notebooks/master-thesis/corpora/jw300/aym-en\n",
    "#%env NAH_EN_CORPUS_DIR = /notebooks/master-thesis/corpora/tatoeba-challenge/en-nah"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%env SRC_PIV_TEST_CORPUS = $(eval echo $(eval echo NL)_EN_CORPUS_DIR)\n",
    "#%env PIV_TGT_TEST_CORPUS = $EN_ES_CORPUS_DIR\n",
    "#%env SRC_TGT_TEST_CORPUS = $AYM_EN_CORPUS_DIR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "src_piv_test_corpus = corpora[(src_lang,piv_lang)]\n",
    "#piv_tgt_test_corpus = en_es_corpus_dir\n",
    "src_tgt_test_corpus = corpora[(src_lang,tgt_lang)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer_path = models_dir + model_name + \"/tokenizers/\" + tokenizer_langs + \"/\"\n",
    "tokenizer_name = tokenizer_langs + \"-tokenizer.json\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/storage/master-thesis/models/10nal-es_es-en/tokenizers/10nal-es-en/10nal-es-en-tokenizer.json\n"
     ]
    }
   ],
   "source": [
    "print(tokenizer_path + tokenizer_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "env: TOKENIZER_PATH=${MODELS_DIR}/${MODEL_NAME}/tokenizers/${TOKENIZER_LANGS}\n"
     ]
    }
   ],
   "source": [
    "%env TOKENIZER_PATH = ${MODELS_DIR}/${MODEL_NAME}/tokenizers/${TOKENIZER_LANGS}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "env: MODEL_DIR=${MODELS_DIR}/${MODEL_NAME}\n"
     ]
    }
   ],
   "source": [
    "%env MODEL_DIR = ${MODELS_DIR}/${MODEL_NAME}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_dir = models_dir+model_name+\"/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/storage/master-thesis/models/10nal-es_es-en/tokenizers/10nal-es-en/10nal-es-en-tokenizer.json\n"
     ]
    }
   ],
   "source": [
    "print(tokenizer_path + tokenizer_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tokenizers import Tokenizer\n",
    "from tokenizers.models import WordPiece\n",
    "\n",
    "tokenizer = Tokenizer.from_file(tokenizer_path + tokenizer_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "def tokenize_files(tokenizer, files, extension, output_path):\n",
    "    for file in files:\n",
    "        print(f\"Reading file {file}\")\n",
    "        with open(file, encoding='utf8') as f:\n",
    "          lines = f.readlines()\n",
    "          tokenized_lines = tokenizer.encode_batch(lines)\n",
    "          tokenized_name = Path(file).stem\n",
    "          tokenized_name = output_path + tokenized_name + \".\" + extension\n",
    "          print(tokenized_name)\n",
    "          with open(tokenized_name, 'w', encoding='utf8') as wf:\n",
    "\n",
    "            wf.writelines([\" \".join(t.tokens) + \"\\n\" for t in tokenized_lines])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Una', '-', 'unay', 'wataña', 'churasqa', 'kaspan', '##tin', 'sara', '##ta', 'tarisqan', '##kum', '(', 'han', '##aypi', 'rikuris', '##qan', '##man', 'hina', ')', 'qawachin', ',', 'kay', 'nacionpa', 'norte', 'lawninpi', 'runakunaqa', '3', '.', '000', 'wata', 'ñawpaqtaraq', 'sara', '##manta', 'harina', '##ta', 'hinaspa', 'ham', '##kata', 'miku', '##sqa', '##n', '##kuta', '.']\n"
     ]
    }
   ],
   "source": [
    "tok = tokenizer.encode(\"Una - unay wataña churasqa kaspantin sarata tarisqankum (hanaypi rikurisqanman hina) qawachin, kay nacionpa norte lawninpi runakunaqa 3.000 wata ñawpaqtaraq saramanta harinata hinaspa hamkata mikusqankuta.\"\n",
    ")\n",
    "print(tok.tokens)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testing src->piv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading file /notebooks/master-thesis/corpora/americasnlp2021/data/nahuatl-spanish/test.nah\n",
      "/storage/master-thesis/models/10nal-es_es-en/tokenizers/10nal-es-en/test.nah\n"
     ]
    }
   ],
   "source": [
    "tokenize_files(tokenizer, [src_piv_test_corpus + 'test.' + src_lang], src_lang, tokenizer_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-11-01 21:11:41 | INFO | fairseq_cli.preprocess | Namespace(aim_repo=None, aim_run_hash=None, align_suffix=None, alignfile=None, all_gather_list_size=16384, amp=False, amp_batch_retries=2, amp_init_scale=128, amp_scale_window=None, azureml_logging=False, bf16=False, bpe=None, cpu=False, criterion='cross_entropy', dataset_impl='mmap', destdir='/storage/master-thesis/models/10nal-es_es-en/tokenizers/10nal-es-en/bin/', dict_only=False, empty_cache_freq=0, fp16=False, fp16_init_scale=128, fp16_no_flatten_grads=False, fp16_scale_tolerance=0.0, fp16_scale_window=None, joined_dictionary=True, log_file=None, log_format=None, log_interval=100, lr_scheduler='fixed', memory_efficient_bf16=False, memory_efficient_fp16=False, min_loss_scale=0.0001, model_parallel_size=1, no_progress_bar=False, nwordssrc=-1, nwordstgt=-1, on_cpu_convert_precision=False, only_source=True, optimizer=None, padding_factor=8, plasma_path='/tmp/plasma', profile=False, quantization_config_path=None, reset_logging=False, scoring='bleu', seed=1, source_lang='nah', srcdict='/storage/master-thesis/models/10nal-es_es-en/tokenizers/10nal-es-en/bin/dict.all.txt', suppress_crashes=False, target_lang='es', task='translation_multi_simple_epoch', tensorboard_logdir=None, testpref='/storage/master-thesis/models/10nal-es_es-en/tokenizers/10nal-es-en/test', tgtdict=None, threshold_loss_scale=None, thresholdsrc=0, thresholdtgt=0, tokenizer=None, tpu=False, trainpref=None, use_plasma_view=False, user_dir=None, validpref=None, wandb_project=None, workers=20)\n",
      "2022-11-01 21:11:41 | INFO | fairseq_cli.preprocess | [nah] Dictionary: 29288 types\n",
      "2022-11-01 21:11:42 | INFO | fairseq_cli.preprocess | [nah] /storage/master-thesis/models/10nal-es_es-en/tokenizers/10nal-es-en/test.nah: 1003 sents, 16297 tokens, 0.184% replaced (by <unk>)\n",
      "2022-11-01 21:11:42 | INFO | fairseq_cli.preprocess | Wrote preprocessed data to /storage/master-thesis/models/10nal-es_es-en/tokenizers/10nal-es-en/bin/\n"
     ]
    }
   ],
   "source": [
    "! fairseq-preprocess --source-lang $SRC_LANG --target-lang $PIV_LANG \\\n",
    "    --testpref $(eval echo $TOKENIZER_PATH)/test \\\n",
    "    --destdir $(eval echo $TOKENIZER_PATH)/bin/ \\\n",
    "    --workers 20 \\\n",
    "    --srcdict $(eval echo $TOKENIZER_PATH)/bin/dict.all.txt \\\n",
    "    --task translation_multi_simple_epoch \\\n",
    "    --joined-dictionary \\\n",
    "    --only-source"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-11-01 21:11:45 | INFO | fairseq_cli.generate | {'_name': None, 'common': {'_name': None, 'no_progress_bar': False, 'log_interval': 100, 'log_format': None, 'log_file': None, 'aim_repo': None, 'aim_run_hash': None, 'tensorboard_logdir': None, 'wandb_project': None, 'azureml_logging': False, 'seed': 1, 'cpu': False, 'tpu': False, 'bf16': False, 'memory_efficient_bf16': False, 'fp16': False, 'memory_efficient_fp16': False, 'fp16_no_flatten_grads': False, 'fp16_init_scale': 128, 'fp16_scale_window': None, 'fp16_scale_tolerance': 0.0, 'on_cpu_convert_precision': False, 'min_loss_scale': 0.0001, 'threshold_loss_scale': None, 'amp': False, 'amp_batch_retries': 2, 'amp_init_scale': 128, 'amp_scale_window': None, 'user_dir': None, 'empty_cache_freq': 0, 'all_gather_list_size': 16384, 'model_parallel_size': 1, 'quantization_config_path': None, 'profile': False, 'reset_logging': False, 'suppress_crashes': False, 'use_plasma_view': False, 'plasma_path': '/tmp/plasma'}, 'common_eval': {'_name': None, 'path': '/storage/master-thesis/models/10nal-es_es-en/checkpoint_best.pt', 'post_process': None, 'quiet': False, 'model_overrides': '{}', 'results_path': None}, 'distributed_training': {'_name': None, 'distributed_world_size': 1, 'distributed_num_procs': 1, 'distributed_rank': 0, 'distributed_backend': 'nccl', 'distributed_init_method': None, 'distributed_port': -1, 'device_id': 0, 'distributed_no_spawn': False, 'ddp_backend': 'pytorch_ddp', 'ddp_comm_hook': 'none', 'bucket_cap_mb': 25, 'fix_batches_to_gpus': False, 'find_unused_parameters': False, 'gradient_as_bucket_view': False, 'fast_stat_sync': False, 'heartbeat_timeout': -1, 'broadcast_buffers': False, 'slowmo_momentum': None, 'slowmo_base_algorithm': 'localsgd', 'localsgd_frequency': 3, 'nprocs_per_node': 1, 'pipeline_model_parallel': False, 'pipeline_balance': None, 'pipeline_devices': None, 'pipeline_chunks': 0, 'pipeline_encoder_balance': None, 'pipeline_encoder_devices': None, 'pipeline_decoder_balance': None, 'pipeline_decoder_devices': None, 'pipeline_checkpoint': 'never', 'zero_sharding': 'none', 'fp16': False, 'memory_efficient_fp16': False, 'tpu': False, 'no_reshard_after_forward': False, 'fp32_reduce_scatter': False, 'cpu_offload': False, 'use_sharded_state': False, 'not_fsdp_flatten_parameters': False}, 'dataset': {'_name': None, 'num_workers': 1, 'skip_invalid_size_inputs_valid_test': False, 'max_tokens': 6000, 'batch_size': None, 'required_batch_size_multiple': 8, 'required_seq_len_multiple': 1, 'dataset_impl': None, 'data_buffer_size': 10, 'train_subset': 'train', 'valid_subset': 'valid', 'combine_valid_subsets': None, 'ignore_unused_valid_subsets': False, 'validate_interval': 1, 'validate_interval_updates': 0, 'validate_after_updates': 0, 'fixed_validation_seed': None, 'disable_validation': False, 'max_tokens_valid': 6000, 'batch_size_valid': None, 'max_valid_steps': None, 'curriculum': 0, 'gen_subset': 'test', 'num_shards': 1, 'shard_id': 0, 'grouped_shuffling': False, 'update_epoch_batch_itr': False, 'update_ordered_indices_seed': False}, 'optimization': {'_name': None, 'max_epoch': 0, 'max_update': 0, 'stop_time_hours': 0.0, 'clip_norm': 0.0, 'sentence_avg': False, 'update_freq': [1], 'lr': [0.25], 'stop_min_lr': -1.0, 'use_bmuf': False, 'skip_remainder_batch': False}, 'checkpoint': {'_name': None, 'save_dir': 'checkpoints', 'restore_file': 'checkpoint_last.pt', 'continue_once': None, 'finetune_from_model': None, 'reset_dataloader': False, 'reset_lr_scheduler': False, 'reset_meters': False, 'reset_optimizer': False, 'optimizer_overrides': '{}', 'save_interval': 1, 'save_interval_updates': 0, 'keep_interval_updates': -1, 'keep_interval_updates_pattern': -1, 'keep_last_epochs': -1, 'keep_best_checkpoints': -1, 'no_save': False, 'no_epoch_checkpoints': False, 'no_last_checkpoints': False, 'no_save_optimizer_state': False, 'best_checkpoint_metric': 'loss', 'maximize_best_checkpoint_metric': False, 'patience': -1, 'checkpoint_suffix': '', 'checkpoint_shard_count': 1, 'load_checkpoint_on_all_dp_ranks': False, 'write_checkpoints_asynchronously': False, 'model_parallel_size': 1}, 'bmuf': {'_name': None, 'block_lr': 1.0, 'block_momentum': 0.875, 'global_sync_iter': 50, 'warmup_iterations': 500, 'use_nbm': False, 'average_sync': False, 'distributed_world_size': 1}, 'generation': {'_name': None, 'beam': 5, 'nbest': 1, 'max_len_a': 0.0, 'max_len_b': 200, 'min_len': 1, 'match_source_len': False, 'unnormalized': False, 'no_early_stop': False, 'no_beamable_mm': False, 'lenpen': 1.0, 'unkpen': 0.0, 'replace_unk': None, 'sacrebleu': False, 'score_reference': False, 'prefix_size': 0, 'no_repeat_ngram_size': 0, 'sampling': False, 'sampling_topk': -1, 'sampling_topp': -1.0, 'constraints': None, 'temperature': 1.0, 'diverse_beam_groups': -1, 'diverse_beam_strength': 0.5, 'diversity_rate': -1.0, 'print_alignment': 'hard', 'print_step': False, 'lm_path': None, 'lm_weight': 0.0, 'iter_decode_eos_penalty': 0.0, 'iter_decode_max_iter': 10, 'iter_decode_force_max_iter': False, 'iter_decode_with_beam': 1, 'iter_decode_with_external_reranker': False, 'retain_iter_history': False, 'retain_dropout': False, 'retain_dropout_modules': None, 'decoding_format': None, 'no_seed_provided': False, 'eos_token': None}, 'eval_lm': {'_name': None, 'output_word_probs': False, 'output_word_stats': False, 'context_window': 0, 'softmax_batch': 9223372036854775807}, 'interactive': {'_name': None, 'buffer_size': 0, 'input': '-'}, 'model': {'_name': 'wav2vec2', 'extractor_mode': 'default', 'encoder_layers': 12, 'encoder_embed_dim': 768, 'encoder_ffn_embed_dim': 3072, 'encoder_attention_heads': 12, 'activation_fn': 'gelu', 'layer_type': 'transformer', 'dropout': 0.1, 'attention_dropout': 0.1, 'activation_dropout': 0.0, 'encoder_layerdrop': 0.0, 'dropout_input': 0.0, 'dropout_features': 0.0, 'final_dim': 0, 'layer_norm_first': False, 'conv_feature_layers': '[(512, 10, 5)] + [(512, 3, 2)] * 4 + [(512,2,2)] + [(512,2,2)]', 'conv_bias': False, 'logit_temp': 0.1, 'quantize_targets': False, 'quantize_input': False, 'same_quantizer': False, 'target_glu': False, 'feature_grad_mult': 1.0, 'quantizer_depth': 1, 'quantizer_factor': 3, 'latent_vars': 320, 'latent_groups': 2, 'latent_dim': 0, 'mask_length': 10, 'mask_prob': 0.65, 'mask_selection': 'static', 'mask_other': 0.0, 'no_mask_overlap': False, 'mask_min_space': 1, 'require_same_masks': True, 'mask_dropout': 0.0, 'mask_channel_length': 10, 'mask_channel_prob': 0.0, 'mask_channel_before': False, 'mask_channel_selection': 'static', 'mask_channel_other': 0.0, 'no_mask_channel_overlap': False, 'mask_channel_min_space': 1, 'num_negatives': 100, 'negatives_from_everywhere': False, 'cross_sample_negatives': 0, 'codebook_negatives': 0, 'conv_pos': 128, 'conv_pos_groups': 16, 'pos_conv_depth': 1, 'latent_temp': [2.0, 0.5, 0.999995], 'max_positions': 100000, 'checkpoint_activations': False, 'required_seq_len_multiple': 1, 'crop_seq_to_multiple': 1, 'depthwise_conv_kernel_size': 31, 'attn_type': '', 'pos_enc_type': 'abs', 'fp16': False}, 'task': Namespace(_name='translation_multi_simple_epoch', aim_repo=None, aim_run_hash=None, all_gather_list_size=16384, amp=False, amp_batch_retries=2, amp_init_scale=128, amp_scale_window=None, arch='wav2vec2', azureml_logging=False, batch_size=None, batch_size_valid=None, beam=5, best_checkpoint_metric='loss', bf16=False, bpe=None, broadcast_buffers=False, bucket_cap_mb=25, checkpoint_shard_count=1, checkpoint_suffix='', combine_valid_subsets=None, constraints=None, continue_once=None, cpu=False, cpu_offload=False, criterion='cross_entropy', curriculum=0, data='/storage/master-thesis/models/10nal-es_es-en/tokenizers/10nal-es-en/bin', data_buffer_size=10, dataset_impl=None, ddp_backend='pytorch_ddp', ddp_comm_hook='none', decoder_langtok=True, decoding_format=None, device_id=0, disable_validation=False, distributed_backend='nccl', distributed_init_method=None, distributed_no_spawn=False, distributed_num_procs=1, distributed_port=-1, distributed_rank=0, distributed_world_size=1, diverse_beam_groups=-1, diverse_beam_strength=0.5, diversity_rate=-1.0, empty_cache_freq=0, enable_lang_ids=False, enable_reservsed_directions_shared_datasets=False, encoder_langtok='src', eos=2, eos_token=None, extra_data=None, extra_lang_pairs=None, fast_stat_sync=False, find_unused_parameters=False, finetune_from_model=None, fix_batches_to_gpus=False, fixed_dictionary=None, fixed_validation_seed=None, force_anneal=None, fp16=False, fp16_init_scale=128, fp16_no_flatten_grads=False, fp16_scale_tolerance=0.0, fp16_scale_window=None, fp32_reduce_scatter=False, gen_subset='test', gradient_as_bucket_view=False, grouped_shuffling=False, heartbeat_timeout=-1, ignore_unused_valid_subsets=False, iter_decode_eos_penalty=0.0, iter_decode_force_max_iter=False, iter_decode_max_iter=10, iter_decode_with_beam=1, iter_decode_with_external_reranker=False, keep_best_checkpoints=-1, keep_inference_langtok=False, keep_interval_updates=-1, keep_interval_updates_pattern=-1, keep_last_epochs=-1, lang_dict=None, lang_pairs='quy-es,cni-es,aym-es,bzd-es,gn-es,oto-es,nah-es,tar-es,shp-es,hch-es,es-en', lang_tok_replacing_bos_eos=False, lang_tok_style='multilingual', langs=None, langtoks=None, langtoks_specs=['main'], left_pad_source='True', left_pad_target='False', lenpen=1, lm_path=None, lm_weight=0.0, load_alignments=False, load_checkpoint_on_all_dp_ranks=False, localsgd_frequency=3, log_file=None, log_format=None, log_interval=100, lr_scheduler='fixed', lr_shrink=0.1, match_source_len=False, max_len_a=0, max_len_b=200, max_source_positions=1024, max_target_positions=1024, max_tokens=6000, max_tokens_valid=6000, max_valid_steps=None, maximize_best_checkpoint_metric=False, memory_efficient_bf16=False, memory_efficient_fp16=False, min_len=1, min_loss_scale=0.0001, model_overrides='{}', model_parallel_size=1, nbest=1, no_beamable_mm=False, no_early_stop=False, no_epoch_checkpoints=False, no_last_checkpoints=False, no_progress_bar=False, no_repeat_ngram_size=0, no_reshard_after_forward=False, no_save=False, no_save_optimizer_state=False, no_seed_provided=False, not_fsdp_flatten_parameters=False, nprocs_per_node=1, num_shards=1, num_workers=1, on_cpu_convert_precision=False, optimizer=None, optimizer_overrides='{}', pad=1, path='/storage/master-thesis/models/10nal-es_es-en/checkpoint_best.pt', patience=-1, pipeline_balance=None, pipeline_checkpoint='never', pipeline_chunks=0, pipeline_decoder_balance=None, pipeline_decoder_devices=None, pipeline_devices=None, pipeline_encoder_balance=None, pipeline_encoder_devices=None, pipeline_model_parallel=False, plasma_path='/tmp/plasma', post_process=None, prefix_size=0, print_alignment='hard', print_step=False, profile=False, quantization_config_path=None, quiet=False, replace_unk=None, required_batch_size_multiple=8, required_seq_len_multiple=1, reset_dataloader=False, reset_logging=False, reset_lr_scheduler=False, reset_meters=False, reset_optimizer=False, restore_file='checkpoint_last.pt', results_path=None, retain_dropout=False, retain_dropout_modules=None, retain_iter_history=False, sacrebleu=False, sampling=False, sampling_method='concat', sampling_temperature=1.5, sampling_topk=-1, sampling_topp=-1.0, sampling_weights=None, sampling_weights_from_file=None, save_dir='checkpoints', save_interval=1, save_interval_updates=0, score_reference=False, scoring='bleu', seed=1, shard_id=0, skip_invalid_size_inputs_valid_test=False, slowmo_base_algorithm='localsgd', slowmo_momentum=None, source_dict=None, source_lang='nah', suppress_crashes=False, target_dict=None, target_lang='es', task='translation_multi_simple_epoch', temperature=1.0, tensorboard_logdir=None, threshold_loss_scale=None, tokenizer=None, tpu=False, train_subset='train', truncate_source=False, unk=3, unkpen=0, unnormalized=False, update_epoch_batch_itr=False, update_ordered_indices_seed=False, upsample_primary=1, use_plasma_view=False, use_sharded_state=False, user_dir=None, valid_subset='valid', validate_after_updates=0, validate_interval=1, validate_interval_updates=0, virtual_data_size=None, virtual_epoch_size=None, wandb_project=None, warmup_updates=0, write_checkpoints_asynchronously=False, zero_sharding='none'), 'criterion': {'_name': 'cross_entropy', 'sentence_avg': True}, 'optimizer': None, 'lr_scheduler': {'_name': 'fixed', 'force_anneal': None, 'lr_shrink': 0.1, 'warmup_updates': 0, 'lr': [0.25]}, 'scoring': {'_name': 'bleu', 'pad': 1, 'eos': 2, 'unk': 3}, 'bpe': None, 'tokenizer': None, 'ema': {'_name': None, 'store_ema': False, 'ema_decay': 0.9999, 'ema_start_update': 0, 'ema_seed_model': None, 'ema_update_freq': 1, 'ema_fp32': False}}\n",
      "2022-11-01 21:11:45 | WARNING | fairseq.data.multilingual.multilingual_data_manager | External language dictionary is not provided; use lang-pairs to infer the set of supported languages. The language ordering is not stable which might cause misalignment in pretraining and finetuning.\n",
      "2022-11-01 21:11:45 | INFO | fairseq.data.multilingual.multilingual_data_manager | inferred language list: ['aym', 'bzd', 'cni', 'en', 'es', 'gn', 'hch', 'nah', 'oto', 'quy', 'shp', 'tar']\n",
      "2022-11-01 21:11:46 | INFO | fairseq.data.multilingual.multilingual_data_manager | [nah] dictionary: 29300 types\n",
      "2022-11-01 21:11:46 | INFO | fairseq.data.multilingual.multilingual_data_manager | [es] dictionary: 29300 types\n",
      "2022-11-01 21:11:46 | INFO | fairseq_cli.generate | loading model(s) from /storage/master-thesis/models/10nal-es_es-en/checkpoint_best.pt\n",
      "2022-11-01 21:11:49 | INFO | fairseq.tasks.translation_multi_simple_epoch | loading data for test epoch=1/None\n",
      "2022-11-01 21:11:49 | INFO | fairseq.tasks.translation_multi_simple_epoch | mem usage: N/A\n",
      "2022-11-01 21:11:49 | INFO | fairseq.data.multilingual.multilingual_data_manager | langtoks settings: {'main': ('src', 'tgt')}\n",
      "2022-11-01 21:11:49 | INFO | fairseq.data.multilingual.multilingual_data_manager | [test] num of shards: {'main:nah-es': 1}\n",
      "2022-11-01 21:11:49 | INFO | fairseq.data.multilingual.multilingual_data_manager | main:nah-es src_langtok: 29295; tgt_langtok: 29292\n",
      "2022-11-01 21:11:49 | INFO | fairseq.data.data_utils | loaded 1,003 examples from: /storage/master-thesis/models/10nal-es_es-en/tokenizers/10nal-es-en/bin/test.nah-es.nah\n",
      "2022-11-01 21:11:49 | INFO | fairseq.data.multilingual.multilingual_data_manager | /storage/master-thesis/models/10nal-es_es-en/tokenizers/10nal-es-en/bin test nah-es 1003 examples\n",
      "2022-11-01 21:11:55 | INFO | fairseq.tasks.translation_multi_simple_epoch | start batch sampler: mem usage: N/A\n",
      "2022-11-01 21:11:55 | INFO | fairseq.tasks.translation_multi_simple_epoch | [test] @batch_sampler order indices time: 0:00:00.000517\n",
      "2022-11-01 21:11:55 | INFO | fairseq.tasks.translation_multi_simple_epoch | mem usage: N/A\n",
      "2022-11-01 21:11:55 | INFO | fairseq.tasks.translation_multi_simple_epoch | [test] @batch_sampler filter_by_size time: 0:00:00.005941\n",
      "2022-11-01 21:11:55 | INFO | fairseq.tasks.translation_multi_simple_epoch | mem usage: N/A\n",
      "2022-11-01 21:11:55 | INFO | fairseq.tasks.translation_multi_simple_epoch | [test] @batch_sampler batch_by_size time: 0:00:00.005944\n",
      "2022-11-01 21:11:55 | INFO | fairseq.tasks.translation_multi_simple_epoch | [test] per epoch batch_sampler set-up time: 0:00:00.013022\n",
      "2022-11-01 21:11:55 | INFO | fairseq.tasks.translation_multi_simple_epoch | mem usage: N/A\n",
      "2022-11-01 21:12:04 | INFO | fairseq_cli.generate | NOTE: hypothesis and token scores are output in base 2����| 5/5 [00:09<00:00,  1.67s/it, wps=1489]\n",
      "2022-11-01 21:12:04 | INFO | fairseq_cli.generate | Translated 1,003 sentences (13,909 tokens) in 6.7s (149.82 sentences/s, 2077.58 tokens/s)\n"
     ]
    }
   ],
   "source": [
    "! PYTHONIOENCODING=utf-8 fairseq-generate $(eval echo $TOKENIZER_PATH)/bin \\\n",
    "    $(eval echo $MODEL_PARAM) \\\n",
    "    --path $(eval echo $MODEL_DIR)/checkpoint_best.pt  \\\n",
    "    --source-lang $SRC_LANG --target-lang $PIV_LANG \\\n",
    "    --max-tokens 6000 \\\n",
    "    --task translation_multi_simple_epoch \\\n",
    "    --encoder-langtok \"src\" \\\n",
    "    --decoder-langtok \\\n",
    "    --lang-pairs $LANG_PAIRS \\\n",
    "    --print-alignment > $(eval echo $MODEL_DIR)/${SRC_LANG}_${PIV_LANG}.${PIV_LANG}.out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "!cat $(eval echo $MODEL_DIR)/${SRC_LANG}_${PIV_LANG}.${PIV_LANG}.out | grep -P \"^H\" |sort -V |cut -f 3- | sed \"s/ ##//g\" > $(eval echo $MODEL_DIR)/${SRC_LANG}_${PIV_LANG}.${PIV_LANG}.hyp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sacrebleu\n",
    "import argparse\n",
    "\n",
    "\n",
    "def calculate_score_report(sys, ref, score_only):\n",
    "\n",
    "    chrf = sacrebleu.corpus_chrf(sys, ref)\n",
    "    bleu = sacrebleu.corpus_bleu(sys, ref)\n",
    "\n",
    "    prefix = 'BLEU = ' if score_only else ''\n",
    "\n",
    "    print('#### Score Report ####')\n",
    "    print(chrf)\n",
    "    print('{}{}'.format(prefix, bleu.format(score_only=score_only)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "gold_lines=[]\n",
    "with open(src_piv_test_corpus + \"test.\" + piv_lang, encoding='utf8') as f:\n",
    "  gold_lines = f.readlines()\n",
    "  gold_lines = [x.strip(\"\\n\") for x in gold_lines]\n",
    "\n",
    "\n",
    "system_lines = []\n",
    "with open(model_dir + src_lang + \"_\" + piv_lang + \".\" + piv_lang + \".hyp\", encoding='utf8') as f:\n",
    "  system_lines = f.readlines()\n",
    "  system_lines = [x.strip(\"\\n\") for x in system_lines]\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "blanks = []\n",
    "for i in range(0,len(gold_lines)):\n",
    "    if gold_lines[i] == \"\":\n",
    "        blanks.append(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[]\n",
      "[]\n"
     ]
    }
   ],
   "source": [
    "print(blanks)\n",
    "blanks.reverse()\n",
    "print(blanks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in blanks:\n",
    "    del gold_lines[i]\n",
    "    del system_lines[i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1003\n",
      "1003\n"
     ]
    }
   ],
   "source": [
    "print(len(gold_lines))\n",
    "print(len(system_lines))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "La comprobación de antecedentes no se puede hacer tan rápido.\n",
      "\n",
      "les hizo saber a los macehuales que no tenían su mujer\n"
     ]
    }
   ],
   "source": [
    "print(gold_lines[500])\n",
    "print()\n",
    "print(system_lines[500])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SCORE SRC->PIV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "That's 100 lines that end in a tokenized period ('.')\n",
      "It looks like you forgot to detokenize your test data, which may hurt your score.\n",
      "If you insist your data is detokenized, or don't care, you can suppress this message with the `force` parameter.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#### Score Report ####\n",
      "chrF2 = 16.94\n",
      "BLEU = 1.79 21.2/3.3/0.8/0.2 (BP = 0.955 ratio = 0.956 hyp_len = 11039 ref_len = 11550)\n"
     ]
    }
   ],
   "source": [
    "calculate_score_report(system_lines, [gold_lines], score_only=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## generating src->piv->tgt\n",
    "### src->piv sub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading file /notebooks/master-thesis/corpora/tatoeba-challenge/en-nah/test.nah\n",
      "/storage/master-thesis/models/10nal-es_es-en/tokenizers/10nal-es-en/test.nah\n"
     ]
    }
   ],
   "source": [
    "tokenize_files(tokenizer, [src_tgt_test_corpus + 'test.' + src_lang], src_lang, tokenizer_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-11-01 21:12:08 | INFO | fairseq_cli.preprocess | Namespace(aim_repo=None, aim_run_hash=None, align_suffix=None, alignfile=None, all_gather_list_size=16384, amp=False, amp_batch_retries=2, amp_init_scale=128, amp_scale_window=None, azureml_logging=False, bf16=False, bpe=None, cpu=False, criterion='cross_entropy', dataset_impl='mmap', destdir='/storage/master-thesis/models/10nal-es_es-en/tokenizers/10nal-es-en/bin/', dict_only=False, empty_cache_freq=0, fp16=False, fp16_init_scale=128, fp16_no_flatten_grads=False, fp16_scale_tolerance=0.0, fp16_scale_window=None, joined_dictionary=True, log_file=None, log_format=None, log_interval=100, lr_scheduler='fixed', memory_efficient_bf16=False, memory_efficient_fp16=False, min_loss_scale=0.0001, model_parallel_size=1, no_progress_bar=False, nwordssrc=-1, nwordstgt=-1, on_cpu_convert_precision=False, only_source=True, optimizer=None, padding_factor=8, plasma_path='/tmp/plasma', profile=False, quantization_config_path=None, reset_logging=False, scoring='bleu', seed=1, source_lang='nah', srcdict='/storage/master-thesis/models/10nal-es_es-en/tokenizers/10nal-es-en/bin/dict.all.txt', suppress_crashes=False, target_lang='es', task='translation_multi_simple_epoch', tensorboard_logdir=None, testpref='/storage/master-thesis/models/10nal-es_es-en/tokenizers/10nal-es-en/test', tgtdict=None, threshold_loss_scale=None, thresholdsrc=0, thresholdtgt=0, tokenizer=None, tpu=False, trainpref=None, use_plasma_view=False, user_dir=None, validpref=None, wandb_project=None, workers=20)\n",
      "2022-11-01 21:12:08 | INFO | fairseq_cli.preprocess | [nah] Dictionary: 29288 types\n",
      "2022-11-01 21:12:09 | INFO | fairseq_cli.preprocess | [nah] /storage/master-thesis/models/10nal-es_es-en/tokenizers/10nal-es-en/test.nah: 1000 sents, 34779 tokens, 0.0% replaced (by <unk>)\n",
      "2022-11-01 21:12:09 | INFO | fairseq_cli.preprocess | Wrote preprocessed data to /storage/master-thesis/models/10nal-es_es-en/tokenizers/10nal-es-en/bin/\n"
     ]
    }
   ],
   "source": [
    "! fairseq-preprocess --source-lang $SRC_LANG --target-lang $PIV_LANG \\\n",
    "    --testpref $(eval echo $TOKENIZER_PATH)/test \\\n",
    "    --destdir $(eval echo $TOKENIZER_PATH)/bin/ \\\n",
    "    --workers 20 \\\n",
    "    --srcdict $(eval echo $TOKENIZER_PATH)/bin/dict.all.txt \\\n",
    "    --task translation_multi_simple_epoch \\\n",
    "    --joined-dictionary \\\n",
    "    --only-source"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-11-01 21:12:13 | INFO | fairseq_cli.generate | {'_name': None, 'common': {'_name': None, 'no_progress_bar': False, 'log_interval': 100, 'log_format': None, 'log_file': None, 'aim_repo': None, 'aim_run_hash': None, 'tensorboard_logdir': None, 'wandb_project': None, 'azureml_logging': False, 'seed': 1, 'cpu': False, 'tpu': False, 'bf16': False, 'memory_efficient_bf16': False, 'fp16': False, 'memory_efficient_fp16': False, 'fp16_no_flatten_grads': False, 'fp16_init_scale': 128, 'fp16_scale_window': None, 'fp16_scale_tolerance': 0.0, 'on_cpu_convert_precision': False, 'min_loss_scale': 0.0001, 'threshold_loss_scale': None, 'amp': False, 'amp_batch_retries': 2, 'amp_init_scale': 128, 'amp_scale_window': None, 'user_dir': None, 'empty_cache_freq': 0, 'all_gather_list_size': 16384, 'model_parallel_size': 1, 'quantization_config_path': None, 'profile': False, 'reset_logging': False, 'suppress_crashes': False, 'use_plasma_view': False, 'plasma_path': '/tmp/plasma'}, 'common_eval': {'_name': None, 'path': '/storage/master-thesis/models/10nal-es_es-en/checkpoint_best.pt', 'post_process': None, 'quiet': False, 'model_overrides': '{}', 'results_path': None}, 'distributed_training': {'_name': None, 'distributed_world_size': 1, 'distributed_num_procs': 1, 'distributed_rank': 0, 'distributed_backend': 'nccl', 'distributed_init_method': None, 'distributed_port': -1, 'device_id': 0, 'distributed_no_spawn': False, 'ddp_backend': 'pytorch_ddp', 'ddp_comm_hook': 'none', 'bucket_cap_mb': 25, 'fix_batches_to_gpus': False, 'find_unused_parameters': False, 'gradient_as_bucket_view': False, 'fast_stat_sync': False, 'heartbeat_timeout': -1, 'broadcast_buffers': False, 'slowmo_momentum': None, 'slowmo_base_algorithm': 'localsgd', 'localsgd_frequency': 3, 'nprocs_per_node': 1, 'pipeline_model_parallel': False, 'pipeline_balance': None, 'pipeline_devices': None, 'pipeline_chunks': 0, 'pipeline_encoder_balance': None, 'pipeline_encoder_devices': None, 'pipeline_decoder_balance': None, 'pipeline_decoder_devices': None, 'pipeline_checkpoint': 'never', 'zero_sharding': 'none', 'fp16': False, 'memory_efficient_fp16': False, 'tpu': False, 'no_reshard_after_forward': False, 'fp32_reduce_scatter': False, 'cpu_offload': False, 'use_sharded_state': False, 'not_fsdp_flatten_parameters': False}, 'dataset': {'_name': None, 'num_workers': 1, 'skip_invalid_size_inputs_valid_test': False, 'max_tokens': 6000, 'batch_size': None, 'required_batch_size_multiple': 8, 'required_seq_len_multiple': 1, 'dataset_impl': None, 'data_buffer_size': 10, 'train_subset': 'train', 'valid_subset': 'valid', 'combine_valid_subsets': None, 'ignore_unused_valid_subsets': False, 'validate_interval': 1, 'validate_interval_updates': 0, 'validate_after_updates': 0, 'fixed_validation_seed': None, 'disable_validation': False, 'max_tokens_valid': 6000, 'batch_size_valid': None, 'max_valid_steps': None, 'curriculum': 0, 'gen_subset': 'test', 'num_shards': 1, 'shard_id': 0, 'grouped_shuffling': False, 'update_epoch_batch_itr': False, 'update_ordered_indices_seed': False}, 'optimization': {'_name': None, 'max_epoch': 0, 'max_update': 0, 'stop_time_hours': 0.0, 'clip_norm': 0.0, 'sentence_avg': False, 'update_freq': [1], 'lr': [0.25], 'stop_min_lr': -1.0, 'use_bmuf': False, 'skip_remainder_batch': False}, 'checkpoint': {'_name': None, 'save_dir': 'checkpoints', 'restore_file': 'checkpoint_last.pt', 'continue_once': None, 'finetune_from_model': None, 'reset_dataloader': False, 'reset_lr_scheduler': False, 'reset_meters': False, 'reset_optimizer': False, 'optimizer_overrides': '{}', 'save_interval': 1, 'save_interval_updates': 0, 'keep_interval_updates': -1, 'keep_interval_updates_pattern': -1, 'keep_last_epochs': -1, 'keep_best_checkpoints': -1, 'no_save': False, 'no_epoch_checkpoints': False, 'no_last_checkpoints': False, 'no_save_optimizer_state': False, 'best_checkpoint_metric': 'loss', 'maximize_best_checkpoint_metric': False, 'patience': -1, 'checkpoint_suffix': '', 'checkpoint_shard_count': 1, 'load_checkpoint_on_all_dp_ranks': False, 'write_checkpoints_asynchronously': False, 'model_parallel_size': 1}, 'bmuf': {'_name': None, 'block_lr': 1.0, 'block_momentum': 0.875, 'global_sync_iter': 50, 'warmup_iterations': 500, 'use_nbm': False, 'average_sync': False, 'distributed_world_size': 1}, 'generation': {'_name': None, 'beam': 5, 'nbest': 1, 'max_len_a': 0.0, 'max_len_b': 200, 'min_len': 1, 'match_source_len': False, 'unnormalized': False, 'no_early_stop': False, 'no_beamable_mm': False, 'lenpen': 1.0, 'unkpen': 0.0, 'replace_unk': None, 'sacrebleu': False, 'score_reference': False, 'prefix_size': 0, 'no_repeat_ngram_size': 0, 'sampling': False, 'sampling_topk': -1, 'sampling_topp': -1.0, 'constraints': None, 'temperature': 1.0, 'diverse_beam_groups': -1, 'diverse_beam_strength': 0.5, 'diversity_rate': -1.0, 'print_alignment': 'hard', 'print_step': False, 'lm_path': None, 'lm_weight': 0.0, 'iter_decode_eos_penalty': 0.0, 'iter_decode_max_iter': 10, 'iter_decode_force_max_iter': False, 'iter_decode_with_beam': 1, 'iter_decode_with_external_reranker': False, 'retain_iter_history': False, 'retain_dropout': False, 'retain_dropout_modules': None, 'decoding_format': None, 'no_seed_provided': False, 'eos_token': None}, 'eval_lm': {'_name': None, 'output_word_probs': False, 'output_word_stats': False, 'context_window': 0, 'softmax_batch': 9223372036854775807}, 'interactive': {'_name': None, 'buffer_size': 0, 'input': '-'}, 'model': {'_name': 'wav2vec2', 'extractor_mode': 'default', 'encoder_layers': 12, 'encoder_embed_dim': 768, 'encoder_ffn_embed_dim': 3072, 'encoder_attention_heads': 12, 'activation_fn': 'gelu', 'layer_type': 'transformer', 'dropout': 0.1, 'attention_dropout': 0.1, 'activation_dropout': 0.0, 'encoder_layerdrop': 0.0, 'dropout_input': 0.0, 'dropout_features': 0.0, 'final_dim': 0, 'layer_norm_first': False, 'conv_feature_layers': '[(512, 10, 5)] + [(512, 3, 2)] * 4 + [(512,2,2)] + [(512,2,2)]', 'conv_bias': False, 'logit_temp': 0.1, 'quantize_targets': False, 'quantize_input': False, 'same_quantizer': False, 'target_glu': False, 'feature_grad_mult': 1.0, 'quantizer_depth': 1, 'quantizer_factor': 3, 'latent_vars': 320, 'latent_groups': 2, 'latent_dim': 0, 'mask_length': 10, 'mask_prob': 0.65, 'mask_selection': 'static', 'mask_other': 0.0, 'no_mask_overlap': False, 'mask_min_space': 1, 'require_same_masks': True, 'mask_dropout': 0.0, 'mask_channel_length': 10, 'mask_channel_prob': 0.0, 'mask_channel_before': False, 'mask_channel_selection': 'static', 'mask_channel_other': 0.0, 'no_mask_channel_overlap': False, 'mask_channel_min_space': 1, 'num_negatives': 100, 'negatives_from_everywhere': False, 'cross_sample_negatives': 0, 'codebook_negatives': 0, 'conv_pos': 128, 'conv_pos_groups': 16, 'pos_conv_depth': 1, 'latent_temp': [2.0, 0.5, 0.999995], 'max_positions': 100000, 'checkpoint_activations': False, 'required_seq_len_multiple': 1, 'crop_seq_to_multiple': 1, 'depthwise_conv_kernel_size': 31, 'attn_type': '', 'pos_enc_type': 'abs', 'fp16': False}, 'task': Namespace(_name='translation_multi_simple_epoch', aim_repo=None, aim_run_hash=None, all_gather_list_size=16384, amp=False, amp_batch_retries=2, amp_init_scale=128, amp_scale_window=None, arch='wav2vec2', azureml_logging=False, batch_size=None, batch_size_valid=None, beam=5, best_checkpoint_metric='loss', bf16=False, bpe=None, broadcast_buffers=False, bucket_cap_mb=25, checkpoint_shard_count=1, checkpoint_suffix='', combine_valid_subsets=None, constraints=None, continue_once=None, cpu=False, cpu_offload=False, criterion='cross_entropy', curriculum=0, data='/storage/master-thesis/models/10nal-es_es-en/tokenizers/10nal-es-en/bin', data_buffer_size=10, dataset_impl=None, ddp_backend='pytorch_ddp', ddp_comm_hook='none', decoder_langtok=True, decoding_format=None, device_id=0, disable_validation=False, distributed_backend='nccl', distributed_init_method=None, distributed_no_spawn=False, distributed_num_procs=1, distributed_port=-1, distributed_rank=0, distributed_world_size=1, diverse_beam_groups=-1, diverse_beam_strength=0.5, diversity_rate=-1.0, empty_cache_freq=0, enable_lang_ids=False, enable_reservsed_directions_shared_datasets=False, encoder_langtok='src', eos=2, eos_token=None, extra_data=None, extra_lang_pairs=None, fast_stat_sync=False, find_unused_parameters=False, finetune_from_model=None, fix_batches_to_gpus=False, fixed_dictionary=None, fixed_validation_seed=None, force_anneal=None, fp16=False, fp16_init_scale=128, fp16_no_flatten_grads=False, fp16_scale_tolerance=0.0, fp16_scale_window=None, fp32_reduce_scatter=False, gen_subset='test', gradient_as_bucket_view=False, grouped_shuffling=False, heartbeat_timeout=-1, ignore_unused_valid_subsets=False, iter_decode_eos_penalty=0.0, iter_decode_force_max_iter=False, iter_decode_max_iter=10, iter_decode_with_beam=1, iter_decode_with_external_reranker=False, keep_best_checkpoints=-1, keep_inference_langtok=False, keep_interval_updates=-1, keep_interval_updates_pattern=-1, keep_last_epochs=-1, lang_dict=None, lang_pairs='quy-es,cni-es,aym-es,bzd-es,gn-es,oto-es,nah-es,tar-es,shp-es,hch-es,es-en', lang_tok_replacing_bos_eos=False, lang_tok_style='multilingual', langs=None, langtoks=None, langtoks_specs=['main'], left_pad_source='True', left_pad_target='False', lenpen=1, lm_path=None, lm_weight=0.0, load_alignments=False, load_checkpoint_on_all_dp_ranks=False, localsgd_frequency=3, log_file=None, log_format=None, log_interval=100, lr_scheduler='fixed', lr_shrink=0.1, match_source_len=False, max_len_a=0, max_len_b=200, max_source_positions=1024, max_target_positions=1024, max_tokens=6000, max_tokens_valid=6000, max_valid_steps=None, maximize_best_checkpoint_metric=False, memory_efficient_bf16=False, memory_efficient_fp16=False, min_len=1, min_loss_scale=0.0001, model_overrides='{}', model_parallel_size=1, nbest=1, no_beamable_mm=False, no_early_stop=False, no_epoch_checkpoints=False, no_last_checkpoints=False, no_progress_bar=False, no_repeat_ngram_size=0, no_reshard_after_forward=False, no_save=False, no_save_optimizer_state=False, no_seed_provided=False, not_fsdp_flatten_parameters=False, nprocs_per_node=1, num_shards=1, num_workers=1, on_cpu_convert_precision=False, optimizer=None, optimizer_overrides='{}', pad=1, path='/storage/master-thesis/models/10nal-es_es-en/checkpoint_best.pt', patience=-1, pipeline_balance=None, pipeline_checkpoint='never', pipeline_chunks=0, pipeline_decoder_balance=None, pipeline_decoder_devices=None, pipeline_devices=None, pipeline_encoder_balance=None, pipeline_encoder_devices=None, pipeline_model_parallel=False, plasma_path='/tmp/plasma', post_process=None, prefix_size=0, print_alignment='hard', print_step=False, profile=False, quantization_config_path=None, quiet=False, replace_unk=None, required_batch_size_multiple=8, required_seq_len_multiple=1, reset_dataloader=False, reset_logging=False, reset_lr_scheduler=False, reset_meters=False, reset_optimizer=False, restore_file='checkpoint_last.pt', results_path=None, retain_dropout=False, retain_dropout_modules=None, retain_iter_history=False, sacrebleu=False, sampling=False, sampling_method='concat', sampling_temperature=1.5, sampling_topk=-1, sampling_topp=-1.0, sampling_weights=None, sampling_weights_from_file=None, save_dir='checkpoints', save_interval=1, save_interval_updates=0, score_reference=False, scoring='bleu', seed=1, shard_id=0, skip_invalid_size_inputs_valid_test=False, slowmo_base_algorithm='localsgd', slowmo_momentum=None, source_dict=None, source_lang='nah', suppress_crashes=False, target_dict=None, target_lang='es', task='translation_multi_simple_epoch', temperature=1.0, tensorboard_logdir=None, threshold_loss_scale=None, tokenizer=None, tpu=False, train_subset='train', truncate_source=False, unk=3, unkpen=0, unnormalized=False, update_epoch_batch_itr=False, update_ordered_indices_seed=False, upsample_primary=1, use_plasma_view=False, use_sharded_state=False, user_dir=None, valid_subset='valid', validate_after_updates=0, validate_interval=1, validate_interval_updates=0, virtual_data_size=None, virtual_epoch_size=None, wandb_project=None, warmup_updates=0, write_checkpoints_asynchronously=False, zero_sharding='none'), 'criterion': {'_name': 'cross_entropy', 'sentence_avg': True}, 'optimizer': None, 'lr_scheduler': {'_name': 'fixed', 'force_anneal': None, 'lr_shrink': 0.1, 'warmup_updates': 0, 'lr': [0.25]}, 'scoring': {'_name': 'bleu', 'pad': 1, 'eos': 2, 'unk': 3}, 'bpe': None, 'tokenizer': None, 'ema': {'_name': None, 'store_ema': False, 'ema_decay': 0.9999, 'ema_start_update': 0, 'ema_seed_model': None, 'ema_update_freq': 1, 'ema_fp32': False}}\n",
      "2022-11-01 21:12:13 | WARNING | fairseq.data.multilingual.multilingual_data_manager | External language dictionary is not provided; use lang-pairs to infer the set of supported languages. The language ordering is not stable which might cause misalignment in pretraining and finetuning.\n",
      "2022-11-01 21:12:13 | INFO | fairseq.data.multilingual.multilingual_data_manager | inferred language list: ['aym', 'bzd', 'cni', 'en', 'es', 'gn', 'hch', 'nah', 'oto', 'quy', 'shp', 'tar']\n",
      "2022-11-01 21:12:13 | INFO | fairseq.data.multilingual.multilingual_data_manager | [nah] dictionary: 29300 types\n",
      "2022-11-01 21:12:13 | INFO | fairseq.data.multilingual.multilingual_data_manager | [es] dictionary: 29300 types\n",
      "2022-11-01 21:12:13 | INFO | fairseq_cli.generate | loading model(s) from /storage/master-thesis/models/10nal-es_es-en/checkpoint_best.pt\n",
      "2022-11-01 21:12:17 | INFO | fairseq.tasks.translation_multi_simple_epoch | loading data for test epoch=1/None\n",
      "2022-11-01 21:12:17 | INFO | fairseq.tasks.translation_multi_simple_epoch | mem usage: N/A\n",
      "2022-11-01 21:12:17 | INFO | fairseq.data.multilingual.multilingual_data_manager | langtoks settings: {'main': ('src', 'tgt')}\n",
      "2022-11-01 21:12:17 | INFO | fairseq.data.multilingual.multilingual_data_manager | [test] num of shards: {'main:nah-es': 1}\n",
      "2022-11-01 21:12:17 | INFO | fairseq.data.multilingual.multilingual_data_manager | main:nah-es src_langtok: 29295; tgt_langtok: 29292\n",
      "2022-11-01 21:12:17 | INFO | fairseq.data.data_utils | loaded 1,000 examples from: /storage/master-thesis/models/10nal-es_es-en/tokenizers/10nal-es-en/bin/test.nah-es.nah\n",
      "2022-11-01 21:12:17 | INFO | fairseq.data.multilingual.multilingual_data_manager | /storage/master-thesis/models/10nal-es_es-en/tokenizers/10nal-es-en/bin test nah-es 1000 examples\n",
      "2022-11-01 21:12:22 | INFO | fairseq.tasks.translation_multi_simple_epoch | start batch sampler: mem usage: N/A\n",
      "2022-11-01 21:12:22 | INFO | fairseq.tasks.translation_multi_simple_epoch | [test] @batch_sampler order indices time: 0:00:00.000513\n",
      "2022-11-01 21:12:22 | INFO | fairseq.tasks.translation_multi_simple_epoch | mem usage: N/A\n",
      "2022-11-01 21:12:22 | INFO | fairseq.tasks.translation_multi_simple_epoch | [test] @batch_sampler filter_by_size time: 0:00:00.005687\n",
      "2022-11-01 21:12:22 | INFO | fairseq.tasks.translation_multi_simple_epoch | mem usage: N/A\n",
      "2022-11-01 21:12:22 | INFO | fairseq.tasks.translation_multi_simple_epoch | [test] @batch_sampler batch_by_size time: 0:00:00.006422\n",
      "2022-11-01 21:12:22 | INFO | fairseq.tasks.translation_multi_simple_epoch | [test] per epoch batch_sampler set-up time: 0:00:00.013112\n",
      "2022-11-01 21:12:22 | INFO | fairseq.tasks.translation_multi_simple_epoch | mem usage: N/A\n",
      "2022-11-01 21:12:37 | INFO | fairseq_cli.generate | NOTE: hypothesis and token scores are output in base 2����| 8/8 [00:14<00:00,  1.68s/it, wps=1348]\n",
      "2022-11-01 21:12:37 | INFO | fairseq_cli.generate | Translated 1,000 sentences (20,066 tokens) in 10.7s (93.68 sentences/s, 1879.86 tokens/s)\n"
     ]
    }
   ],
   "source": [
    "! PYTHONIOENCODING=utf-8 fairseq-generate $(eval echo $TOKENIZER_PATH)/bin \\\n",
    "    --path $(eval echo $MODEL_DIR)/checkpoint_best.pt  \\\n",
    "    $(eval echo $MODEL_PARAM) \\\n",
    "    --source-lang $SRC_LANG --target-lang $PIV_LANG \\\n",
    "    --max-tokens 6000 \\\n",
    "    --task translation_multi_simple_epoch \\\n",
    "    --encoder-langtok \"src\" \\\n",
    "    --decoder-langtok \\\n",
    "    --lang-pairs $LANG_PAIRS \\\n",
    "    --print-alignment > $(eval echo $MODEL_DIR)/${SRC_LANG}_${PIV_LANG}.${PIV_LANG}.out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "!cat $(eval echo $MODEL_DIR)/${SRC_LANG}_${PIV_LANG}.${PIV_LANG}.out | grep -P \"^H\" |sort -V |cut -f 3- | sed \"s/ ##//g\" > $(eval echo $MODEL_DIR)/${SRC_LANG}_${PIV_LANG}.${PIV_LANG}.hyp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### piv->tgt sub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading file /storage/master-thesis/models/10nal-es_es-en/nah_es.es.hyp\n",
      "/storage/master-thesis/models/10nal-es_es-en/tokenizers/10nal-es-en/nah_es.es.es\n"
     ]
    }
   ],
   "source": [
    "tokenize_files(tokenizer, [model_dir + src_lang + \"_\" + piv_lang + \".\" + piv_lang + \".hyp\"], piv_lang, tokenizer_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "mv $(eval echo $TOKENIZER_PATH)/${SRC_LANG}_${PIV_LANG}.${PIV_LANG}.${PIV_LANG} $(eval echo $TOKENIZER_PATH)/test.${PIV_LANG}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-11-01 21:12:41 | INFO | fairseq_cli.preprocess | Namespace(aim_repo=None, aim_run_hash=None, align_suffix=None, alignfile=None, all_gather_list_size=16384, amp=False, amp_batch_retries=2, amp_init_scale=128, amp_scale_window=None, azureml_logging=False, bf16=False, bpe=None, cpu=False, criterion='cross_entropy', dataset_impl='mmap', destdir='/storage/master-thesis/models/10nal-es_es-en/tokenizers/10nal-es-en/bin/', dict_only=False, empty_cache_freq=0, fp16=False, fp16_init_scale=128, fp16_no_flatten_grads=False, fp16_scale_tolerance=0.0, fp16_scale_window=None, joined_dictionary=True, log_file=None, log_format=None, log_interval=100, lr_scheduler='fixed', memory_efficient_bf16=False, memory_efficient_fp16=False, min_loss_scale=0.0001, model_parallel_size=1, no_progress_bar=False, nwordssrc=-1, nwordstgt=-1, on_cpu_convert_precision=False, only_source=True, optimizer=None, padding_factor=8, plasma_path='/tmp/plasma', profile=False, quantization_config_path=None, reset_logging=False, scoring='bleu', seed=1, source_lang='es', srcdict='/storage/master-thesis/models/10nal-es_es-en/tokenizers/10nal-es-en/bin/dict.all.txt', suppress_crashes=False, target_lang='en', task='translation_multi_simple_epoch', tensorboard_logdir=None, testpref='/storage/master-thesis/models/10nal-es_es-en/tokenizers/10nal-es-en/test', tgtdict=None, threshold_loss_scale=None, thresholdsrc=0, thresholdtgt=0, tokenizer=None, tpu=False, trainpref=None, use_plasma_view=False, user_dir=None, validpref=None, wandb_project=None, workers=20)\n",
      "2022-11-01 21:12:42 | INFO | fairseq_cli.preprocess | [es] Dictionary: 29288 types\n",
      "2022-11-01 21:12:42 | INFO | fairseq_cli.preprocess | [es] /storage/master-thesis/models/10nal-es_es-en/tokenizers/10nal-es-en/test.es: 1000 sents, 19046 tokens, 0.0% replaced (by <unk>)\n",
      "2022-11-01 21:12:42 | INFO | fairseq_cli.preprocess | Wrote preprocessed data to /storage/master-thesis/models/10nal-es_es-en/tokenizers/10nal-es-en/bin/\n"
     ]
    }
   ],
   "source": [
    "! fairseq-preprocess --source-lang $PIV_LANG --target-lang $TGT_LANG \\\n",
    "    --testpref $(eval echo $TOKENIZER_PATH)/test \\\n",
    "    --destdir $(eval echo $TOKENIZER_PATH)/bin/ \\\n",
    "    --workers 20 \\\n",
    "    --srcdict $(eval echo $TOKENIZER_PATH)/bin/dict.all.txt \\\n",
    "    --task translation_multi_simple_epoch \\\n",
    "    --joined-dictionary \\\n",
    "    --only-source"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-11-01 21:12:46 | INFO | fairseq_cli.generate | {'_name': None, 'common': {'_name': None, 'no_progress_bar': False, 'log_interval': 100, 'log_format': None, 'log_file': None, 'aim_repo': None, 'aim_run_hash': None, 'tensorboard_logdir': None, 'wandb_project': None, 'azureml_logging': False, 'seed': 1, 'cpu': False, 'tpu': False, 'bf16': False, 'memory_efficient_bf16': False, 'fp16': False, 'memory_efficient_fp16': False, 'fp16_no_flatten_grads': False, 'fp16_init_scale': 128, 'fp16_scale_window': None, 'fp16_scale_tolerance': 0.0, 'on_cpu_convert_precision': False, 'min_loss_scale': 0.0001, 'threshold_loss_scale': None, 'amp': False, 'amp_batch_retries': 2, 'amp_init_scale': 128, 'amp_scale_window': None, 'user_dir': None, 'empty_cache_freq': 0, 'all_gather_list_size': 16384, 'model_parallel_size': 1, 'quantization_config_path': None, 'profile': False, 'reset_logging': False, 'suppress_crashes': False, 'use_plasma_view': False, 'plasma_path': '/tmp/plasma'}, 'common_eval': {'_name': None, 'path': '/storage/master-thesis/models/10nal-es_es-en/checkpoint_best.pt', 'post_process': None, 'quiet': False, 'model_overrides': '{}', 'results_path': None}, 'distributed_training': {'_name': None, 'distributed_world_size': 1, 'distributed_num_procs': 1, 'distributed_rank': 0, 'distributed_backend': 'nccl', 'distributed_init_method': None, 'distributed_port': -1, 'device_id': 0, 'distributed_no_spawn': False, 'ddp_backend': 'pytorch_ddp', 'ddp_comm_hook': 'none', 'bucket_cap_mb': 25, 'fix_batches_to_gpus': False, 'find_unused_parameters': False, 'gradient_as_bucket_view': False, 'fast_stat_sync': False, 'heartbeat_timeout': -1, 'broadcast_buffers': False, 'slowmo_momentum': None, 'slowmo_base_algorithm': 'localsgd', 'localsgd_frequency': 3, 'nprocs_per_node': 1, 'pipeline_model_parallel': False, 'pipeline_balance': None, 'pipeline_devices': None, 'pipeline_chunks': 0, 'pipeline_encoder_balance': None, 'pipeline_encoder_devices': None, 'pipeline_decoder_balance': None, 'pipeline_decoder_devices': None, 'pipeline_checkpoint': 'never', 'zero_sharding': 'none', 'fp16': False, 'memory_efficient_fp16': False, 'tpu': False, 'no_reshard_after_forward': False, 'fp32_reduce_scatter': False, 'cpu_offload': False, 'use_sharded_state': False, 'not_fsdp_flatten_parameters': False}, 'dataset': {'_name': None, 'num_workers': 1, 'skip_invalid_size_inputs_valid_test': False, 'max_tokens': 6000, 'batch_size': None, 'required_batch_size_multiple': 8, 'required_seq_len_multiple': 1, 'dataset_impl': None, 'data_buffer_size': 10, 'train_subset': 'train', 'valid_subset': 'valid', 'combine_valid_subsets': None, 'ignore_unused_valid_subsets': False, 'validate_interval': 1, 'validate_interval_updates': 0, 'validate_after_updates': 0, 'fixed_validation_seed': None, 'disable_validation': False, 'max_tokens_valid': 6000, 'batch_size_valid': None, 'max_valid_steps': None, 'curriculum': 0, 'gen_subset': 'test', 'num_shards': 1, 'shard_id': 0, 'grouped_shuffling': False, 'update_epoch_batch_itr': False, 'update_ordered_indices_seed': False}, 'optimization': {'_name': None, 'max_epoch': 0, 'max_update': 0, 'stop_time_hours': 0.0, 'clip_norm': 0.0, 'sentence_avg': False, 'update_freq': [1], 'lr': [0.25], 'stop_min_lr': -1.0, 'use_bmuf': False, 'skip_remainder_batch': False}, 'checkpoint': {'_name': None, 'save_dir': 'checkpoints', 'restore_file': 'checkpoint_last.pt', 'continue_once': None, 'finetune_from_model': None, 'reset_dataloader': False, 'reset_lr_scheduler': False, 'reset_meters': False, 'reset_optimizer': False, 'optimizer_overrides': '{}', 'save_interval': 1, 'save_interval_updates': 0, 'keep_interval_updates': -1, 'keep_interval_updates_pattern': -1, 'keep_last_epochs': -1, 'keep_best_checkpoints': -1, 'no_save': False, 'no_epoch_checkpoints': False, 'no_last_checkpoints': False, 'no_save_optimizer_state': False, 'best_checkpoint_metric': 'loss', 'maximize_best_checkpoint_metric': False, 'patience': -1, 'checkpoint_suffix': '', 'checkpoint_shard_count': 1, 'load_checkpoint_on_all_dp_ranks': False, 'write_checkpoints_asynchronously': False, 'model_parallel_size': 1}, 'bmuf': {'_name': None, 'block_lr': 1.0, 'block_momentum': 0.875, 'global_sync_iter': 50, 'warmup_iterations': 500, 'use_nbm': False, 'average_sync': False, 'distributed_world_size': 1}, 'generation': {'_name': None, 'beam': 5, 'nbest': 1, 'max_len_a': 0.0, 'max_len_b': 200, 'min_len': 1, 'match_source_len': False, 'unnormalized': False, 'no_early_stop': False, 'no_beamable_mm': False, 'lenpen': 1.0, 'unkpen': 0.0, 'replace_unk': None, 'sacrebleu': False, 'score_reference': False, 'prefix_size': 0, 'no_repeat_ngram_size': 0, 'sampling': False, 'sampling_topk': -1, 'sampling_topp': -1.0, 'constraints': None, 'temperature': 1.0, 'diverse_beam_groups': -1, 'diverse_beam_strength': 0.5, 'diversity_rate': -1.0, 'print_alignment': 'hard', 'print_step': False, 'lm_path': None, 'lm_weight': 0.0, 'iter_decode_eos_penalty': 0.0, 'iter_decode_max_iter': 10, 'iter_decode_force_max_iter': False, 'iter_decode_with_beam': 1, 'iter_decode_with_external_reranker': False, 'retain_iter_history': False, 'retain_dropout': False, 'retain_dropout_modules': None, 'decoding_format': None, 'no_seed_provided': False, 'eos_token': None}, 'eval_lm': {'_name': None, 'output_word_probs': False, 'output_word_stats': False, 'context_window': 0, 'softmax_batch': 9223372036854775807}, 'interactive': {'_name': None, 'buffer_size': 0, 'input': '-'}, 'model': {'_name': 'wav2vec2', 'extractor_mode': 'default', 'encoder_layers': 12, 'encoder_embed_dim': 768, 'encoder_ffn_embed_dim': 3072, 'encoder_attention_heads': 12, 'activation_fn': 'gelu', 'layer_type': 'transformer', 'dropout': 0.1, 'attention_dropout': 0.1, 'activation_dropout': 0.0, 'encoder_layerdrop': 0.0, 'dropout_input': 0.0, 'dropout_features': 0.0, 'final_dim': 0, 'layer_norm_first': False, 'conv_feature_layers': '[(512, 10, 5)] + [(512, 3, 2)] * 4 + [(512,2,2)] + [(512,2,2)]', 'conv_bias': False, 'logit_temp': 0.1, 'quantize_targets': False, 'quantize_input': False, 'same_quantizer': False, 'target_glu': False, 'feature_grad_mult': 1.0, 'quantizer_depth': 1, 'quantizer_factor': 3, 'latent_vars': 320, 'latent_groups': 2, 'latent_dim': 0, 'mask_length': 10, 'mask_prob': 0.65, 'mask_selection': 'static', 'mask_other': 0.0, 'no_mask_overlap': False, 'mask_min_space': 1, 'require_same_masks': True, 'mask_dropout': 0.0, 'mask_channel_length': 10, 'mask_channel_prob': 0.0, 'mask_channel_before': False, 'mask_channel_selection': 'static', 'mask_channel_other': 0.0, 'no_mask_channel_overlap': False, 'mask_channel_min_space': 1, 'num_negatives': 100, 'negatives_from_everywhere': False, 'cross_sample_negatives': 0, 'codebook_negatives': 0, 'conv_pos': 128, 'conv_pos_groups': 16, 'pos_conv_depth': 1, 'latent_temp': [2.0, 0.5, 0.999995], 'max_positions': 100000, 'checkpoint_activations': False, 'required_seq_len_multiple': 1, 'crop_seq_to_multiple': 1, 'depthwise_conv_kernel_size': 31, 'attn_type': '', 'pos_enc_type': 'abs', 'fp16': False}, 'task': Namespace(_name='translation_multi_simple_epoch', aim_repo=None, aim_run_hash=None, all_gather_list_size=16384, amp=False, amp_batch_retries=2, amp_init_scale=128, amp_scale_window=None, arch='wav2vec2', azureml_logging=False, batch_size=None, batch_size_valid=None, beam=5, best_checkpoint_metric='loss', bf16=False, bpe=None, broadcast_buffers=False, bucket_cap_mb=25, checkpoint_shard_count=1, checkpoint_suffix='', combine_valid_subsets=None, constraints=None, continue_once=None, cpu=False, cpu_offload=False, criterion='cross_entropy', curriculum=0, data='/storage/master-thesis/models/10nal-es_es-en/tokenizers/10nal-es-en/bin', data_buffer_size=10, dataset_impl=None, ddp_backend='pytorch_ddp', ddp_comm_hook='none', decoder_langtok=True, decoding_format=None, device_id=0, disable_validation=False, distributed_backend='nccl', distributed_init_method=None, distributed_no_spawn=False, distributed_num_procs=1, distributed_port=-1, distributed_rank=0, distributed_world_size=1, diverse_beam_groups=-1, diverse_beam_strength=0.5, diversity_rate=-1.0, empty_cache_freq=0, enable_lang_ids=False, enable_reservsed_directions_shared_datasets=False, encoder_langtok='src', eos=2, eos_token=None, extra_data=None, extra_lang_pairs=None, fast_stat_sync=False, find_unused_parameters=False, finetune_from_model=None, fix_batches_to_gpus=False, fixed_dictionary=None, fixed_validation_seed=None, force_anneal=None, fp16=False, fp16_init_scale=128, fp16_no_flatten_grads=False, fp16_scale_tolerance=0.0, fp16_scale_window=None, fp32_reduce_scatter=False, gen_subset='test', gradient_as_bucket_view=False, grouped_shuffling=False, heartbeat_timeout=-1, ignore_unused_valid_subsets=False, iter_decode_eos_penalty=0.0, iter_decode_force_max_iter=False, iter_decode_max_iter=10, iter_decode_with_beam=1, iter_decode_with_external_reranker=False, keep_best_checkpoints=-1, keep_inference_langtok=False, keep_interval_updates=-1, keep_interval_updates_pattern=-1, keep_last_epochs=-1, lang_dict=None, lang_pairs='quy-es,cni-es,aym-es,bzd-es,gn-es,oto-es,nah-es,tar-es,shp-es,hch-es,es-en', lang_tok_replacing_bos_eos=False, lang_tok_style='multilingual', langs=None, langtoks=None, langtoks_specs=['main'], left_pad_source='True', left_pad_target='False', lenpen=1, lm_path=None, lm_weight=0.0, load_alignments=False, load_checkpoint_on_all_dp_ranks=False, localsgd_frequency=3, log_file=None, log_format=None, log_interval=100, lr_scheduler='fixed', lr_shrink=0.1, match_source_len=False, max_len_a=0, max_len_b=200, max_source_positions=1024, max_target_positions=1024, max_tokens=6000, max_tokens_valid=6000, max_valid_steps=None, maximize_best_checkpoint_metric=False, memory_efficient_bf16=False, memory_efficient_fp16=False, min_len=1, min_loss_scale=0.0001, model_overrides='{}', model_parallel_size=1, nbest=1, no_beamable_mm=False, no_early_stop=False, no_epoch_checkpoints=False, no_last_checkpoints=False, no_progress_bar=False, no_repeat_ngram_size=0, no_reshard_after_forward=False, no_save=False, no_save_optimizer_state=False, no_seed_provided=False, not_fsdp_flatten_parameters=False, nprocs_per_node=1, num_shards=1, num_workers=1, on_cpu_convert_precision=False, optimizer=None, optimizer_overrides='{}', pad=1, path='/storage/master-thesis/models/10nal-es_es-en/checkpoint_best.pt', patience=-1, pipeline_balance=None, pipeline_checkpoint='never', pipeline_chunks=0, pipeline_decoder_balance=None, pipeline_decoder_devices=None, pipeline_devices=None, pipeline_encoder_balance=None, pipeline_encoder_devices=None, pipeline_model_parallel=False, plasma_path='/tmp/plasma', post_process=None, prefix_size=0, print_alignment='hard', print_step=False, profile=False, quantization_config_path=None, quiet=False, replace_unk=None, required_batch_size_multiple=8, required_seq_len_multiple=1, reset_dataloader=False, reset_logging=False, reset_lr_scheduler=False, reset_meters=False, reset_optimizer=False, restore_file='checkpoint_last.pt', results_path=None, retain_dropout=False, retain_dropout_modules=None, retain_iter_history=False, sacrebleu=False, sampling=False, sampling_method='concat', sampling_temperature=1.5, sampling_topk=-1, sampling_topp=-1.0, sampling_weights=None, sampling_weights_from_file=None, save_dir='checkpoints', save_interval=1, save_interval_updates=0, score_reference=False, scoring='bleu', seed=1, shard_id=0, skip_invalid_size_inputs_valid_test=False, slowmo_base_algorithm='localsgd', slowmo_momentum=None, source_dict=None, source_lang='es', suppress_crashes=False, target_dict=None, target_lang='en', task='translation_multi_simple_epoch', temperature=1.0, tensorboard_logdir=None, threshold_loss_scale=None, tokenizer=None, tpu=False, train_subset='train', truncate_source=False, unk=3, unkpen=0, unnormalized=False, update_epoch_batch_itr=False, update_ordered_indices_seed=False, upsample_primary=1, use_plasma_view=False, use_sharded_state=False, user_dir=None, valid_subset='valid', validate_after_updates=0, validate_interval=1, validate_interval_updates=0, virtual_data_size=None, virtual_epoch_size=None, wandb_project=None, warmup_updates=0, write_checkpoints_asynchronously=False, zero_sharding='none'), 'criterion': {'_name': 'cross_entropy', 'sentence_avg': True}, 'optimizer': None, 'lr_scheduler': {'_name': 'fixed', 'force_anneal': None, 'lr_shrink': 0.1, 'warmup_updates': 0, 'lr': [0.25]}, 'scoring': {'_name': 'bleu', 'pad': 1, 'eos': 2, 'unk': 3}, 'bpe': None, 'tokenizer': None, 'ema': {'_name': None, 'store_ema': False, 'ema_decay': 0.9999, 'ema_start_update': 0, 'ema_seed_model': None, 'ema_update_freq': 1, 'ema_fp32': False}}\n",
      "2022-11-01 21:12:46 | WARNING | fairseq.data.multilingual.multilingual_data_manager | External language dictionary is not provided; use lang-pairs to infer the set of supported languages. The language ordering is not stable which might cause misalignment in pretraining and finetuning.\n",
      "2022-11-01 21:12:46 | INFO | fairseq.data.multilingual.multilingual_data_manager | inferred language list: ['aym', 'bzd', 'cni', 'en', 'es', 'gn', 'hch', 'nah', 'oto', 'quy', 'shp', 'tar']\n",
      "2022-11-01 21:12:46 | INFO | fairseq.data.multilingual.multilingual_data_manager | [es] dictionary: 29300 types\n",
      "2022-11-01 21:12:46 | INFO | fairseq.data.multilingual.multilingual_data_manager | [en] dictionary: 29300 types\n",
      "2022-11-01 21:12:46 | INFO | fairseq_cli.generate | loading model(s) from /storage/master-thesis/models/10nal-es_es-en/checkpoint_best.pt\n",
      "2022-11-01 21:12:50 | INFO | fairseq.tasks.translation_multi_simple_epoch | loading data for test epoch=1/None\n",
      "2022-11-01 21:12:50 | INFO | fairseq.tasks.translation_multi_simple_epoch | mem usage: N/A\n",
      "2022-11-01 21:12:50 | INFO | fairseq.data.multilingual.multilingual_data_manager | langtoks settings: {'main': ('src', 'tgt')}\n",
      "2022-11-01 21:12:50 | INFO | fairseq.data.multilingual.multilingual_data_manager | [test] num of shards: {'main:es-en': 1}\n",
      "2022-11-01 21:12:50 | INFO | fairseq.data.multilingual.multilingual_data_manager | main:es-en src_langtok: 29292; tgt_langtok: 29291\n",
      "2022-11-01 21:12:50 | INFO | fairseq.data.data_utils | loaded 1,000 examples from: /storage/master-thesis/models/10nal-es_es-en/tokenizers/10nal-es-en/bin/test.es-en.es\n",
      "2022-11-01 21:12:50 | INFO | fairseq.data.multilingual.multilingual_data_manager | /storage/master-thesis/models/10nal-es_es-en/tokenizers/10nal-es-en/bin test es-en 1000 examples\n",
      "2022-11-01 21:12:56 | INFO | fairseq.tasks.translation_multi_simple_epoch | start batch sampler: mem usage: N/A\n",
      "2022-11-01 21:12:56 | INFO | fairseq.tasks.translation_multi_simple_epoch | [test] @batch_sampler order indices time: 0:00:00.000548\n",
      "2022-11-01 21:12:56 | INFO | fairseq.tasks.translation_multi_simple_epoch | mem usage: N/A\n",
      "2022-11-01 21:12:56 | INFO | fairseq.tasks.translation_multi_simple_epoch | [test] @batch_sampler filter_by_size time: 0:00:00.005424\n",
      "2022-11-01 21:12:56 | INFO | fairseq.tasks.translation_multi_simple_epoch | mem usage: N/A\n",
      "2022-11-01 21:12:56 | INFO | fairseq.tasks.translation_multi_simple_epoch | [test] @batch_sampler batch_by_size time: 0:00:00.006072\n",
      "2022-11-01 21:12:56 | INFO | fairseq.tasks.translation_multi_simple_epoch | [test] per epoch batch_sampler set-up time: 0:00:00.012559\n",
      "2022-11-01 21:12:56 | INFO | fairseq.tasks.translation_multi_simple_epoch | mem usage: N/A\n",
      "2022-11-01 21:13:06 | INFO | fairseq_cli.generate | NOTE: hypothesis and token scores are output in base 2����| 5/5 [00:10<00:00,  1.92s/it, wps=1875]\n",
      "2022-11-01 21:13:06 | INFO | fairseq_cli.generate | Translated 1,000 sentences (19,158 tokens) in 7.3s (136.96 sentences/s, 2623.80 tokens/s)\n"
     ]
    }
   ],
   "source": [
    "! PYTHONIOENCODING=utf-8 fairseq-generate $(eval echo $TOKENIZER_PATH)/bin \\\n",
    "    --path $(eval echo $MODEL_DIR)/checkpoint_best.pt  \\\n",
    "    $(eval echo $MODEL_PARAM) \\\n",
    "    --source-lang $PIV_LANG --target-lang $TGT_LANG \\\n",
    "    --max-tokens 6000 \\\n",
    "    --task translation_multi_simple_epoch \\\n",
    "    --encoder-langtok \"src\" \\\n",
    "    --decoder-langtok \\\n",
    "    --lang-pairs $LANG_PAIRS \\\n",
    "    --print-alignment > $(eval echo $MODEL_DIR)/${PIV_LANG}_${TGT_LANG}.${TGT_LANG}.out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "!cat $(eval echo $MODEL_DIR)/${PIV_LANG}_${TGT_LANG}.${TGT_LANG}.out | grep -P \"^H\" |sort -V |cut -f 3- | sed \"s/ ##//g\" > $(eval echo $MODEL_DIR)/${PIV_LANG}_${TGT_LANG}.${TGT_LANG}.hyp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "gold_lines=[]\n",
    "with open(src_tgt_test_corpus + \"test.\" + tgt_lang, encoding='utf8') as f:\n",
    "  gold_lines = f.readlines()\n",
    "  gold_lines = [x.strip(\"\\n\") for x in gold_lines]\n",
    "\n",
    "\n",
    "system_lines = []\n",
    "with open(model_dir + piv_lang + \"_\" + tgt_lang + \".\" + tgt_lang + \".hyp\", encoding='utf8') as f:\n",
    "  system_lines = f.readlines()\n",
    "  system_lines = [x.strip(\"\\n\") for x in system_lines]\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "blanks = []\n",
    "for i in range(0,len(gold_lines)):\n",
    "    if gold_lines[i] == \"\":\n",
    "        blanks.append(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[]\n",
      "[]\n"
     ]
    }
   ],
   "source": [
    "print(blanks)\n",
    "blanks.reverse()\n",
    "print(blanks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in blanks:\n",
    "    del gold_lines[i]\n",
    "    del system_lines[i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000\n",
      "1000\n"
     ]
    }
   ],
   "source": [
    "print(len(gold_lines))\n",
    "print(len(system_lines))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "They will be judged.\n",
      "\n",
      "Then everyone stayed there , everyone stayed .\n"
     ]
    }
   ],
   "source": [
    "print(gold_lines[200])\n",
    "print()\n",
    "print(system_lines[200])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SCORE SRC->PIV->TGT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "That's 100 lines that end in a tokenized period ('.')\n",
      "It looks like you forgot to detokenize your test data, which may hurt your score.\n",
      "If you insist your data is detokenized, or don't care, you can suppress this message with the `force` parameter.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#### Score Report ####\n",
      "chrF2 = 12.97\n",
      "BLEU = 1.02 19.1/1.7/0.4/0.2 (BP = 0.830 ratio = 0.843 hyp_len = 15904 ref_len = 18871)\n"
     ]
    }
   ],
   "source": [
    "calculate_score_report(system_lines, [gold_lines], score_only=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## generating src->tgt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading file /notebooks/master-thesis/corpora/tatoeba-challenge/en-nah/test.nah\n",
      "/storage/master-thesis/models/10nal-es_es-en/tokenizers/10nal-es-en/test.nah\n"
     ]
    }
   ],
   "source": [
    "tokenize_files(tokenizer, [src_tgt_test_corpus + 'test.' + src_lang], src_lang, tokenizer_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-11-01 21:13:10 | INFO | fairseq_cli.preprocess | Namespace(aim_repo=None, aim_run_hash=None, align_suffix=None, alignfile=None, all_gather_list_size=16384, amp=False, amp_batch_retries=2, amp_init_scale=128, amp_scale_window=None, azureml_logging=False, bf16=False, bpe=None, cpu=False, criterion='cross_entropy', dataset_impl='mmap', destdir='/storage/master-thesis/models/10nal-es_es-en/tokenizers/10nal-es-en/bin/', dict_only=False, empty_cache_freq=0, fp16=False, fp16_init_scale=128, fp16_no_flatten_grads=False, fp16_scale_tolerance=0.0, fp16_scale_window=None, joined_dictionary=True, log_file=None, log_format=None, log_interval=100, lr_scheduler='fixed', memory_efficient_bf16=False, memory_efficient_fp16=False, min_loss_scale=0.0001, model_parallel_size=1, no_progress_bar=False, nwordssrc=-1, nwordstgt=-1, on_cpu_convert_precision=False, only_source=True, optimizer=None, padding_factor=8, plasma_path='/tmp/plasma', profile=False, quantization_config_path=None, reset_logging=False, scoring='bleu', seed=1, source_lang='nah', srcdict='/storage/master-thesis/models/10nal-es_es-en/tokenizers/10nal-es-en/bin/dict.all.txt', suppress_crashes=False, target_lang='en', task='translation_multi_simple_epoch', tensorboard_logdir=None, testpref='/storage/master-thesis/models/10nal-es_es-en/tokenizers/10nal-es-en/test', tgtdict=None, threshold_loss_scale=None, thresholdsrc=0, thresholdtgt=0, tokenizer=None, tpu=False, trainpref=None, use_plasma_view=False, user_dir=None, validpref=None, wandb_project=None, workers=20)\n",
      "2022-11-01 21:13:11 | INFO | fairseq_cli.preprocess | [nah] Dictionary: 29288 types\n",
      "2022-11-01 21:13:11 | INFO | fairseq_cli.preprocess | [nah] /storage/master-thesis/models/10nal-es_es-en/tokenizers/10nal-es-en/test.nah: 1000 sents, 34779 tokens, 0.0% replaced (by <unk>)\n",
      "2022-11-01 21:13:11 | INFO | fairseq_cli.preprocess | Wrote preprocessed data to /storage/master-thesis/models/10nal-es_es-en/tokenizers/10nal-es-en/bin/\n"
     ]
    }
   ],
   "source": [
    "! fairseq-preprocess --source-lang $SRC_LANG --target-lang $TGT_LANG \\\n",
    "    --testpref $(eval echo $TOKENIZER_PATH)/test \\\n",
    "    --destdir $(eval echo $TOKENIZER_PATH)/bin/ \\\n",
    "    --workers 20 \\\n",
    "    --srcdict $(eval echo $TOKENIZER_PATH)/bin/dict.all.txt \\\n",
    "    --task translation_multi_simple_epoch \\\n",
    "    --joined-dictionary \\\n",
    "    --only-source"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-11-01 21:13:15 | INFO | fairseq_cli.generate | {'_name': None, 'common': {'_name': None, 'no_progress_bar': False, 'log_interval': 100, 'log_format': None, 'log_file': None, 'aim_repo': None, 'aim_run_hash': None, 'tensorboard_logdir': None, 'wandb_project': None, 'azureml_logging': False, 'seed': 1, 'cpu': False, 'tpu': False, 'bf16': False, 'memory_efficient_bf16': False, 'fp16': False, 'memory_efficient_fp16': False, 'fp16_no_flatten_grads': False, 'fp16_init_scale': 128, 'fp16_scale_window': None, 'fp16_scale_tolerance': 0.0, 'on_cpu_convert_precision': False, 'min_loss_scale': 0.0001, 'threshold_loss_scale': None, 'amp': False, 'amp_batch_retries': 2, 'amp_init_scale': 128, 'amp_scale_window': None, 'user_dir': None, 'empty_cache_freq': 0, 'all_gather_list_size': 16384, 'model_parallel_size': 1, 'quantization_config_path': None, 'profile': False, 'reset_logging': False, 'suppress_crashes': False, 'use_plasma_view': False, 'plasma_path': '/tmp/plasma'}, 'common_eval': {'_name': None, 'path': '/storage/master-thesis/models/10nal-es_es-en/checkpoint_best.pt', 'post_process': None, 'quiet': False, 'model_overrides': '{}', 'results_path': None}, 'distributed_training': {'_name': None, 'distributed_world_size': 1, 'distributed_num_procs': 1, 'distributed_rank': 0, 'distributed_backend': 'nccl', 'distributed_init_method': None, 'distributed_port': -1, 'device_id': 0, 'distributed_no_spawn': False, 'ddp_backend': 'pytorch_ddp', 'ddp_comm_hook': 'none', 'bucket_cap_mb': 25, 'fix_batches_to_gpus': False, 'find_unused_parameters': False, 'gradient_as_bucket_view': False, 'fast_stat_sync': False, 'heartbeat_timeout': -1, 'broadcast_buffers': False, 'slowmo_momentum': None, 'slowmo_base_algorithm': 'localsgd', 'localsgd_frequency': 3, 'nprocs_per_node': 1, 'pipeline_model_parallel': False, 'pipeline_balance': None, 'pipeline_devices': None, 'pipeline_chunks': 0, 'pipeline_encoder_balance': None, 'pipeline_encoder_devices': None, 'pipeline_decoder_balance': None, 'pipeline_decoder_devices': None, 'pipeline_checkpoint': 'never', 'zero_sharding': 'none', 'fp16': False, 'memory_efficient_fp16': False, 'tpu': False, 'no_reshard_after_forward': False, 'fp32_reduce_scatter': False, 'cpu_offload': False, 'use_sharded_state': False, 'not_fsdp_flatten_parameters': False}, 'dataset': {'_name': None, 'num_workers': 1, 'skip_invalid_size_inputs_valid_test': False, 'max_tokens': 6000, 'batch_size': None, 'required_batch_size_multiple': 8, 'required_seq_len_multiple': 1, 'dataset_impl': None, 'data_buffer_size': 10, 'train_subset': 'train', 'valid_subset': 'valid', 'combine_valid_subsets': None, 'ignore_unused_valid_subsets': False, 'validate_interval': 1, 'validate_interval_updates': 0, 'validate_after_updates': 0, 'fixed_validation_seed': None, 'disable_validation': False, 'max_tokens_valid': 6000, 'batch_size_valid': None, 'max_valid_steps': None, 'curriculum': 0, 'gen_subset': 'test', 'num_shards': 1, 'shard_id': 0, 'grouped_shuffling': False, 'update_epoch_batch_itr': False, 'update_ordered_indices_seed': False}, 'optimization': {'_name': None, 'max_epoch': 0, 'max_update': 0, 'stop_time_hours': 0.0, 'clip_norm': 0.0, 'sentence_avg': False, 'update_freq': [1], 'lr': [0.25], 'stop_min_lr': -1.0, 'use_bmuf': False, 'skip_remainder_batch': False}, 'checkpoint': {'_name': None, 'save_dir': 'checkpoints', 'restore_file': 'checkpoint_last.pt', 'continue_once': None, 'finetune_from_model': None, 'reset_dataloader': False, 'reset_lr_scheduler': False, 'reset_meters': False, 'reset_optimizer': False, 'optimizer_overrides': '{}', 'save_interval': 1, 'save_interval_updates': 0, 'keep_interval_updates': -1, 'keep_interval_updates_pattern': -1, 'keep_last_epochs': -1, 'keep_best_checkpoints': -1, 'no_save': False, 'no_epoch_checkpoints': False, 'no_last_checkpoints': False, 'no_save_optimizer_state': False, 'best_checkpoint_metric': 'loss', 'maximize_best_checkpoint_metric': False, 'patience': -1, 'checkpoint_suffix': '', 'checkpoint_shard_count': 1, 'load_checkpoint_on_all_dp_ranks': False, 'write_checkpoints_asynchronously': False, 'model_parallel_size': 1}, 'bmuf': {'_name': None, 'block_lr': 1.0, 'block_momentum': 0.875, 'global_sync_iter': 50, 'warmup_iterations': 500, 'use_nbm': False, 'average_sync': False, 'distributed_world_size': 1}, 'generation': {'_name': None, 'beam': 5, 'nbest': 1, 'max_len_a': 0.0, 'max_len_b': 200, 'min_len': 1, 'match_source_len': False, 'unnormalized': False, 'no_early_stop': False, 'no_beamable_mm': False, 'lenpen': 1.0, 'unkpen': 0.0, 'replace_unk': None, 'sacrebleu': False, 'score_reference': False, 'prefix_size': 0, 'no_repeat_ngram_size': 0, 'sampling': False, 'sampling_topk': -1, 'sampling_topp': -1.0, 'constraints': None, 'temperature': 1.0, 'diverse_beam_groups': -1, 'diverse_beam_strength': 0.5, 'diversity_rate': -1.0, 'print_alignment': 'hard', 'print_step': False, 'lm_path': None, 'lm_weight': 0.0, 'iter_decode_eos_penalty': 0.0, 'iter_decode_max_iter': 10, 'iter_decode_force_max_iter': False, 'iter_decode_with_beam': 1, 'iter_decode_with_external_reranker': False, 'retain_iter_history': False, 'retain_dropout': False, 'retain_dropout_modules': None, 'decoding_format': None, 'no_seed_provided': False, 'eos_token': None}, 'eval_lm': {'_name': None, 'output_word_probs': False, 'output_word_stats': False, 'context_window': 0, 'softmax_batch': 9223372036854775807}, 'interactive': {'_name': None, 'buffer_size': 0, 'input': '-'}, 'model': {'_name': 'wav2vec2', 'extractor_mode': 'default', 'encoder_layers': 12, 'encoder_embed_dim': 768, 'encoder_ffn_embed_dim': 3072, 'encoder_attention_heads': 12, 'activation_fn': 'gelu', 'layer_type': 'transformer', 'dropout': 0.1, 'attention_dropout': 0.1, 'activation_dropout': 0.0, 'encoder_layerdrop': 0.0, 'dropout_input': 0.0, 'dropout_features': 0.0, 'final_dim': 0, 'layer_norm_first': False, 'conv_feature_layers': '[(512, 10, 5)] + [(512, 3, 2)] * 4 + [(512,2,2)] + [(512,2,2)]', 'conv_bias': False, 'logit_temp': 0.1, 'quantize_targets': False, 'quantize_input': False, 'same_quantizer': False, 'target_glu': False, 'feature_grad_mult': 1.0, 'quantizer_depth': 1, 'quantizer_factor': 3, 'latent_vars': 320, 'latent_groups': 2, 'latent_dim': 0, 'mask_length': 10, 'mask_prob': 0.65, 'mask_selection': 'static', 'mask_other': 0.0, 'no_mask_overlap': False, 'mask_min_space': 1, 'require_same_masks': True, 'mask_dropout': 0.0, 'mask_channel_length': 10, 'mask_channel_prob': 0.0, 'mask_channel_before': False, 'mask_channel_selection': 'static', 'mask_channel_other': 0.0, 'no_mask_channel_overlap': False, 'mask_channel_min_space': 1, 'num_negatives': 100, 'negatives_from_everywhere': False, 'cross_sample_negatives': 0, 'codebook_negatives': 0, 'conv_pos': 128, 'conv_pos_groups': 16, 'pos_conv_depth': 1, 'latent_temp': [2.0, 0.5, 0.999995], 'max_positions': 100000, 'checkpoint_activations': False, 'required_seq_len_multiple': 1, 'crop_seq_to_multiple': 1, 'depthwise_conv_kernel_size': 31, 'attn_type': '', 'pos_enc_type': 'abs', 'fp16': False}, 'task': Namespace(_name='translation_multi_simple_epoch', aim_repo=None, aim_run_hash=None, all_gather_list_size=16384, amp=False, amp_batch_retries=2, amp_init_scale=128, amp_scale_window=None, arch='wav2vec2', azureml_logging=False, batch_size=None, batch_size_valid=None, beam=5, best_checkpoint_metric='loss', bf16=False, bpe=None, broadcast_buffers=False, bucket_cap_mb=25, checkpoint_shard_count=1, checkpoint_suffix='', combine_valid_subsets=None, constraints=None, continue_once=None, cpu=False, cpu_offload=False, criterion='cross_entropy', curriculum=0, data='/storage/master-thesis/models/10nal-es_es-en/tokenizers/10nal-es-en/bin', data_buffer_size=10, dataset_impl=None, ddp_backend='pytorch_ddp', ddp_comm_hook='none', decoder_langtok=True, decoding_format=None, device_id=0, disable_validation=False, distributed_backend='nccl', distributed_init_method=None, distributed_no_spawn=False, distributed_num_procs=1, distributed_port=-1, distributed_rank=0, distributed_world_size=1, diverse_beam_groups=-1, diverse_beam_strength=0.5, diversity_rate=-1.0, empty_cache_freq=0, enable_lang_ids=False, enable_reservsed_directions_shared_datasets=False, encoder_langtok='src', eos=2, eos_token=None, extra_data=None, extra_lang_pairs=None, fast_stat_sync=False, find_unused_parameters=False, finetune_from_model=None, fix_batches_to_gpus=False, fixed_dictionary=None, fixed_validation_seed=None, force_anneal=None, fp16=False, fp16_init_scale=128, fp16_no_flatten_grads=False, fp16_scale_tolerance=0.0, fp16_scale_window=None, fp32_reduce_scatter=False, gen_subset='test', gradient_as_bucket_view=False, grouped_shuffling=False, heartbeat_timeout=-1, ignore_unused_valid_subsets=False, iter_decode_eos_penalty=0.0, iter_decode_force_max_iter=False, iter_decode_max_iter=10, iter_decode_with_beam=1, iter_decode_with_external_reranker=False, keep_best_checkpoints=-1, keep_inference_langtok=False, keep_interval_updates=-1, keep_interval_updates_pattern=-1, keep_last_epochs=-1, lang_dict=None, lang_pairs='quy-es,cni-es,aym-es,bzd-es,gn-es,oto-es,nah-es,tar-es,shp-es,hch-es,es-en', lang_tok_replacing_bos_eos=False, lang_tok_style='multilingual', langs=None, langtoks=None, langtoks_specs=['main'], left_pad_source='True', left_pad_target='False', lenpen=1, lm_path=None, lm_weight=0.0, load_alignments=False, load_checkpoint_on_all_dp_ranks=False, localsgd_frequency=3, log_file=None, log_format=None, log_interval=100, lr_scheduler='fixed', lr_shrink=0.1, match_source_len=False, max_len_a=0, max_len_b=200, max_source_positions=1024, max_target_positions=1024, max_tokens=6000, max_tokens_valid=6000, max_valid_steps=None, maximize_best_checkpoint_metric=False, memory_efficient_bf16=False, memory_efficient_fp16=False, min_len=1, min_loss_scale=0.0001, model_overrides='{}', model_parallel_size=1, nbest=1, no_beamable_mm=False, no_early_stop=False, no_epoch_checkpoints=False, no_last_checkpoints=False, no_progress_bar=False, no_repeat_ngram_size=0, no_reshard_after_forward=False, no_save=False, no_save_optimizer_state=False, no_seed_provided=False, not_fsdp_flatten_parameters=False, nprocs_per_node=1, num_shards=1, num_workers=1, on_cpu_convert_precision=False, optimizer=None, optimizer_overrides='{}', pad=1, path='/storage/master-thesis/models/10nal-es_es-en/checkpoint_best.pt', patience=-1, pipeline_balance=None, pipeline_checkpoint='never', pipeline_chunks=0, pipeline_decoder_balance=None, pipeline_decoder_devices=None, pipeline_devices=None, pipeline_encoder_balance=None, pipeline_encoder_devices=None, pipeline_model_parallel=False, plasma_path='/tmp/plasma', post_process=None, prefix_size=0, print_alignment='hard', print_step=False, profile=False, quantization_config_path=None, quiet=False, replace_unk=None, required_batch_size_multiple=8, required_seq_len_multiple=1, reset_dataloader=False, reset_logging=False, reset_lr_scheduler=False, reset_meters=False, reset_optimizer=False, restore_file='checkpoint_last.pt', results_path=None, retain_dropout=False, retain_dropout_modules=None, retain_iter_history=False, sacrebleu=False, sampling=False, sampling_method='concat', sampling_temperature=1.5, sampling_topk=-1, sampling_topp=-1.0, sampling_weights=None, sampling_weights_from_file=None, save_dir='checkpoints', save_interval=1, save_interval_updates=0, score_reference=False, scoring='bleu', seed=1, shard_id=0, skip_invalid_size_inputs_valid_test=False, slowmo_base_algorithm='localsgd', slowmo_momentum=None, source_dict=None, source_lang='nah', suppress_crashes=False, target_dict=None, target_lang='en', task='translation_multi_simple_epoch', temperature=1.0, tensorboard_logdir=None, threshold_loss_scale=None, tokenizer=None, tpu=False, train_subset='train', truncate_source=False, unk=3, unkpen=0, unnormalized=False, update_epoch_batch_itr=False, update_ordered_indices_seed=False, upsample_primary=1, use_plasma_view=False, use_sharded_state=False, user_dir=None, valid_subset='valid', validate_after_updates=0, validate_interval=1, validate_interval_updates=0, virtual_data_size=None, virtual_epoch_size=None, wandb_project=None, warmup_updates=0, write_checkpoints_asynchronously=False, zero_sharding='none'), 'criterion': {'_name': 'cross_entropy', 'sentence_avg': True}, 'optimizer': None, 'lr_scheduler': {'_name': 'fixed', 'force_anneal': None, 'lr_shrink': 0.1, 'warmup_updates': 0, 'lr': [0.25]}, 'scoring': {'_name': 'bleu', 'pad': 1, 'eos': 2, 'unk': 3}, 'bpe': None, 'tokenizer': None, 'ema': {'_name': None, 'store_ema': False, 'ema_decay': 0.9999, 'ema_start_update': 0, 'ema_seed_model': None, 'ema_update_freq': 1, 'ema_fp32': False}}\n",
      "2022-11-01 21:13:15 | WARNING | fairseq.data.multilingual.multilingual_data_manager | External language dictionary is not provided; use lang-pairs to infer the set of supported languages. The language ordering is not stable which might cause misalignment in pretraining and finetuning.\n",
      "2022-11-01 21:13:15 | INFO | fairseq.data.multilingual.multilingual_data_manager | inferred language list: ['aym', 'bzd', 'cni', 'en', 'es', 'gn', 'hch', 'nah', 'oto', 'quy', 'shp', 'tar']\n",
      "2022-11-01 21:13:15 | INFO | fairseq.data.multilingual.multilingual_data_manager | [nah] dictionary: 29300 types\n",
      "2022-11-01 21:13:15 | INFO | fairseq.data.multilingual.multilingual_data_manager | [en] dictionary: 29300 types\n",
      "2022-11-01 21:13:15 | INFO | fairseq_cli.generate | loading model(s) from /storage/master-thesis/models/10nal-es_es-en/checkpoint_best.pt\n",
      "2022-11-01 21:13:19 | INFO | fairseq.tasks.translation_multi_simple_epoch | loading data for test epoch=1/None\n",
      "2022-11-01 21:13:19 | INFO | fairseq.tasks.translation_multi_simple_epoch | mem usage: N/A\n",
      "2022-11-01 21:13:19 | INFO | fairseq.data.multilingual.multilingual_data_manager | langtoks settings: {'main': ('src', 'tgt')}\n",
      "2022-11-01 21:13:19 | INFO | fairseq.data.multilingual.multilingual_data_manager | [test] num of shards: {'main:nah-en': 1}\n",
      "2022-11-01 21:13:19 | INFO | fairseq.data.multilingual.multilingual_data_manager | main:nah-en src_langtok: 29295; tgt_langtok: 29291\n",
      "2022-11-01 21:13:19 | INFO | fairseq.data.data_utils | loaded 1,000 examples from: /storage/master-thesis/models/10nal-es_es-en/tokenizers/10nal-es-en/bin/test.nah-en.nah\n",
      "2022-11-01 21:13:19 | INFO | fairseq.data.multilingual.multilingual_data_manager | /storage/master-thesis/models/10nal-es_es-en/tokenizers/10nal-es-en/bin test nah-en 1000 examples\n",
      "2022-11-01 21:13:24 | INFO | fairseq.tasks.translation_multi_simple_epoch | start batch sampler: mem usage: N/A\n",
      "2022-11-01 21:13:24 | INFO | fairseq.tasks.translation_multi_simple_epoch | [test] @batch_sampler order indices time: 0:00:00.000599\n",
      "2022-11-01 21:13:24 | INFO | fairseq.tasks.translation_multi_simple_epoch | mem usage: N/A\n",
      "2022-11-01 21:13:24 | INFO | fairseq.tasks.translation_multi_simple_epoch | [test] @batch_sampler filter_by_size time: 0:00:00.005579\n",
      "2022-11-01 21:13:24 | INFO | fairseq.tasks.translation_multi_simple_epoch | mem usage: N/A\n",
      "2022-11-01 21:13:24 | INFO | fairseq.tasks.translation_multi_simple_epoch | [test] @batch_sampler batch_by_size time: 0:00:00.006158\n",
      "2022-11-01 21:13:24 | INFO | fairseq.tasks.translation_multi_simple_epoch | [test] per epoch batch_sampler set-up time: 0:00:00.012944\n",
      "2022-11-01 21:13:24 | INFO | fairseq.tasks.translation_multi_simple_epoch | mem usage: N/A\n",
      "2022-11-01 21:13:38 | INFO | fairseq_cli.generate | NOTE: hypothesis and token scores are output in base 2����| 8/8 [00:14<00:00,  1.58s/it, wps=1475]\n",
      "2022-11-01 21:13:38 | INFO | fairseq_cli.generate | Translated 1,000 sentences (20,889 tokens) in 10.0s (99.69 sentences/s, 2082.49 tokens/s)\n"
     ]
    }
   ],
   "source": [
    "! PYTHONIOENCODING=utf-8 fairseq-generate $(eval echo $TOKENIZER_PATH)/bin \\\n",
    "    --path $(eval echo $MODEL_DIR)/checkpoint_best.pt  \\\n",
    "    $(eval echo $MODEL_PARAM) \\\n",
    "    --source-lang $SRC_LANG --target-lang $TGT_LANG \\\n",
    "    --max-tokens 6000 \\\n",
    "    --task translation_multi_simple_epoch \\\n",
    "    --encoder-langtok \"src\" \\\n",
    "    --decoder-langtok \\\n",
    "    --lang-pairs $LANG_PAIRS \\\n",
    "    --print-alignment > $(eval echo $MODEL_DIR)/${SRC_LANG}_${TGT_LANG}.${TGT_LANG}.out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "!cat $(eval echo $MODEL_DIR)/${SRC_LANG}_${TGT_LANG}.${TGT_LANG}.out | grep -P \"^H\" |sort -V |cut -f 3- | sed \"s/ ##//g\" > $(eval echo $MODEL_DIR)/${SRC_LANG}_${TGT_LANG}.${TGT_LANG}.hyp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "gold_lines=[]\n",
    "with open(src_tgt_test_corpus + \"test.\" + tgt_lang, encoding='utf8') as f:\n",
    "  gold_lines = f.readlines()\n",
    "  gold_lines = [x.strip(\"\\n\") for x in gold_lines]\n",
    "\n",
    "\n",
    "system_lines = []\n",
    "with open(model_dir + src_lang + \"_\" + tgt_lang + \".\" + tgt_lang + \".hyp\", encoding='utf8') as f:\n",
    "  system_lines = f.readlines()\n",
    "  system_lines = [x.strip(\"\\n\") for x in system_lines]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "blanks = []\n",
    "for i in range(0,len(gold_lines)):\n",
    "    if gold_lines[i] == \"\":\n",
    "        blanks.append(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[]\n",
      "[]\n"
     ]
    }
   ],
   "source": [
    "print(blanks)\n",
    "blanks.reverse()\n",
    "print(blanks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in blanks:\n",
    "    del gold_lines[i]\n",
    "    del system_lines[i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000\n",
      "1000\n"
     ]
    }
   ],
   "source": [
    "print(len(gold_lines))\n",
    "print(len(system_lines))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Countless millions, their number known only to God, will live again.\n",
      "\n",
      "Después se cortan las hojas de maíz tostado , se hieren y se ponen a cocerlo .\n"
     ]
    }
   ],
   "source": [
    "print(gold_lines[100])\n",
    "print()\n",
    "print(system_lines[100])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SCORE SRC->TGT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "That's 100 lines that end in a tokenized period ('.')\n",
      "It looks like you forgot to detokenize your test data, which may hurt your score.\n",
      "If you insist your data is detokenized, or don't care, you can suppress this message with the `force` parameter.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#### Score Report ####\n",
      "chrF2 = 11.67\n",
      "BLEU = 0.85 11.8/0.9/0.4/0.2 (BP = 0.913 ratio = 0.916 hyp_len = 17288 ref_len = 18871)\n"
     ]
    }
   ],
   "source": [
    "calculate_score_report(system_lines, [gold_lines], score_only=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
