{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ENVIRONMENT VARIABLES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "EN_ES_CORPUS_DIR = \"/notebooks/master-thesis/corpora/tatoeba-challenge/en-es/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "AYM_ES_CORPUS_DIR = \"/notebooks/master-thesis/corpora/americasnlp2021/data/aymara-spanish\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer_path = \"/storage/master-thesis/models/aym-es++es-en/tokenizers/aym-es-en/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "env: TOKENIZER_PATH=/storage/master-thesis/models/nah-es++es-en/tokenizers/nah-es-en\n"
     ]
    }
   ],
   "source": [
    "%env TOKENIZER_PATH = /storage/master-thesis/models/aym-es++es-en/tokenizers/aym-es-en"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenized_path_es_en = \"/storage/master-thesis/models/aym-es++es-en/tokenizers/aym-es-en/es-en/\"\n",
    "tokenized_path_aym_es = \"/storage/master-thesis/models/aym-es++es-en/tokenizers/aym-es-en/aym-es/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "env: TOKENIZED_PATH_ES_EN=/storage/master-thesis/models/nah-es++es-en/tokenizers/nah-es-en/es-en\n",
      "env: TOKENIZED_PATH_NAH_ES=/storage/master-thesis/models/nah-es++es-en/tokenizers/nah-es-en/nah-es\n"
     ]
    }
   ],
   "source": [
    "%env TOKENIZED_PATH_ES_EN = /storage/master-thesis/models/aym-es++es-en/tokenizers/aym-es-en/es-en\n",
    "%env TOKENIZED_PATH_AYM_ES = /storage/master-thesis/models/aym-es++es-en/tokenizers/aym-es-en/aym-es"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "env: BIN_DIR=/storage/master-thesis/models/nah-es++es-en/tokenizers/nah-es-en/bin\n"
     ]
    }
   ],
   "source": [
    "%env BIN_DIR = /storage/master-thesis/models/aym-es++es-en/tokenizers/aym-es-en/bin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "! mkdir -p $TOKENIZED_PATH_ES_EN\n",
    "! mkdir -p $TOKENIZED_PATH_AYM_ES\n",
    "! mkdir -p $BIN_DIR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "env: MODEL_DIR=/storage/master-thesis/models/nah-es++es-en\n"
     ]
    }
   ],
   "source": [
    "%env MODEL_DIR = /storage/master-thesis/models/aym-es++es-en"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LANG=\n",
      "LANGUAGE=\n",
      "LC_CTYPE=\"POSIX\"\n",
      "LC_NUMERIC=\"POSIX\"\n",
      "LC_TIME=\"POSIX\"\n",
      "LC_COLLATE=\"POSIX\"\n",
      "LC_MONETARY=\"POSIX\"\n",
      "LC_MESSAGES=\"POSIX\"\n",
      "LC_PAPER=\"POSIX\"\n",
      "LC_NAME=\"POSIX\"\n",
      "LC_ADDRESS=\"POSIX\"\n",
      "LC_TELEPHONE=\"POSIX\"\n",
      "LC_MEASUREMENT=\"POSIX\"\n",
      "LC_IDENTIFICATION=\"POSIX\"\n",
      "LC_ALL=\n"
     ]
    }
   ],
   "source": [
    "! locale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/bin/sh: 1: update-locale: not found\n",
      "env: LANG=en_US.UTF-8\n",
      "env: LC_CTYPE=en_US.UTF-8\n",
      "env: LC_ALL=en_US.UTF-8\n"
     ]
    }
   ],
   "source": [
    "! update-locale LANG=en_US.UTF-8 LANGUAGE=en.UTF-8\n",
    "\n",
    "%env LANG=en_US.UTF-8\n",
    "%env LC_CTYPE=en_US.UTF-8\n",
    "%env LC_ALL=en_US.UTF-8"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: tokenizers==0.10.3 in /usr/local/lib/python3.6/dist-packages (0.10.3)\n",
      "\u001b[33mWARNING: You are using pip version 20.2.4; however, version 21.3.1 is available.\n",
      "You should consider upgrading via the '/usr/bin/python3 -m pip install --upgrade pip' command.\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install tokenizers==0.10.3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found existing installation: torch 1.10.0+cu113\n",
      "Uninstalling torch-1.10.0+cu113:\n",
      "  Successfully uninstalled torch-1.10.0+cu113\n",
      "\u001b[33mWARNING: Skipping torchvision as it is not installed.\u001b[0m\n",
      "Found existing installation: torchaudio 0.10.0+cu113\n",
      "Uninstalling torchaudio-0.10.0+cu113:\n",
      "  Successfully uninstalled torchaudio-0.10.0+cu113\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip uninstall torch torchvision torchaudio -y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: https://pypi.org/simple, https://download.pytorch.org/whl/cu113\n",
      "Collecting torch\n",
      "  Using cached https://download.pytorch.org/whl/cu113/torch-1.10.2%2Bcu113-cp36-cp36m-linux_x86_64.whl (1821.5 MB)\n",
      "Collecting torchvision\n",
      "  Using cached https://download.pytorch.org/whl/cu113/torchvision-0.11.3%2Bcu113-cp36-cp36m-linux_x86_64.whl (24.6 MB)\n",
      "Collecting torchaudio\n",
      "  Using cached https://download.pytorch.org/whl/cu113/torchaudio-0.10.2%2Bcu113-cp36-cp36m-linux_x86_64.whl (2.9 MB)\n",
      "Requirement already satisfied: dataclasses; python_version < \"3.7\" in /usr/local/lib/python3.6/dist-packages (from torch) (0.8)\n",
      "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.6/dist-packages (from torch) (3.10.0.2)\n",
      "Requirement already satisfied: pillow!=8.3.0,>=5.3.0 in /usr/local/lib/python3.6/dist-packages (from torchvision) (8.3.2)\n",
      "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from torchvision) (1.18.5)\n",
      "Installing collected packages: torch, torchvision, torchaudio\n",
      "Successfully installed torch-1.10.2+cu113 torchaudio-0.10.2+cu113 torchvision-0.11.3+cu113\n",
      "\u001b[33mWARNING: You are using pip version 20.2.4; however, version 21.3.1 is available.\n",
      "You should consider upgrading via the '/usr/bin/python3 -m pip install --upgrade pip' command.\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install torch torchvision torchaudio --extra-index-url https://download.pytorch.org/whl/cu113"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mWARNING: Skipping fairseq as it is not installed.\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip uninstall fairseq -y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting fairseq\n",
      "  Using cached fairseq-0.12.2-cp36-cp36m-manylinux_2_5_x86_64.manylinux1_x86_64.whl (11.0 MB)\n",
      "Requirement already satisfied: cython in /usr/local/lib/python3.6/dist-packages (from fairseq) (0.29.24)\n",
      "Requirement already satisfied: dataclasses; python_version < \"3.7\" in /usr/local/lib/python3.6/dist-packages (from fairseq) (0.8)\n",
      "Requirement already satisfied: torch in /usr/local/lib/python3.6/dist-packages (from fairseq) (1.10.2)\n",
      "Requirement already satisfied: hydra-core<1.1,>=1.0.7 in /usr/local/lib/python3.6/dist-packages (from fairseq) (1.0.7)\n",
      "Requirement already satisfied: tqdm in /usr/local/lib/python3.6/dist-packages (from fairseq) (4.51.0)\n",
      "Requirement already satisfied: bitarray in /usr/local/lib/python3.6/dist-packages (from fairseq) (2.6.0)\n",
      "Requirement already satisfied: cffi in /usr/local/lib/python3.6/dist-packages (from fairseq) (1.14.3)\n",
      "Requirement already satisfied: numpy<1.20.0; python_version < \"3.7\" in /usr/local/lib/python3.6/dist-packages (from fairseq) (1.18.5)\n",
      "Requirement already satisfied: torchaudio>=0.8.0 in /usr/local/lib/python3.6/dist-packages (from fairseq) (0.10.1)\n",
      "Requirement already satisfied: omegaconf<2.1 in /usr/local/lib/python3.6/dist-packages (from fairseq) (2.0.6)\n",
      "Requirement already satisfied: sacrebleu>=1.4.12 in /usr/local/lib/python3.6/dist-packages (from fairseq) (2.0.0)\n",
      "Requirement already satisfied: regex in /usr/local/lib/python3.6/dist-packages (from fairseq) (2020.11.13)\n",
      "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.6/dist-packages (from torch->fairseq) (3.10.0.2)\n",
      "Requirement already satisfied: importlib-resources; python_version < \"3.9\" in /usr/local/lib/python3.6/dist-packages (from hydra-core<1.1,>=1.0.7->fairseq) (5.2.2)\n",
      "Requirement already satisfied: antlr4-python3-runtime==4.8 in /usr/local/lib/python3.6/dist-packages (from hydra-core<1.1,>=1.0.7->fairseq) (4.8)\n",
      "Requirement already satisfied: pycparser in /usr/local/lib/python3.6/dist-packages (from cffi->fairseq) (2.20)\n",
      "Requirement already satisfied: PyYAML>=5.1.* in /usr/local/lib/python3.6/dist-packages (from omegaconf<2.1->fairseq) (5.4.1)\n",
      "Requirement already satisfied: colorama in /usr/local/lib/python3.6/dist-packages (from sacrebleu>=1.4.12->fairseq) (0.4.4)\n",
      "Requirement already satisfied: portalocker in /usr/local/lib/python3.6/dist-packages (from sacrebleu>=1.4.12->fairseq) (2.3.2)\n",
      "Requirement already satisfied: tabulate>=0.8.9 in /usr/local/lib/python3.6/dist-packages (from sacrebleu>=1.4.12->fairseq) (0.8.9)\n",
      "Requirement already satisfied: zipp>=3.1.0; python_version < \"3.10\" in /usr/local/lib/python3.6/dist-packages (from importlib-resources; python_version < \"3.9\"->hydra-core<1.1,>=1.0.7->fairseq) (3.4.0)\n",
      "Installing collected packages: fairseq\n",
      "Successfully installed fairseq-0.12.2\n",
      "\u001b[33mWARNING: You are using pip version 20.2.4; however, version 21.3.1 is available.\n",
      "You should consider upgrading via the '/usr/bin/python3 -m pip install --upgrade pip' command.\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install fairseq # --no-deps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found existing installation: apex 0.1\n",
      "Uninstalling apex-0.1:\n",
      "  Successfully uninstalled apex-0.1\n"
     ]
    }
   ],
   "source": [
    "! pip uninstall apex -y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "rm -r apex"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#! git clone https://github.com/NVIDIA/apex\n",
    "\n",
    "! pip install -v --disable-pip-version-check --no-cache-dir apex"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/\n"
     ]
    }
   ],
   "source": [
    "cd .."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting tensorboardX\n",
      "  Downloading tensorboardX-2.5.1-py2.py3-none-any.whl (125 kB)\n",
      "\u001b[K     |################################| 125 kB 34.2 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from tensorboardX) (1.18.5)\n",
      "Requirement already satisfied: protobuf<=3.20.1,>=3.8.0 in /usr/local/lib/python3.6/dist-packages (from tensorboardX) (3.13.0)\n",
      "Requirement already satisfied: six>=1.9 in /usr/local/lib/python3.6/dist-packages (from protobuf<=3.20.1,>=3.8.0->tensorboardX) (1.15.0)\n",
      "Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from protobuf<=3.20.1,>=3.8.0->tensorboardX) (50.3.2)\n",
      "Installing collected packages: tensorboardX\n",
      "Successfully installed tensorboardX-2.5.1\n",
      "\u001b[33mWARNING: You are using pip version 20.2.4; however, version 21.3.1 is available.\n",
      "You should consider upgrading via the '/usr/bin/python3 -m pip install --upgrade pip' command.\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install tensorboardX"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Converting tatoeba format to standard format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "\n",
    "with open(EN_ES_CORPUS_DIR + \"original/valid.txt\", encoding='utf8') as f:\n",
    "    es = open(EN_ES_CORPUS_DIR + \"dev.es\", 'w', encoding='utf8')\n",
    "    en = open(EN_ES_CORPUS_DIR + \"dev.en\", 'w', encoding='utf8')\n",
    "    for line in csv.reader(f, delimiter=\"\\t\"):\n",
    "        es.write(line[3] + \"\\n\")\n",
    "        en.write(line[2] + \"\\n\")\n",
    "    en.close()\n",
    "    es.close()\n",
    "    \n",
    "with open(EN_ES_CORPUS_DIR + \"original/dev.txt\", encoding='utf8') as f:\n",
    "    es = open(EN_ES_CORPUS_DIR + \"train.es\", 'w', encoding='utf8')\n",
    "    en = open(EN_ES_CORPUS_DIR + \"train.en\", 'w', encoding='utf8')\n",
    "    for line in csv.reader(f, delimiter=\"\\t\"):\n",
    "        if \"\\n\" in line[2] or \"\\n\" in line[3]:\n",
    "            continue\n",
    "        if len(line) != 4:\n",
    "            continue\n",
    "            \n",
    "        es.write(line[3] + \"\\n\")\n",
    "        en.write(line[2] + \"\\n\")\n",
    "        \n",
    "    en.close()\n",
    "    es.close()\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tokenizing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tokenizers import Tokenizer\n",
    "from tokenizers.models import WordPiece\n",
    "\n",
    "en_es_aym_tokenizer = Tokenizer(WordPiece(unk_token=\"[UNK]\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tokenizers.trainers import WordPieceTrainer\n",
    "\n",
    "en_es_aym_trainer = WordPieceTrainer(special_tokens=[\"[UNK]\", \"[CLS]\", \"[SEP]\", \"[PAD]\", \"[MASK]\"], show_progress=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tokenizers.pre_tokenizers import Whitespace\n",
    "\n",
    "en_es_aym_tokenizer.pre_tokenizer = Whitespace()\n",
    "\n",
    "en_files = [f\"/notebooks/master-thesis/corpora/tatoeba-challenge/en-es/{split}.en\" for split in [\"dev\", \"train\"]]\n",
    "es_files = [f\"/notebooks/master-thesis/corpora/tatoeba-challenge/en-es/{split}.es\" for split in [\"dev\", \"train\"]]\n",
    "aym_files = [f\"/notebooks/master-thesis/corpora/americasnlp2021/data/aymara-spanish/{split}.aym\" for split in [\"dev\", \"train\"]]\n",
    "es2_files = [f\"/notebooks/master-thesis/corpora/americasnlp2021/data/aymara-spanish/{split}.es\" for split in [\"dev\", \"train\"]]\n",
    "\n",
    "files = en_files + es_files + es2_files + aym_files\n",
    "#print(files)\n",
    "en_es_aym_tokenizer.train(files= files, trainer=en_es_aym_trainer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ! cat /notebooks/master-thesis/corpora/tatoeba-challenge/en-es/dev.en"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "\n",
    "\n",
    "def tokenize_files(tokenizer, files, extension, output_path):\n",
    "    for file in files:\n",
    "        print(f\"Reading file {file}\")\n",
    "        with open(file, encoding='utf8') as f:\n",
    "          lines = f.readlines()\n",
    "          tokenized_lines = tokenizer.encode_batch(lines)\n",
    "          tokenized_name = Path(file).stem\n",
    "          tokenized_name = output_path + tokenized_name + \".\" + extension\n",
    "          print(tokenized_name)\n",
    "          with open(tokenized_name, 'w', encoding='utf8') as wf:\n",
    "\n",
    "            wf.writelines([\" \".join(t.tokens) + \"\\n\" for t in tokenized_lines])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "en_es_aym_tokenizer.save(tokenizer_path + \"aym-es-en-tokenizer.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<tokenizers.Tokenizer object at 0x7fc8ec001e70>\n"
     ]
    }
   ],
   "source": [
    "print(en_es_aym_tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['we', 'hold', 'this', 'truth', 'to', 'be', 'self', 'evident', 'that', 'everyone', 'is', 'created', 'equal', '?']\n"
     ]
    }
   ],
   "source": [
    "tok = en_es_aym_tokenizer.encode(\"we hold this truth to be self evident that everyone is created equal?\")\n",
    "print(tok.tokens)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading file /notebooks/master-thesis/corpora/tatoeba-challenge/en-es/dev.en\n",
      "/storage/master-thesis/models/nah-es++es-en/tokenizers/nah-es-en/es-en/dev.en\n",
      "Reading file /notebooks/master-thesis/corpora/tatoeba-challenge/en-es/train.en\n",
      "/storage/master-thesis/models/nah-es++es-en/tokenizers/nah-es-en/es-en/train.en\n",
      "Reading file /notebooks/master-thesis/corpora/tatoeba-challenge/en-es/dev.es\n",
      "/storage/master-thesis/models/nah-es++es-en/tokenizers/nah-es-en/es-en/dev.es\n",
      "Reading file /notebooks/master-thesis/corpora/tatoeba-challenge/en-es/train.es\n",
      "/storage/master-thesis/models/nah-es++es-en/tokenizers/nah-es-en/es-en/train.es\n",
      "Reading file /notebooks/master-thesis/corpora/americasnlp2021/data/nahuatl-spanish/dev.nah\n",
      "/storage/master-thesis/models/nah-es++es-en/tokenizers/nah-es-en/nah-es/dev.nah\n",
      "Reading file /notebooks/master-thesis/corpora/americasnlp2021/data/nahuatl-spanish/train.nah\n",
      "/storage/master-thesis/models/nah-es++es-en/tokenizers/nah-es-en/nah-es/train.nah\n",
      "Reading file /notebooks/master-thesis/corpora/americasnlp2021/data/nahuatl-spanish/dev.es\n",
      "/storage/master-thesis/models/nah-es++es-en/tokenizers/nah-es-en/nah-es/dev.es\n",
      "Reading file /notebooks/master-thesis/corpora/americasnlp2021/data/nahuatl-spanish/train.es\n",
      "/storage/master-thesis/models/nah-es++es-en/tokenizers/nah-es-en/nah-es/train.es\n"
     ]
    }
   ],
   "source": [
    "tokenize_files(en_es_aym_tokenizer, en_files, \"en\", tokenized_path_es_en)\n",
    "tokenize_files(en_es_aym_tokenizer, es_files, \"es\", tokenized_path_es_en)\n",
    "\n",
    "tokenize_files(en_es_aym_tokenizer, aym_files, \"aym\", tokenized_path_aym_es)\n",
    "tokenize_files(en_es_aym_tokenizer, es2_files, \"es\", tokenized_path_aym_es)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Binarizing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rm: cannot remove '/storage/master-thesis/models/nah-es++es-en/tokenizers/nah-es-en/bin/dict.nah.txt': No such file or directory\n",
      "rm: cannot remove '/storage/master-thesis/models/nah-es++es-en/tokenizers/nah-es-en/bin/dict.es.txt': No such file or directory\n",
      "rm: cannot remove '/storage/master-thesis/models/nah-es++es-en/tokenizers/nah-es-en/bin/dict.en.txt': No such file or directory\n"
     ]
    }
   ],
   "source": [
    "### Removing previous dict files\n",
    "! rm $BIN_DIR/dict.aym.txt\n",
    "! rm $BIN_DIR/dict.es.txt\n",
    "! rm $BIN_DIR/dict.en.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Concatenating all training data\n",
    "! cat $TOKENIZED_PATH_AYM_ES/train.aym $TOKENIZED_PATH_AYM_ES/train.es $TOKENIZED_PATH_ES_EN/train.es $TOKENIZED_PATH_ES_EN/train.en > $BIN_DIR/train.all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " \u001b[0m\u001b[01;34m10nal-es+es-en\u001b[0m/            s.pt\n",
      " CITATION.cff               \u001b[01;34mscripts\u001b[0m/\n",
      " CODE_OF_CONDUCT.md         setup.cfg\n",
      " CONTRIBUTING.md            setup.py\n",
      " ISSUES.md                  sj.pt\n",
      " LICENSE                    \u001b[01;34msrc\u001b[0m/\n",
      " MANIFEST.in                \u001b[01;34mtemplates\u001b[0m/\n",
      " Makefile                  'test 10nal-es + es-en model.ipynb'\n",
      " README.md                 'test 11ind-en model.ipynb'\n",
      " README_zh-hans.md         'test capsulenet quy-es + es-en model.ipynb'\n",
      " README_zh-hant.md         'test it-nl-ro-en model.ipynb'\n",
      " \u001b[01;34mTOKENIZED_PATH_ES_EN\u001b[0m/     'test nl-it-en + de-en model.ipynb'\n",
      " \u001b[01;34mTOKENIZED_PATH_NAH_ES\u001b[0m/    'test quy-es + aym-es,en + es-en model.ipynb'\n",
      " Untitled.ipynb            'test quy-es + es-en model.ipynb'\n",
      " bar.txt                   'test quy-es -> es-en model.ipynb'\n",
      " \u001b[01;34mcheckpoints\u001b[0m/              'test residual drop quy-es + es-en model.ipynb'\n",
      " den.pt                     \u001b[01;34mtests\u001b[0m/\n",
      " \u001b[01;34mdocker\u001b[0m/                   'train 10nal-es + es-en model.ipynb'\n",
      " \u001b[01;34mdocs\u001b[0m/                     'train 11ind-en model.ipynb'\n",
      " en_pa.pa.out              'train capsulenet nl-it-en + de-en model.ipynb'\n",
      " es-en.zip                 'train capsulenet quy-es + es-en model.ipynb'\n",
      " es_en.en.out              'train es-en model.ipynb'\n",
      " \u001b[01;34mexamples\u001b[0m/                 'train it-nl-ro-en + de-en model.ipynb'\n",
      " hi.en.en.en               'train it-nl-ro-en model.ipynb'\n",
      " hi_en.en.out              'train nah-es,es-en.ipynb'\n",
      " hubconf.py                'train quy-es + aym-es,en + es-en model.ipynb'\n",
      " \u001b[01;34mmaster-thesis\u001b[0m/            'train quy-es,es-en.ipynb'\n",
      " \u001b[01;34mmodel_cards\u001b[0m/              'train residual drop quy-es + es-en model.ipynb'\n",
      " norm.pt                    train.all\n",
      " \u001b[01;34mnotebooks\u001b[0m/                 train.en\n",
      " num.pt                     train.en-ml.en.bin\n",
      " pos.pt                     train.en-ml.ml.bin\n",
      " pyproject.toml             train.en-ml.ml.idx\n",
      " quy.es.es.es               \u001b[01;34mutils\u001b[0m/\n",
      " quy_es.es.out              valohai.yaml\n",
      " resdrop_quy-es+es-en.zip   vj.pt\n"
     ]
    }
   ],
   "source": [
    "ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-09-14 20:49:01 | INFO | fairseq_cli.preprocess | Namespace(align_suffix=None, alignfile=None, all_gather_list_size=16384, bf16=False, bpe=None, checkpoint_shard_count=1, checkpoint_suffix='', cpu=False, criterion='cross_entropy', dataset_impl='mmap', destdir='/storage/master-thesis/models/nah-es++es-en/tokenizers/nah-es-en/bin', empty_cache_freq=0, fp16=False, fp16_init_scale=128, fp16_no_flatten_grads=False, fp16_scale_tolerance=0.0, fp16_scale_window=None, joined_dictionary=False, log_format=None, log_interval=100, lr_scheduler='fixed', memory_efficient_bf16=False, memory_efficient_fp16=False, min_loss_scale=0.0001, model_parallel_size=1, no_progress_bar=False, nwordssrc=-1, nwordstgt=-1, only_source=True, optimizer=None, padding_factor=8, profile=False, quantization_config_path=None, scoring='bleu', seed=1, source_lang='all', srcdict=None, target_lang=None, task='translation', tensorboard_logdir=None, testpref=None, tgtdict=None, threshold_loss_scale=None, thresholdsrc=0, thresholdtgt=0, tokenizer=None, tpu=False, trainpref='/storage/master-thesis/models/nah-es++es-en/tokenizers/nah-es-en/bin/train', user_dir=None, validpref=None, workers=20)\n",
      "2022-09-14 20:49:03 | INFO | fairseq_cli.preprocess | [all] Dictionary: 28912 types\n",
      "2022-09-14 20:49:10 | INFO | fairseq_cli.preprocess | [all] /storage/master-thesis/models/nah-es++es-en/tokenizers/nah-es-en/bin/train.all: 426884 sents, 4903931 tokens, 0.0% replaced by <unk>\n",
      "2022-09-14 20:49:10 | INFO | fairseq_cli.preprocess | Wrote preprocessed data to /storage/master-thesis/models/nah-es++es-en/tokenizers/nah-es-en/bin\n"
     ]
    }
   ],
   "source": [
    "! fairseq-preprocess --source-lang all \\\n",
    "    --trainpref $BIN_DIR/train \\\n",
    "    --destdir $BIN_DIR \\\n",
    "    --workers 20 \\\n",
    "    --only-source"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/storage/master-thesis/models/nah-es++es-en/tokenizers/nah-es-en/bin\n"
     ]
    }
   ],
   "source": [
    "! echo $BIN_DIR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-09-14 20:49:14 | INFO | fairseq_cli.preprocess | Namespace(align_suffix=None, alignfile=None, all_gather_list_size=16384, bf16=False, bpe=None, checkpoint_shard_count=1, checkpoint_suffix='', cpu=False, criterion='cross_entropy', dataset_impl='mmap', destdir='/storage/master-thesis/models/nah-es++es-en/tokenizers/nah-es-en/bin', empty_cache_freq=0, fp16=False, fp16_init_scale=128, fp16_no_flatten_grads=False, fp16_scale_tolerance=0.0, fp16_scale_window=None, joined_dictionary=False, log_format=None, log_interval=100, lr_scheduler='fixed', memory_efficient_bf16=False, memory_efficient_fp16=False, min_loss_scale=0.0001, model_parallel_size=1, no_progress_bar=False, nwordssrc=-1, nwordstgt=-1, only_source=False, optimizer=None, padding_factor=8, profile=False, quantization_config_path=None, scoring='bleu', seed=1, source_lang='nah', srcdict='/storage/master-thesis/models/nah-es++es-en/tokenizers/nah-es-en/bin/dict.all.txt', target_lang='es', task='translation', tensorboard_logdir=None, testpref=None, tgtdict='/storage/master-thesis/models/nah-es++es-en/tokenizers/nah-es-en/bin/dict.all.txt', threshold_loss_scale=None, thresholdsrc=0, thresholdtgt=0, tokenizer=None, tpu=False, trainpref='/storage/master-thesis/models/nah-es++es-en/tokenizers/nah-es-en/nah-es/train', user_dir=None, validpref='/storage/master-thesis/models/nah-es++es-en/tokenizers/nah-es-en/nah-es/dev', workers=20)\n",
      "2022-09-14 20:49:14 | INFO | fairseq_cli.preprocess | [nah] Dictionary: 28912 types\n",
      "2022-09-14 20:49:15 | INFO | fairseq_cli.preprocess | [nah] /storage/master-thesis/models/nah-es++es-en/tokenizers/nah-es-en/nah-es/train.nah: 16145 sents, 529303 tokens, 0.0% replaced by <unk>\n",
      "2022-09-14 20:49:15 | INFO | fairseq_cli.preprocess | [nah] Dictionary: 28912 types\n",
      "2022-09-14 20:49:15 | INFO | fairseq_cli.preprocess | [nah] /storage/master-thesis/models/nah-es++es-en/tokenizers/nah-es-en/nah-es/dev.nah: 671 sents, 9095 tokens, 0.44% replaced by <unk>\n",
      "2022-09-14 20:49:15 | INFO | fairseq_cli.preprocess | [es] Dictionary: 28912 types\n",
      "2022-09-14 20:49:16 | INFO | fairseq_cli.preprocess | [es] /storage/master-thesis/models/nah-es++es-en/tokenizers/nah-es-en/nah-es/train.es: 16145 sents, 544039 tokens, 0.0% replaced by <unk>\n",
      "2022-09-14 20:49:16 | INFO | fairseq_cli.preprocess | [es] Dictionary: 28912 types\n",
      "2022-09-14 20:49:16 | INFO | fairseq_cli.preprocess | [es] /storage/master-thesis/models/nah-es++es-en/tokenizers/nah-es-en/nah-es/dev.es: 671 sents, 8705 tokens, 0.172% replaced by <unk>\n",
      "2022-09-14 20:49:16 | INFO | fairseq_cli.preprocess | Wrote preprocessed data to /storage/master-thesis/models/nah-es++es-en/tokenizers/nah-es-en/bin\n"
     ]
    }
   ],
   "source": [
    "! fairseq-preprocess --source-lang aym --target-lang es \\\n",
    "    --trainpref $TOKENIZED_PATH_AYM_ES/train --validpref $TOKENIZED_PATH_AYM_ES/dev \\\n",
    "    --destdir $BIN_DIR \\\n",
    "    --srcdict $BIN_DIR/dict.all.txt \\\n",
    "    --tgtdict $BIN_DIR/dict.all.txt \\\n",
    "    --workers 20"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reusing es dict from aym-es preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-09-14 20:49:22 | INFO | fairseq_cli.preprocess | Namespace(align_suffix=None, alignfile=None, all_gather_list_size=16384, bf16=False, bpe=None, checkpoint_shard_count=1, checkpoint_suffix='', cpu=False, criterion='cross_entropy', dataset_impl='mmap', destdir='/storage/master-thesis/models/nah-es++es-en/tokenizers/nah-es-en/bin', empty_cache_freq=0, fp16=False, fp16_init_scale=128, fp16_no_flatten_grads=False, fp16_scale_tolerance=0.0, fp16_scale_window=None, joined_dictionary=False, log_format=None, log_interval=100, lr_scheduler='fixed', memory_efficient_bf16=False, memory_efficient_fp16=False, min_loss_scale=0.0001, model_parallel_size=1, no_progress_bar=False, nwordssrc=-1, nwordstgt=-1, only_source=False, optimizer=None, padding_factor=8, profile=False, quantization_config_path=None, scoring='bleu', seed=1, source_lang='es', srcdict='/storage/master-thesis/models/nah-es++es-en/tokenizers/nah-es-en/bin/dict.all.txt', target_lang='en', task='translation', tensorboard_logdir=None, testpref=None, tgtdict='/storage/master-thesis/models/nah-es++es-en/tokenizers/nah-es-en/bin/dict.all.txt', threshold_loss_scale=None, thresholdsrc=0, thresholdtgt=0, tokenizer=None, tpu=False, trainpref='/storage/master-thesis/models/nah-es++es-en/tokenizers/nah-es-en/es-en/train', user_dir=None, validpref='/storage/master-thesis/models/nah-es++es-en/tokenizers/nah-es-en/es-en/dev', workers=20)\n",
      "2022-09-14 20:49:23 | INFO | fairseq_cli.preprocess | [es] Dictionary: 28912 types\n",
      "2022-09-14 20:49:26 | INFO | fairseq_cli.preprocess | [es] /storage/master-thesis/models/nah-es++es-en/tokenizers/nah-es-en/es-en/train.es: 197297 sents, 1874493 tokens, 0.0% replaced by <unk>\n",
      "2022-09-14 20:49:26 | INFO | fairseq_cli.preprocess | [es] Dictionary: 28912 types\n",
      "2022-09-14 20:49:26 | INFO | fairseq_cli.preprocess | [es] /storage/master-thesis/models/nah-es++es-en/tokenizers/nah-es-en/es-en/dev.es: 4643 sents, 51251 tokens, 0.041% replaced by <unk>\n",
      "2022-09-14 20:49:26 | INFO | fairseq_cli.preprocess | [en] Dictionary: 28912 types\n",
      "2022-09-14 20:49:28 | INFO | fairseq_cli.preprocess | [en] /storage/master-thesis/models/nah-es++es-en/tokenizers/nah-es-en/es-en/train.en: 197297 sents, 1956096 tokens, 0.0% replaced by <unk>\n",
      "2022-09-14 20:49:28 | INFO | fairseq_cli.preprocess | [en] Dictionary: 28912 types\n",
      "2022-09-14 20:49:29 | INFO | fairseq_cli.preprocess | [en] /storage/master-thesis/models/nah-es++es-en/tokenizers/nah-es-en/es-en/dev.en: 4643 sents, 53167 tokens, 0.0414% replaced by <unk>\n",
      "2022-09-14 20:49:29 | INFO | fairseq_cli.preprocess | Wrote preprocessed data to /storage/master-thesis/models/nah-es++es-en/tokenizers/nah-es-en/bin\n"
     ]
    }
   ],
   "source": [
    "! fairseq-preprocess --source-lang es --target-lang en \\\n",
    "    --trainpref $TOKENIZED_PATH_ES_EN/train --validpref $TOKENIZED_PATH_ES_EN/dev \\\n",
    "    --destdir $BIN_DIR \\\n",
    "    --srcdict $BIN_DIR/dict.all.txt \\\n",
    "    --tgtdict $BIN_DIR/dict.all.txt \\\n",
    "    --workers 20"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-09-15 08:04:11 | INFO | fairseq_cli.train | Namespace(activation_dropout=0.0, activation_fn='relu', adam_betas='(0.9, 0.98)', adam_eps=1e-08, adaptive_input=False, adaptive_softmax_cutoff=None, adaptive_softmax_dropout=0, all_gather_list_size=16384, arch='transformer', attention_dropout=0.0, batch_size=None, batch_size_valid=None, best_checkpoint_metric='loss', bf16=False, bpe=None, broadcast_buffers=False, bucket_cap_mb=25, checkpoint_shard_count=1, checkpoint_suffix='', clip_norm=0.0, cpu=False, criterion='label_smoothed_cross_entropy', cross_self_attention=False, curriculum=0, data='/storage/master-thesis/models/nah-es++es-en/tokenizers/nah-es-en/bin', data_buffer_size=10, dataset_impl=None, ddp_backend='c10d', decoder_attention_heads=8, decoder_embed_dim=512, decoder_embed_path=None, decoder_ffn_embed_dim=2048, decoder_input_dim=512, decoder_langtok=True, decoder_layerdrop=0, decoder_layers=6, decoder_layers_to_keep=None, decoder_learned_pos=False, decoder_normalize_before=False, decoder_output_dim=512, device_id=0, disable_validation=False, distributed_backend='nccl', distributed_init_method=None, distributed_no_spawn=False, distributed_num_procs=1, distributed_port=-1, distributed_rank=0, distributed_world_size=1, distributed_wrapper='DDP', dropout=0.3, empty_cache_freq=0, enable_lang_ids=False, enable_reservsed_directions_shared_datasets=False, encoder_attention_heads=8, encoder_embed_dim=512, encoder_embed_path=None, encoder_ffn_embed_dim=2048, encoder_langtok='src', encoder_layerdrop=0, encoder_layers=6, encoder_layers_to_keep=None, encoder_learned_pos=False, encoder_normalize_before=False, extra_data=None, extra_lang_pairs=None, fast_stat_sync=False, find_unused_parameters=False, finetune_from_model=None, fix_batches_to_gpus=False, fixed_dictionary=None, fixed_validation_seed=None, fp16=True, fp16_init_scale=128, fp16_no_flatten_grads=False, fp16_scale_tolerance=0.0, fp16_scale_window=None, gen_subset='test', ignore_prefix_size=0, keep_best_checkpoints=-1, keep_inference_langtok=False, keep_interval_updates=-1, keep_last_epochs=2, label_smoothing=0.1, lang_dict=None, lang_pairs='nah-es,es-en', lang_tok_replacing_bos_eos=False, lang_tok_style='multilingual', langs=None, langtoks=None, langtoks_specs=['main'], layernorm_embedding=False, left_pad_source='True', left_pad_target='False', load_alignments=False, localsgd_frequency=3, log_format=None, log_interval=100, lr=[0.0005], lr_scheduler='inverse_sqrt', max_epoch=200, max_source_positions=1024, max_target_positions=1024, max_tokens=4096, max_tokens_valid=4096, max_update=0, maximize_best_checkpoint_metric=False, memory_efficient_bf16=False, memory_efficient_fp16=False, min_loss_scale=0.0001, min_lr=-1.0, model_parallel_size=1, no_cross_attention=False, no_epoch_checkpoints=False, no_last_checkpoints=False, no_progress_bar=False, no_save=False, no_save_optimizer_state=False, no_scale_embedding=False, no_seed_provided=False, no_token_positional_embeddings=False, nprocs_per_node=1, num_shards=1, num_workers=1, optimizer='adam', optimizer_overrides='{}', patience=10, pipeline_balance=None, pipeline_checkpoint='never', pipeline_chunks=0, pipeline_decoder_balance=None, pipeline_decoder_devices=None, pipeline_devices=None, pipeline_encoder_balance=None, pipeline_encoder_devices=None, pipeline_model_parallel=False, profile=False, quant_noise_pq=0, quant_noise_pq_block_size=8, quant_noise_scalar=0, quantization_config_path=None, report_accuracy=False, required_batch_size_multiple=8, required_seq_len_multiple=1, reset_dataloader=False, reset_lr_scheduler=False, reset_meters=False, reset_optimizer=True, restore_file='/storage/master-thesis/models/nah-es++es-en/checkpoint_last.pt', sampling_method='concat', sampling_temperature=1.5, sampling_weights=None, sampling_weights_from_file=None, save_dir='/storage/master-thesis/models/nah-es++es-en/', save_interval=1, save_interval_updates=0, scoring='bleu', seed=1, sentence_avg=False, shard_id=0, share_all_embeddings=True, share_decoder_input_output_embed=False, skip_invalid_size_inputs_valid_test=False, slowmo_algorithm='LocalSGD', slowmo_momentum=None, source_lang=None, stop_time_hours=0, target_lang=None, task='translation_multi_simple_epoch', tensorboard_logdir=None, threshold_loss_scale=None, tie_adaptive_weights=False, tokenizer=None, tpu=False, train_subset='train', truncate_source=False, update_freq=[1], upsample_primary=1, use_bmuf=False, use_old_adam=False, user_dir=None, valid_subset='valid', validate_after_updates=0, validate_interval=1, validate_interval_updates=0, virtual_data_size=None, virtual_epoch_size=1000000, warmup_init_lr=-1, warmup_updates=4000, weight_decay=0.0001, zero_sharding='none')\n",
      "2022-09-15 08:04:11 | WARNING | fairseq.data.multilingual.multilingual_data_manager | External language dictionary is not provided; use lang-pairs to infer the set of supported languages. The language ordering is not stable which might cause misalignment in pretraining and finetuning.\n",
      "2022-09-15 08:04:11 | INFO | fairseq.data.multilingual.multilingual_data_manager | inferred language list: ['en', 'es', 'nah']\n",
      "2022-09-15 08:04:11 | INFO | fairseq.data.multilingual.multilingual_data_manager | [en] dictionary: 28915 types\n",
      "2022-09-15 08:04:11 | INFO | fairseq.data.multilingual.multilingual_data_manager | [es] dictionary: 28915 types\n",
      "2022-09-15 08:04:11 | INFO | fairseq.data.multilingual.multilingual_data_manager | [nah] dictionary: 28915 types\n",
      "2022-09-15 08:04:11 | INFO | fairseq.tasks.translation_multi_simple_epoch | loading data for valid epoch=1/None\n",
      "2022-09-15 08:04:11 | INFO | fairseq.tasks.translation_multi_simple_epoch | mem usage: N/A\n",
      "2022-09-15 08:04:11 | INFO | fairseq.data.multilingual.multilingual_data_manager | langtoks settings: {'main': ('src', 'tgt')}\n",
      "2022-09-15 08:04:11 | INFO | fairseq.data.multilingual.multilingual_data_manager | [valid] num of shards: {'main:nah-es': 1, 'main:es-en': 1}\n",
      "2022-09-15 08:04:11 | INFO | fairseq.data.multilingual.multilingual_data_manager | main:nah-es src_langtok: 28914; tgt_langtok: 28913\n",
      "2022-09-15 08:04:11 | INFO | fairseq.data.data_utils | loaded 671 examples from: /storage/master-thesis/models/nah-es++es-en/tokenizers/nah-es-en/bin/valid.nah-es.nah\n",
      "2022-09-15 08:04:11 | INFO | fairseq.data.data_utils | loaded 671 examples from: /storage/master-thesis/models/nah-es++es-en/tokenizers/nah-es-en/bin/valid.nah-es.es\n",
      "2022-09-15 08:04:11 | INFO | fairseq.data.multilingual.multilingual_data_manager | /storage/master-thesis/models/nah-es++es-en/tokenizers/nah-es-en/bin valid nah-es 671 examples\n",
      "2022-09-15 08:04:11 | INFO | fairseq.data.multilingual.multilingual_data_manager | main:es-en src_langtok: 28913; tgt_langtok: 28912\n",
      "2022-09-15 08:04:11 | INFO | fairseq.data.data_utils | loaded 4643 examples from: /storage/master-thesis/models/nah-es++es-en/tokenizers/nah-es-en/bin/valid.es-en.es\n",
      "2022-09-15 08:04:11 | INFO | fairseq.data.data_utils | loaded 4643 examples from: /storage/master-thesis/models/nah-es++es-en/tokenizers/nah-es-en/bin/valid.es-en.en\n",
      "2022-09-15 08:04:11 | INFO | fairseq.data.multilingual.multilingual_data_manager | /storage/master-thesis/models/nah-es++es-en/tokenizers/nah-es-en/bin valid es-en 4643 examples\n",
      "2022-09-15 08:04:12 | INFO | fairseq_cli.train | TransformerModel(\n",
      "  (encoder): TransformerEncoder(\n",
      "    (dropout_module): FairseqDropout()\n",
      "    (embed_tokens): Embedding(28915, 512, padding_idx=1)\n",
      "    (embed_positions): SinusoidalPositionalEmbedding()\n",
      "    (layers): ModuleList(\n",
      "      (0): TransformerEncoderLayer(\n",
      "        (self_attn): MultiheadAttention(\n",
      "          (dropout_module): FairseqDropout()\n",
      "          (k_proj): Linear(in_features=512, out_features=512, bias=True)\n",
      "          (v_proj): Linear(in_features=512, out_features=512, bias=True)\n",
      "          (q_proj): Linear(in_features=512, out_features=512, bias=True)\n",
      "          (out_proj): Linear(in_features=512, out_features=512, bias=True)\n",
      "        )\n",
      "        (self_attn_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)\n",
      "        (dropout_module): FairseqDropout()\n",
      "        (activation_dropout_module): FairseqDropout()\n",
      "        (fc1): Linear(in_features=512, out_features=2048, bias=True)\n",
      "        (fc2): Linear(in_features=2048, out_features=512, bias=True)\n",
      "        (final_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)\n",
      "      )\n",
      "      (1): TransformerEncoderLayer(\n",
      "        (self_attn): MultiheadAttention(\n",
      "          (dropout_module): FairseqDropout()\n",
      "          (k_proj): Linear(in_features=512, out_features=512, bias=True)\n",
      "          (v_proj): Linear(in_features=512, out_features=512, bias=True)\n",
      "          (q_proj): Linear(in_features=512, out_features=512, bias=True)\n",
      "          (out_proj): Linear(in_features=512, out_features=512, bias=True)\n",
      "        )\n",
      "        (self_attn_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)\n",
      "        (dropout_module): FairseqDropout()\n",
      "        (activation_dropout_module): FairseqDropout()\n",
      "        (fc1): Linear(in_features=512, out_features=2048, bias=True)\n",
      "        (fc2): Linear(in_features=2048, out_features=512, bias=True)\n",
      "        (final_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)\n",
      "      )\n",
      "      (2): TransformerEncoderLayer(\n",
      "        (self_attn): MultiheadAttention(\n",
      "          (dropout_module): FairseqDropout()\n",
      "          (k_proj): Linear(in_features=512, out_features=512, bias=True)\n",
      "          (v_proj): Linear(in_features=512, out_features=512, bias=True)\n",
      "          (q_proj): Linear(in_features=512, out_features=512, bias=True)\n",
      "          (out_proj): Linear(in_features=512, out_features=512, bias=True)\n",
      "        )\n",
      "        (self_attn_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)\n",
      "        (dropout_module): FairseqDropout()\n",
      "        (activation_dropout_module): FairseqDropout()\n",
      "        (fc1): Linear(in_features=512, out_features=2048, bias=True)\n",
      "        (fc2): Linear(in_features=2048, out_features=512, bias=True)\n",
      "        (final_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)\n",
      "      )\n",
      "      (3): TransformerEncoderLayer(\n",
      "        (self_attn): MultiheadAttention(\n",
      "          (dropout_module): FairseqDropout()\n",
      "          (k_proj): Linear(in_features=512, out_features=512, bias=True)\n",
      "          (v_proj): Linear(in_features=512, out_features=512, bias=True)\n",
      "          (q_proj): Linear(in_features=512, out_features=512, bias=True)\n",
      "          (out_proj): Linear(in_features=512, out_features=512, bias=True)\n",
      "        )\n",
      "        (self_attn_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)\n",
      "        (dropout_module): FairseqDropout()\n",
      "        (activation_dropout_module): FairseqDropout()\n",
      "        (fc1): Linear(in_features=512, out_features=2048, bias=True)\n",
      "        (fc2): Linear(in_features=2048, out_features=512, bias=True)\n",
      "        (final_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)\n",
      "      )\n",
      "      (4): TransformerEncoderLayer(\n",
      "        (self_attn): MultiheadAttention(\n",
      "          (dropout_module): FairseqDropout()\n",
      "          (k_proj): Linear(in_features=512, out_features=512, bias=True)\n",
      "          (v_proj): Linear(in_features=512, out_features=512, bias=True)\n",
      "          (q_proj): Linear(in_features=512, out_features=512, bias=True)\n",
      "          (out_proj): Linear(in_features=512, out_features=512, bias=True)\n",
      "        )\n",
      "        (self_attn_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)\n",
      "        (dropout_module): FairseqDropout()\n",
      "        (activation_dropout_module): FairseqDropout()\n",
      "        (fc1): Linear(in_features=512, out_features=2048, bias=True)\n",
      "        (fc2): Linear(in_features=2048, out_features=512, bias=True)\n",
      "        (final_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)\n",
      "      )\n",
      "      (5): TransformerEncoderLayer(\n",
      "        (self_attn): MultiheadAttention(\n",
      "          (dropout_module): FairseqDropout()\n",
      "          (k_proj): Linear(in_features=512, out_features=512, bias=True)\n",
      "          (v_proj): Linear(in_features=512, out_features=512, bias=True)\n",
      "          (q_proj): Linear(in_features=512, out_features=512, bias=True)\n",
      "          (out_proj): Linear(in_features=512, out_features=512, bias=True)\n",
      "        )\n",
      "        (self_attn_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)\n",
      "        (dropout_module): FairseqDropout()\n",
      "        (activation_dropout_module): FairseqDropout()\n",
      "        (fc1): Linear(in_features=512, out_features=2048, bias=True)\n",
      "        (fc2): Linear(in_features=2048, out_features=512, bias=True)\n",
      "        (final_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (decoder): TransformerDecoder(\n",
      "    (dropout_module): FairseqDropout()\n",
      "    (embed_tokens): Embedding(28915, 512, padding_idx=1)\n",
      "    (embed_positions): SinusoidalPositionalEmbedding()\n",
      "    (layers): ModuleList(\n",
      "      (0): TransformerDecoderLayer(\n",
      "        (dropout_module): FairseqDropout()\n",
      "        (self_attn): MultiheadAttention(\n",
      "          (dropout_module): FairseqDropout()\n",
      "          (k_proj): Linear(in_features=512, out_features=512, bias=True)\n",
      "          (v_proj): Linear(in_features=512, out_features=512, bias=True)\n",
      "          (q_proj): Linear(in_features=512, out_features=512, bias=True)\n",
      "          (out_proj): Linear(in_features=512, out_features=512, bias=True)\n",
      "        )\n",
      "        (activation_dropout_module): FairseqDropout()\n",
      "        (self_attn_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)\n",
      "        (encoder_attn): MultiheadAttention(\n",
      "          (dropout_module): FairseqDropout()\n",
      "          (k_proj): Linear(in_features=512, out_features=512, bias=True)\n",
      "          (v_proj): Linear(in_features=512, out_features=512, bias=True)\n",
      "          (q_proj): Linear(in_features=512, out_features=512, bias=True)\n",
      "          (out_proj): Linear(in_features=512, out_features=512, bias=True)\n",
      "        )\n",
      "        (encoder_attn_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)\n",
      "        (fc1): Linear(in_features=512, out_features=2048, bias=True)\n",
      "        (fc2): Linear(in_features=2048, out_features=512, bias=True)\n",
      "        (final_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)\n",
      "      )\n",
      "      (1): TransformerDecoderLayer(\n",
      "        (dropout_module): FairseqDropout()\n",
      "        (self_attn): MultiheadAttention(\n",
      "          (dropout_module): FairseqDropout()\n",
      "          (k_proj): Linear(in_features=512, out_features=512, bias=True)\n",
      "          (v_proj): Linear(in_features=512, out_features=512, bias=True)\n",
      "          (q_proj): Linear(in_features=512, out_features=512, bias=True)\n",
      "          (out_proj): Linear(in_features=512, out_features=512, bias=True)\n",
      "        )\n",
      "        (activation_dropout_module): FairseqDropout()\n",
      "        (self_attn_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)\n",
      "        (encoder_attn): MultiheadAttention(\n",
      "          (dropout_module): FairseqDropout()\n",
      "          (k_proj): Linear(in_features=512, out_features=512, bias=True)\n",
      "          (v_proj): Linear(in_features=512, out_features=512, bias=True)\n",
      "          (q_proj): Linear(in_features=512, out_features=512, bias=True)\n",
      "          (out_proj): Linear(in_features=512, out_features=512, bias=True)\n",
      "        )\n",
      "        (encoder_attn_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)\n",
      "        (fc1): Linear(in_features=512, out_features=2048, bias=True)\n",
      "        (fc2): Linear(in_features=2048, out_features=512, bias=True)\n",
      "        (final_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)\n",
      "      )\n",
      "      (2): TransformerDecoderLayer(\n",
      "        (dropout_module): FairseqDropout()\n",
      "        (self_attn): MultiheadAttention(\n",
      "          (dropout_module): FairseqDropout()\n",
      "          (k_proj): Linear(in_features=512, out_features=512, bias=True)\n",
      "          (v_proj): Linear(in_features=512, out_features=512, bias=True)\n",
      "          (q_proj): Linear(in_features=512, out_features=512, bias=True)\n",
      "          (out_proj): Linear(in_features=512, out_features=512, bias=True)\n",
      "        )\n",
      "        (activation_dropout_module): FairseqDropout()\n",
      "        (self_attn_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)\n",
      "        (encoder_attn): MultiheadAttention(\n",
      "          (dropout_module): FairseqDropout()\n",
      "          (k_proj): Linear(in_features=512, out_features=512, bias=True)\n",
      "          (v_proj): Linear(in_features=512, out_features=512, bias=True)\n",
      "          (q_proj): Linear(in_features=512, out_features=512, bias=True)\n",
      "          (out_proj): Linear(in_features=512, out_features=512, bias=True)\n",
      "        )\n",
      "        (encoder_attn_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)\n",
      "        (fc1): Linear(in_features=512, out_features=2048, bias=True)\n",
      "        (fc2): Linear(in_features=2048, out_features=512, bias=True)\n",
      "        (final_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)\n",
      "      )\n",
      "      (3): TransformerDecoderLayer(\n",
      "        (dropout_module): FairseqDropout()\n",
      "        (self_attn): MultiheadAttention(\n",
      "          (dropout_module): FairseqDropout()\n",
      "          (k_proj): Linear(in_features=512, out_features=512, bias=True)\n",
      "          (v_proj): Linear(in_features=512, out_features=512, bias=True)\n",
      "          (q_proj): Linear(in_features=512, out_features=512, bias=True)\n",
      "          (out_proj): Linear(in_features=512, out_features=512, bias=True)\n",
      "        )\n",
      "        (activation_dropout_module): FairseqDropout()\n",
      "        (self_attn_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)\n",
      "        (encoder_attn): MultiheadAttention(\n",
      "          (dropout_module): FairseqDropout()\n",
      "          (k_proj): Linear(in_features=512, out_features=512, bias=True)\n",
      "          (v_proj): Linear(in_features=512, out_features=512, bias=True)\n",
      "          (q_proj): Linear(in_features=512, out_features=512, bias=True)\n",
      "          (out_proj): Linear(in_features=512, out_features=512, bias=True)\n",
      "        )\n",
      "        (encoder_attn_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)\n",
      "        (fc1): Linear(in_features=512, out_features=2048, bias=True)\n",
      "        (fc2): Linear(in_features=2048, out_features=512, bias=True)\n",
      "        (final_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)\n",
      "      )\n",
      "      (4): TransformerDecoderLayer(\n",
      "        (dropout_module): FairseqDropout()\n",
      "        (self_attn): MultiheadAttention(\n",
      "          (dropout_module): FairseqDropout()\n",
      "          (k_proj): Linear(in_features=512, out_features=512, bias=True)\n",
      "          (v_proj): Linear(in_features=512, out_features=512, bias=True)\n",
      "          (q_proj): Linear(in_features=512, out_features=512, bias=True)\n",
      "          (out_proj): Linear(in_features=512, out_features=512, bias=True)\n",
      "        )\n",
      "        (activation_dropout_module): FairseqDropout()\n",
      "        (self_attn_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)\n",
      "        (encoder_attn): MultiheadAttention(\n",
      "          (dropout_module): FairseqDropout()\n",
      "          (k_proj): Linear(in_features=512, out_features=512, bias=True)\n",
      "          (v_proj): Linear(in_features=512, out_features=512, bias=True)\n",
      "          (q_proj): Linear(in_features=512, out_features=512, bias=True)\n",
      "          (out_proj): Linear(in_features=512, out_features=512, bias=True)\n",
      "        )\n",
      "        (encoder_attn_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)\n",
      "        (fc1): Linear(in_features=512, out_features=2048, bias=True)\n",
      "        (fc2): Linear(in_features=2048, out_features=512, bias=True)\n",
      "        (final_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)\n",
      "      )\n",
      "      (5): TransformerDecoderLayer(\n",
      "        (dropout_module): FairseqDropout()\n",
      "        (self_attn): MultiheadAttention(\n",
      "          (dropout_module): FairseqDropout()\n",
      "          (k_proj): Linear(in_features=512, out_features=512, bias=True)\n",
      "          (v_proj): Linear(in_features=512, out_features=512, bias=True)\n",
      "          (q_proj): Linear(in_features=512, out_features=512, bias=True)\n",
      "          (out_proj): Linear(in_features=512, out_features=512, bias=True)\n",
      "        )\n",
      "        (activation_dropout_module): FairseqDropout()\n",
      "        (self_attn_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)\n",
      "        (encoder_attn): MultiheadAttention(\n",
      "          (dropout_module): FairseqDropout()\n",
      "          (k_proj): Linear(in_features=512, out_features=512, bias=True)\n",
      "          (v_proj): Linear(in_features=512, out_features=512, bias=True)\n",
      "          (q_proj): Linear(in_features=512, out_features=512, bias=True)\n",
      "          (out_proj): Linear(in_features=512, out_features=512, bias=True)\n",
      "        )\n",
      "        (encoder_attn_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)\n",
      "        (fc1): Linear(in_features=512, out_features=2048, bias=True)\n",
      "        (fc2): Linear(in_features=2048, out_features=512, bias=True)\n",
      "        (final_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)\n",
      "      )\n",
      "    )\n",
      "    (output_projection): Linear(in_features=512, out_features=28915, bias=False)\n",
      "  )\n",
      ")\n",
      "2022-09-15 08:04:12 | INFO | fairseq_cli.train | task: translation_multi_simple_epoch (TranslationMultiSimpleEpochTask)\n",
      "2022-09-15 08:04:12 | INFO | fairseq_cli.train | model: transformer (TransformerModel)\n",
      "2022-09-15 08:04:12 | INFO | fairseq_cli.train | criterion: label_smoothed_cross_entropy (LabelSmoothedCrossEntropyCriterion)\n",
      "2022-09-15 08:04:12 | INFO | fairseq_cli.train | num. model params: 58942976 (num. trained: 58942976)\n",
      "2022-09-15 08:04:17 | INFO | fairseq.trainer | detected shared parameter: encoder.embed_tokens.weight <- decoder.embed_tokens.weight\n",
      "2022-09-15 08:04:17 | INFO | fairseq.trainer | detected shared parameter: encoder.embed_tokens.weight <- decoder.output_projection.weight\n",
      "2022-09-15 08:04:17 | INFO | fairseq.utils | ***********************CUDA enviroments for all 1 workers***********************\n",
      "2022-09-15 08:04:17 | INFO | fairseq.utils | rank   0: capabilities =  7.5  ; total memory = 15.747 GB ; name = Quadro RTX 5000                         \n",
      "2022-09-15 08:04:17 | INFO | fairseq.utils | ***********************CUDA enviroments for all 1 workers***********************\n",
      "2022-09-15 08:04:17 | INFO | fairseq_cli.train | training on 1 devices (GPUs/TPUs)\n",
      "2022-09-15 08:04:17 | INFO | fairseq_cli.train | max tokens per GPU = 4096 and max sentences per GPU = None\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/bin/fairseq-train\", line 8, in <module>\n",
      "    sys.exit(cli_main())\n",
      "  File \"/usr/local/lib/python3.6/dist-packages/fairseq_cli/train.py\", line 352, in cli_main\n",
      "    distributed_utils.call_main(args, main)\n",
      "  File \"/usr/local/lib/python3.6/dist-packages/fairseq/distributed_utils.py\", line 301, in call_main\n",
      "    main(args, **kwargs)\n",
      "  File \"/usr/local/lib/python3.6/dist-packages/fairseq_cli/train.py\", line 114, in main\n",
      "    disable_iterator_cache=task.has_sharded_data(\"train\"),\n",
      "  File \"/usr/local/lib/python3.6/dist-packages/fairseq/checkpoint_utils.py\", line 193, in load_checkpoint\n",
      "    reset_meters=reset_meters,\n",
      "  File \"/usr/local/lib/python3.6/dist-packages/fairseq/trainer.py\", line 279, in load_checkpoint\n",
      "    state = checkpoint_utils.load_checkpoint_to_cpu(filename)\n",
      "  File \"/usr/local/lib/python3.6/dist-packages/fairseq/checkpoint_utils.py\", line 232, in load_checkpoint_to_cpu\n",
      "    state = _upgrade_state_dict(state)\n",
      "  File \"/usr/local/lib/python3.6/dist-packages/fairseq/checkpoint_utils.py\", line 420, in _upgrade_state_dict\n",
      "    state[\"args\"].task = \"translation\"\n",
      "AttributeError: 'NoneType' object has no attribute 'task'\n"
     ]
    }
   ],
   "source": [
    "! fairseq-train $BIN_DIR \\\n",
    "    --arch=transformer --share-all-embeddings \\\n",
    "    --task translation_multi_simple_epoch --lang-pairs aym-es,es-en \\\n",
    "    --optimizer adam --adam-betas '(0.9, 0.98)' --clip-norm 0.0 \\\n",
    "    --lr 5e-4 --lr-scheduler inverse_sqrt --warmup-updates 4000 \\\n",
    "    --dropout 0.3 --weight-decay 0.0001 \\\n",
    "    --criterion label_smoothed_cross_entropy --label-smoothing 0.1 \\\n",
    "    --max-tokens 4096 \\\n",
    "    --restore-file $MODEL_DIR/checkpoint_last.pt \\\n",
    "    --save-dir $MODEL_DIR/ \\\n",
    "    --keep-last-epochs 2 \\\n",
    "    --reset-optimizer \\\n",
    "    --encoder-langtok \"src\" \\\n",
    "    --decoder-langtok \\\n",
    "    --fp16 \\\n",
    "    --max-epoch 200 \\\n",
    "    --patience 10\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/storage/master-thesis/models/quy-es+es-en\n"
     ]
    }
   ],
   "source": [
    "! echo $MODEL_DIR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/storage/master-thesis/models/quy-es+es-en\n"
     ]
    }
   ],
   "source": [
    "cd /storage/master-thesis/models/nah-es+es-en"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "! rm checkpoint108.pt\n",
    "! rm checkpoint109.pt\n",
    "! rm checkpoint_best.pt\n",
    "! rm checkpoint_last.pt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "! rm dict.en.txt\n",
    "! rm dict.es.txt\n",
    "! rm dict.nah.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.5K\t/notebooks/CITATION.cff\n",
      "5.5K\t/notebooks/CODE_OF_CONDUCT.md\n",
      "15K\t/notebooks/CONTRIBUTING.md\n",
      "19K\t/notebooks/ISSUES.md\n",
      "12K\t/notebooks/LICENSE\n",
      "512\t/notebooks/MANIFEST.in\n",
      "3.5K\t/notebooks/Makefile\n",
      "41K\t/notebooks/README.md\n",
      "41K\t/notebooks/README_zh-hans.md\n",
      "42K\t/notebooks/README_zh-hant.md\n",
      "12K\t/notebooks/docker\n",
      "4.6M\t/notebooks/docs\n",
      "5.0M\t/notebooks/examples\n",
      "8.5K\t/notebooks/hubconf.py\n",
      "7.8G\t/notebooks/master-thesis\n",
      "1.5K\t/notebooks/model_cards\n",
      "9.5K\t/notebooks/notebooks\n",
      "512\t/notebooks/pyproject.toml\n",
      "64K\t/notebooks/scripts\n",
      "1.0K\t/notebooks/setup.cfg\n",
      "13K\t/notebooks/setup.py\n",
      "13M\t/notebooks/src\n",
      "731K\t/notebooks/templates\n",
      "4.5K\t/notebooks/test quy-es -> es-en model.ipynb\n",
      "6.8M\t/notebooks/tests\n",
      "147K\t/notebooks/train es-en model.ipynb\n",
      "158K\t/notebooks/train quy-es + es-en model.ipynb\n",
      "160K\t/notebooks/utils\n",
      "3.5K\t/notebooks/valohai.yaml\n",
      "7.9G\ttotal\n"
     ]
    }
   ],
   "source": [
    "! du -shc /notebooks/*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "512\t/notebooks/master-thesis/Untitled.ipynb\n",
      "362M\t/notebooks/master-thesis/corpora\n",
      "7.5G\t/notebooks/master-thesis/models\n",
      "7.8G\ttotal\n"
     ]
    }
   ],
   "source": [
    "! du -shc /notebooks/master-thesis/*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.6G\t/notebooks/master-thesis/models/es-en\n",
      "802M\t/notebooks/master-thesis/models/quy-es\n",
      "5.2G\t/notebooks/master-thesis/models/quy-es+es-en\n",
      "7.5G\ttotal\n"
     ]
    }
   ],
   "source": [
    "! du -shc /notebooks/master-thesis/models/*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19M\t/apex\n",
      "5.0M\t/bin\n",
      "4.0K\t/boot\n",
      "24K\t/content\n",
      "^C\n"
     ]
    }
   ],
   "source": [
    "! du -shc /*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " CITATION.cff         \u001b[0m\u001b[01;34mdocker\u001b[0m/          setup.py\n",
      " CODE_OF_CONDUCT.md   \u001b[01;34mdocs\u001b[0m/            \u001b[01;34msrc\u001b[0m/\n",
      " CONTRIBUTING.md      \u001b[01;34mexamples\u001b[0m/        \u001b[01;34mtemplates\u001b[0m/\n",
      " ISSUES.md            hubconf.py      'test quy-es -> es-en model.ipynb'\n",
      " LICENSE              \u001b[01;34mmaster-thesis\u001b[0m/   \u001b[01;34mtests\u001b[0m/\n",
      " MANIFEST.in          \u001b[01;34mmodel_cards\u001b[0m/    'train es-en model.ipynb'\n",
      " Makefile             \u001b[01;34mnotebooks\u001b[0m/      'train quy-es + es-en model.ipynb'\n",
      " README.md            pyproject.toml   \u001b[01;34mutils\u001b[0m/\n",
      " README_zh-hans.md    \u001b[01;34mscripts\u001b[0m/         valohai.yaml\n",
      " README_zh-hant.md    setup.cfg\n"
     ]
    }
   ],
   "source": [
    "ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/storage/master-thesis\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
