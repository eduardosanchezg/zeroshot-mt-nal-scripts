{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ENVIRONMENT VARIABLES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "EN_IT_CORPUS_DIR = \"/notebooks/master-thesis/corpora/iwslt17/en-it/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "EN_NL_CORPUS_DIR = \"/notebooks/master-thesis/corpora/iwslt17/en-nl/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "EN_RO_CORPUS_DIR = \"/notebooks/master-thesis/corpora/iwslt17/en-ro/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "IT_NL_CORPUS_DIR = \"/notebooks/master-thesis/corpora/iwslt17/it-nl/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "IT_RO_CORPUS_DIR = \"/notebooks/master-thesis/corpora/iwslt17/it-ro/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "NL_RO_CORPUS_DIR = \"/notebooks/master-thesis/corpora/iwslt17/nl-ro/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "DE_EN_CORPUS_DIR = \"/notebooks/master-thesis/corpora/iwslt17/de-en/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer_path = \"/storage/master-thesis/models/it-nl-ro-en+de-en/tokenizers/it-nl-ro-en-de/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "env: TOKENIZER_PATH=/storage/master-thesis/models/it-nl-ro-en+de-en/tokenizers/it-nl-ro-en-de\n"
     ]
    }
   ],
   "source": [
    "%env TOKENIZER_PATH = /storage/master-thesis/models/it-nl-ro-en+de-en/tokenizers/it-nl-ro-en-de"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenized_path_en_it = \"/storage/master-thesis/models/it-nl-ro-en+de-en/tokenizers/it-nl-ro-en-de/en-it/\"\n",
    "tokenized_path_en_nl = \"/storage/master-thesis/models/it-nl-ro-en+de-en/tokenizers/it-nl-ro-en-de/en-nl/\"\n",
    "tokenized_path_en_ro = \"/storage/master-thesis/models/it-nl-ro-en+de-en/tokenizers/it-nl-ro-en-de/en-ro/\"\n",
    "tokenized_path_it_nl = \"/storage/master-thesis/models/it-nl-ro-en+de-en/tokenizers/it-nl-ro-en-de/it-nl/\"\n",
    "tokenized_path_it_ro = \"/storage/master-thesis/models/it-nl-ro-en+de-en/tokenizers/it-nl-ro-en-de/it-ro/\"\n",
    "tokenized_path_nl_ro = \"/storage/master-thesis/models/it-nl-ro-en+de-en/tokenizers/it-nl-ro-en-de/nl-ro/\"\n",
    "tokenized_path_de_en = \"/storage/master-thesis/models/it-nl-ro-en+de-en/tokenizers/it-nl-ro-en-de/de-en/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "env: TOKENIZED_PATH_EN_IT=/storage/master-thesis/models/it-nl-ro-en+de-en/tokenizers/it-nl-ro-en-de/en-it\n",
      "env: TOKENIZED_PATH_EN_NL=/storage/master-thesis/models/it-nl-ro-en+de-en/tokenizers/it-nl-ro-en-de/en-nl\n",
      "env: TOKENIZED_PATH_EN_RO=/storage/master-thesis/models/it-nl-ro-en+de-en/tokenizers/it-nl-ro-en-de/en-ro\n",
      "env: TOKENIZED_PATH_IT_NL=/storage/master-thesis/models/it-nl-ro-en+de-en/tokenizers/it-nl-ro-en-de/it-nl\n",
      "env: TOKENIZED_PATH_IT_RO=/storage/master-thesis/models/it-nl-ro-en+de-en/tokenizers/it-nl-ro-en-de/it-ro\n",
      "env: TOKENIZED_PATH_NL_RO=/storage/master-thesis/models/it-nl-ro-en+de-en/tokenizers/it-nl-ro-en-de/nl-ro\n",
      "env: TOKENIZED_PATH_DE_EN=/storage/master-thesis/models/it-nl-ro-en+de-en/tokenizers/it-nl-ro-en-de/de-en\n"
     ]
    }
   ],
   "source": [
    "%env TOKENIZED_PATH_EN_IT = /storage/master-thesis/models/it-nl-ro-en+de-en/tokenizers/it-nl-ro-en-de/en-it\n",
    "%env TOKENIZED_PATH_EN_NL = /storage/master-thesis/models/it-nl-ro-en+de-en/tokenizers/it-nl-ro-en-de/en-nl\n",
    "%env TOKENIZED_PATH_EN_RO = /storage/master-thesis/models/it-nl-ro-en+de-en/tokenizers/it-nl-ro-en-de/en-ro\n",
    "%env TOKENIZED_PATH_IT_NL = /storage/master-thesis/models/it-nl-ro-en+de-en/tokenizers/it-nl-ro-en-de/it-nl\n",
    "%env TOKENIZED_PATH_IT_RO = /storage/master-thesis/models/it-nl-ro-en+de-en/tokenizers/it-nl-ro-en-de/it-ro\n",
    "%env TOKENIZED_PATH_NL_RO = /storage/master-thesis/models/it-nl-ro-en+de-en/tokenizers/it-nl-ro-en-de/nl-ro\n",
    "%env TOKENIZED_PATH_DE_EN = /storage/master-thesis/models/it-nl-ro-en+de-en/tokenizers/it-nl-ro-en-de/de-en"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "env: BIN_DIR=/storage/master-thesis/models/it-nl-ro-en+de-en/tokenizers/it-nl-ro-en-de/bin\n"
     ]
    }
   ],
   "source": [
    "%env BIN_DIR = /storage/master-thesis/models/it-nl-ro-en+de-en/tokenizers/it-nl-ro-en-de/bin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "env: MODEL_DIR=/storage/master-thesis/models/it-nl-ro-en+de-en\n"
     ]
    }
   ],
   "source": [
    "%env MODEL_DIR = /storage/master-thesis/models/it-nl-ro-en+de-en"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tokenizing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tokenizers import Tokenizer\n",
    "from tokenizers.models import WordPiece\n",
    "\n",
    "it_nl_ro_en_de_tokenizer = Tokenizer(WordPiece(unk_token=\"[UNK]\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tokenizers.trainers import WordPieceTrainer\n",
    "\n",
    "it_nl_ro_en_de_trainer = WordPieceTrainer(special_tokens=[\"[UNK]\", \"[CLS]\", \"[SEP]\", \"[PAD]\", \"[MASK]\"], vocab_size=30000, show_progress=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tokenizers.pre_tokenizers import Whitespace\n",
    "\n",
    "it_nl_ro_en_de_tokenizer.pre_tokenizer = Whitespace()\n",
    "\n",
    "en_it_files = [EN_IT_CORPUS_DIR + f\"{split}.en\" for split in [\"valid\",\"train\"]]\n",
    "it_en_files = [EN_IT_CORPUS_DIR + f\"{split}.it\" for split in [\"valid\",\"train\"]]\n",
    "\n",
    "en_nl_files = [EN_NL_CORPUS_DIR + f\"{split}.en\" for split in [\"valid\",\"train\"]]\n",
    "nl_en_files = [EN_NL_CORPUS_DIR + f\"{split}.nl\" for split in [\"valid\",\"train\"]]\n",
    "\n",
    "en_ro_files = [EN_RO_CORPUS_DIR + f\"{split}.en\" for split in [\"valid\",\"train\"]]\n",
    "ro_en_files = [EN_RO_CORPUS_DIR + f\"{split}.ro\" for split in [\"valid\",\"train\"]]\n",
    "\n",
    "de_en_files = [DE_EN_CORPUS_DIR + f\"{split}.de\" for split in [\"valid\", \"train\"]]\n",
    "en_de_files = [DE_EN_CORPUS_DIR + f\"{split}.en\" for split in [\"valid\", \"train\"]]\n",
    "\n",
    "\n",
    "files = en_it_files + it_en_files + en_nl_files + nl_en_files + en_ro_files + ro_en_files + de_en_files + en_de_files\n",
    "it_nl_ro_en_de_tokenizer.train(files= files, trainer=it_nl_ro_en_de_trainer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "\n",
    "\n",
    "def tokenize_files(tokenizer, files, extension, output_path):\n",
    "    for file in files:\n",
    "        print(f\"Reading file {file}\")\n",
    "        with open(file, encoding='utf8') as f:\n",
    "          lines = f.readlines()\n",
    "          tokenized_lines = tokenizer.encode_batch(lines)\n",
    "          tokenized_name = Path(file).stem\n",
    "          tokenized_name = output_path + tokenized_name + \".\" + extension\n",
    "          print(tokenized_name)\n",
    "          with open(tokenized_name, 'w', encoding='utf8') as wf:\n",
    "\n",
    "            wf.writelines([\" \".join(t.tokens) + \"\\n\" for t in tokenized_lines])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "mkdir -p /storage/master-thesis/models/it-nl-ro-en+de-en/tokenizers/it-nl-ro-en-de"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/storage/master-thesis/models/it-nl-ro-en+de-en/tokenizers/it-nl-ro-en-de\n"
     ]
    }
   ],
   "source": [
    "cd /storage/master-thesis/models/it-nl-ro-en+de-en/tokenizers/it-nl-ro-en-de"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "it_nl_ro_en_de_tokenizer.save(tokenizer_path + \"it_nl_ro_en_de_tokenizer.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['we', 'hold', 'this', 'truth', 'to', 'be', 'self', 'evident', '##ly', 'that', 'everyone', 'is', 'created', 'equal', '?']\n"
     ]
    }
   ],
   "source": [
    "tok = it_nl_ro_en_de_tokenizer.encode(\"we hold this truth to be self evidently that everyone is created equal?\")\n",
    "print(tok.tokens)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/storage/master-thesis/models/it-nl-ro-en+de-en/tokenizers/it-nl-ro-en-de\n"
     ]
    }
   ],
   "source": [
    "cd /storage/master-thesis/models/it-nl-ro-en+de-en/tokenizers/it-nl-ro-en-de/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mkdir: cannot create directory 'en-it': File exists\n",
      "mkdir: cannot create directory 'en-nl': File exists\n",
      "mkdir: cannot create directory 'en-ro': File exists\n",
      "mkdir: cannot create directory 'de-en': File exists\n"
     ]
    }
   ],
   "source": [
    "! mkdir en-it\n",
    "! mkdir en-nl\n",
    "! mkdir en-ro\n",
    "! mkdir de-en"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading file /notebooks/master-thesis/corpora/iwslt17/en-it/valid.en\n",
      "/storage/master-thesis/models/it-nl-ro-en+de-en/tokenizers/it-nl-ro-en-de/en-it/valid.en\n",
      "Reading file /notebooks/master-thesis/corpora/iwslt17/en-it/train.en\n",
      "/storage/master-thesis/models/it-nl-ro-en+de-en/tokenizers/it-nl-ro-en-de/en-it/train.en\n",
      "Reading file /notebooks/master-thesis/corpora/iwslt17/en-it/valid.it\n",
      "/storage/master-thesis/models/it-nl-ro-en+de-en/tokenizers/it-nl-ro-en-de/en-it/valid.it\n",
      "Reading file /notebooks/master-thesis/corpora/iwslt17/en-it/train.it\n",
      "/storage/master-thesis/models/it-nl-ro-en+de-en/tokenizers/it-nl-ro-en-de/en-it/train.it\n",
      "Reading file /notebooks/master-thesis/corpora/iwslt17/en-nl/valid.en\n",
      "/storage/master-thesis/models/it-nl-ro-en+de-en/tokenizers/it-nl-ro-en-de/en-nl/valid.en\n",
      "Reading file /notebooks/master-thesis/corpora/iwslt17/en-nl/train.en\n",
      "/storage/master-thesis/models/it-nl-ro-en+de-en/tokenizers/it-nl-ro-en-de/en-nl/train.en\n",
      "Reading file /notebooks/master-thesis/corpora/iwslt17/en-nl/valid.nl\n",
      "/storage/master-thesis/models/it-nl-ro-en+de-en/tokenizers/it-nl-ro-en-de/en-nl/valid.nl\n",
      "Reading file /notebooks/master-thesis/corpora/iwslt17/en-nl/train.nl\n",
      "/storage/master-thesis/models/it-nl-ro-en+de-en/tokenizers/it-nl-ro-en-de/en-nl/train.nl\n",
      "Reading file /notebooks/master-thesis/corpora/iwslt17/en-ro/valid.en\n",
      "/storage/master-thesis/models/it-nl-ro-en+de-en/tokenizers/it-nl-ro-en-de/en-ro/valid.en\n",
      "Reading file /notebooks/master-thesis/corpora/iwslt17/en-ro/train.en\n",
      "/storage/master-thesis/models/it-nl-ro-en+de-en/tokenizers/it-nl-ro-en-de/en-ro/train.en\n",
      "Reading file /notebooks/master-thesis/corpora/iwslt17/en-ro/valid.ro\n",
      "/storage/master-thesis/models/it-nl-ro-en+de-en/tokenizers/it-nl-ro-en-de/en-ro/valid.ro\n",
      "Reading file /notebooks/master-thesis/corpora/iwslt17/en-ro/train.ro\n",
      "/storage/master-thesis/models/it-nl-ro-en+de-en/tokenizers/it-nl-ro-en-de/en-ro/train.ro\n",
      "Reading file /notebooks/master-thesis/corpora/iwslt17/de-en/valid.de\n",
      "/storage/master-thesis/models/it-nl-ro-en+de-en/tokenizers/it-nl-ro-en-de/de-en/valid.de\n",
      "Reading file /notebooks/master-thesis/corpora/iwslt17/de-en/train.de\n",
      "/storage/master-thesis/models/it-nl-ro-en+de-en/tokenizers/it-nl-ro-en-de/de-en/train.de\n",
      "Reading file /notebooks/master-thesis/corpora/iwslt17/de-en/valid.en\n",
      "/storage/master-thesis/models/it-nl-ro-en+de-en/tokenizers/it-nl-ro-en-de/de-en/valid.en\n",
      "Reading file /notebooks/master-thesis/corpora/iwslt17/de-en/train.en\n",
      "/storage/master-thesis/models/it-nl-ro-en+de-en/tokenizers/it-nl-ro-en-de/de-en/train.en\n"
     ]
    }
   ],
   "source": [
    "tokenize_files(it_nl_ro_en_de_tokenizer, en_it_files, \"en\", tokenized_path_en_it)\n",
    "tokenize_files(it_nl_ro_en_de_tokenizer, it_en_files, \"it\", tokenized_path_en_it)\n",
    "\n",
    "tokenize_files(it_nl_ro_en_de_tokenizer, en_nl_files, \"en\", tokenized_path_en_nl)\n",
    "tokenize_files(it_nl_ro_en_de_tokenizer, nl_en_files, \"nl\", tokenized_path_en_nl)\n",
    "\n",
    "tokenize_files(it_nl_ro_en_de_tokenizer, en_ro_files, \"en\", tokenized_path_en_ro)\n",
    "tokenize_files(it_nl_ro_en_de_tokenizer, ro_en_files, \"ro\", tokenized_path_en_ro)\n",
    "\n",
    "tokenize_files(it_nl_ro_en_de_tokenizer, de_en_files, \"de\", tokenized_path_de_en)\n",
    "tokenize_files(it_nl_ro_en_de_tokenizer, en_de_files, \"en\", tokenized_path_de_en)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Binarizing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mkdir: cannot create directory '/storage/master-thesis/models/it-nl-ro-en+de-en/tokenizers/it-nl-ro-en-de/bin/': File exists\n"
     ]
    }
   ],
   "source": [
    "mkdir /storage/master-thesis/models/it-nl-ro-en+de-en/tokenizers/it-nl-ro-en-de/bin/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Concatenating all training data\n",
    "! cat $TOKENIZED_PATH_EN_IT/train.en $TOKENIZED_PATH_EN_IT/train.it \\\n",
    "    $TOKENIZED_PATH_EN_NL/train.en $TOKENIZED_PATH_EN_NL/train.nl \\\n",
    "    $TOKENIZED_PATH_EN_RO/train.en $TOKENIZED_PATH_EN_RO/train.ro \\\n",
    "    $TOKENIZED_PATH_DE_EN/train.de $TOKENIZED_PATH_DE_EN/train.en \\\n",
    "    > $BIN_DIR/train.all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-06-22 13:13:08 | INFO | fairseq_cli.preprocess | Namespace(align_suffix=None, alignfile=None, all_gather_list_size=16384, bf16=False, bpe=None, checkpoint_shard_count=1, checkpoint_suffix='', cpu=False, criterion='cross_entropy', dataset_impl='mmap', destdir='/storage/master-thesis/models/it-nl-ro-en+de-en/tokenizers/it-nl-ro-en-de/bin', empty_cache_freq=0, fp16=False, fp16_init_scale=128, fp16_no_flatten_grads=False, fp16_scale_tolerance=0.0, fp16_scale_window=None, joined_dictionary=False, log_format=None, log_interval=100, lr_scheduler='fixed', memory_efficient_bf16=False, memory_efficient_fp16=False, min_loss_scale=0.0001, model_parallel_size=1, no_progress_bar=False, nwordssrc=-1, nwordstgt=-1, only_source=True, optimizer=None, padding_factor=8, profile=False, quantization_config_path=None, scoring='bleu', seed=1, source_lang='all', srcdict=None, target_lang=None, task='translation_multi_simple_epoch', tensorboard_logdir=None, testpref=None, tgtdict=None, threshold_loss_scale=None, thresholdsrc=0, thresholdtgt=0, tokenizer=None, tpu=False, trainpref='/storage/master-thesis/models/it-nl-ro-en+de-en/tokenizers/it-nl-ro-en-de/bin/train', user_dir=None, validpref=None, workers=20)\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/bin/fairseq-preprocess\", line 8, in <module>\n",
      "    sys.exit(cli_main())\n",
      "  File \"/usr/local/lib/python3.6/dist-packages/fairseq_cli/preprocess.py\", line 394, in cli_main\n",
      "    main(args)\n",
      "  File \"/usr/local/lib/python3.6/dist-packages/fairseq_cli/preprocess.py\", line 74, in main\n",
      "    raise FileExistsError(dict_path(args.source_lang))\n",
      "FileExistsError: /storage/master-thesis/models/it-nl-ro-en+de-en/tokenizers/it-nl-ro-en-de/bin/dict.all.txt\n"
     ]
    }
   ],
   "source": [
    "! fairseq-preprocess --source-lang all \\\n",
    "    --trainpref $BIN_DIR/train \\\n",
    "    --destdir $BIN_DIR \\\n",
    "    --workers 20 \\\n",
    "    --task translation_multi_simple_epoch \\\n",
    "    --only-source"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-01-11 01:14:22 | INFO | fairseq_cli.preprocess | Namespace(align_suffix=None, alignfile=None, all_gather_list_size=16384, bf16=False, bpe=None, checkpoint_shard_count=1, checkpoint_suffix='', cpu=False, criterion='cross_entropy', dataset_impl='mmap', destdir='/storage/master-thesis/models/it-nl-ro-en+de-en/tokenizers/it-nl-ro-en-de/bin', empty_cache_freq=0, fp16=False, fp16_init_scale=128, fp16_no_flatten_grads=False, fp16_scale_tolerance=0.0, fp16_scale_window=None, joined_dictionary=False, log_format=None, log_interval=100, lr_scheduler='fixed', memory_efficient_bf16=False, memory_efficient_fp16=False, min_loss_scale=0.0001, model_parallel_size=1, no_progress_bar=False, nwordssrc=-1, nwordstgt=-1, only_source=False, optimizer=None, padding_factor=8, profile=False, quantization_config_path=None, scoring='bleu', seed=1, source_lang='en', srcdict='/storage/master-thesis/models/it-nl-ro-en+de-en/tokenizers/it-nl-ro-en-de/bin/dict.all.txt', target_lang='it', task='translation_multi_simple_epoch', tensorboard_logdir=None, testpref=None, tgtdict='/storage/master-thesis/models/it-nl-ro-en+de-en/tokenizers/it-nl-ro-en-de/bin/dict.all.txt', threshold_loss_scale=None, thresholdsrc=0, thresholdtgt=0, tokenizer=None, tpu=False, trainpref='/storage/master-thesis/models/it-nl-ro-en+de-en/tokenizers/it-nl-ro-en-de/en-it/train', user_dir=None, validpref='/storage/master-thesis/models/it-nl-ro-en+de-en/tokenizers/it-nl-ro-en-de/en-it/valid', workers=20)\n",
      "2022-01-11 01:14:22 | INFO | fairseq_cli.preprocess | [en] Dictionary: 29328 types\n",
      "2022-01-11 01:14:25 | INFO | fairseq_cli.preprocess | [en] /storage/master-thesis/models/it-nl-ro-en+de-en/tokenizers/it-nl-ro-en-de/en-it/train.en: 145105 sents, 3332751 tokens, 0.0239% replaced by <unk>\n",
      "2022-01-11 01:14:25 | INFO | fairseq_cli.preprocess | [en] Dictionary: 29328 types\n",
      "2022-01-11 01:14:26 | INFO | fairseq_cli.preprocess | [en] /storage/master-thesis/models/it-nl-ro-en+de-en/tokenizers/it-nl-ro-en-de/en-it/valid.en: 929 sents, 24225 tokens, 0.111% replaced by <unk>\n",
      "2022-01-11 01:14:26 | INFO | fairseq_cli.preprocess | [it] Dictionary: 29328 types\n",
      "2022-01-11 01:14:29 | INFO | fairseq_cli.preprocess | [it] /storage/master-thesis/models/it-nl-ro-en+de-en/tokenizers/it-nl-ro-en-de/en-it/train.it: 145105 sents, 3375399 tokens, 0.0403% replaced by <unk>\n",
      "2022-01-11 01:14:29 | INFO | fairseq_cli.preprocess | [it] Dictionary: 29328 types\n",
      "2022-01-11 01:14:30 | INFO | fairseq_cli.preprocess | [it] /storage/master-thesis/models/it-nl-ro-en+de-en/tokenizers/it-nl-ro-en-de/en-it/valid.it: 929 sents, 23680 tokens, 0.0887% replaced by <unk>\n",
      "2022-01-11 01:14:30 | INFO | fairseq_cli.preprocess | Wrote preprocessed data to /storage/master-thesis/models/it-nl-ro-en+de-en/tokenizers/it-nl-ro-en-de/bin\n"
     ]
    }
   ],
   "source": [
    "! fairseq-preprocess --source-lang en --target-lang it \\\n",
    "    --trainpref $TOKENIZED_PATH_EN_IT/train --validpref $TOKENIZED_PATH_EN_IT/valid \\\n",
    "    --destdir $BIN_DIR \\\n",
    "    --srcdict $BIN_DIR/dict.all.txt \\\n",
    "    --tgtdict $BIN_DIR/dict.all.txt \\\n",
    "    --task translation_multi_simple_epoch \\\n",
    "    --workers 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-01-11 01:14:33 | INFO | fairseq_cli.preprocess | Namespace(align_suffix=None, alignfile=None, all_gather_list_size=16384, bf16=False, bpe=None, checkpoint_shard_count=1, checkpoint_suffix='', cpu=False, criterion='cross_entropy', dataset_impl='mmap', destdir='/storage/master-thesis/models/it-nl-ro-en+de-en/tokenizers/it-nl-ro-en-de/bin', empty_cache_freq=0, fp16=False, fp16_init_scale=128, fp16_no_flatten_grads=False, fp16_scale_tolerance=0.0, fp16_scale_window=None, joined_dictionary=False, log_format=None, log_interval=100, lr_scheduler='fixed', memory_efficient_bf16=False, memory_efficient_fp16=False, min_loss_scale=0.0001, model_parallel_size=1, no_progress_bar=False, nwordssrc=-1, nwordstgt=-1, only_source=False, optimizer=None, padding_factor=8, profile=False, quantization_config_path=None, scoring='bleu', seed=1, source_lang='it', srcdict='/storage/master-thesis/models/it-nl-ro-en+de-en/tokenizers/it-nl-ro-en-de/bin/dict.all.txt', target_lang='en', task='translation_multi_simple_epoch', tensorboard_logdir=None, testpref=None, tgtdict='/storage/master-thesis/models/it-nl-ro-en+de-en/tokenizers/it-nl-ro-en-de/bin/dict.all.txt', threshold_loss_scale=None, thresholdsrc=0, thresholdtgt=0, tokenizer=None, tpu=False, trainpref='/storage/master-thesis/models/it-nl-ro-en+de-en/tokenizers/it-nl-ro-en-de/en-it/train', user_dir=None, validpref='/storage/master-thesis/models/it-nl-ro-en+de-en/tokenizers/it-nl-ro-en-de/en-it/valid', workers=20)\n",
      "2022-01-11 01:14:33 | INFO | fairseq_cli.preprocess | [it] Dictionary: 29328 types\n",
      "2022-01-11 01:14:37 | INFO | fairseq_cli.preprocess | [it] /storage/master-thesis/models/it-nl-ro-en+de-en/tokenizers/it-nl-ro-en-de/en-it/train.it: 145105 sents, 3375399 tokens, 0.0403% replaced by <unk>\n",
      "2022-01-11 01:14:37 | INFO | fairseq_cli.preprocess | [it] Dictionary: 29328 types\n",
      "2022-01-11 01:14:37 | INFO | fairseq_cli.preprocess | [it] /storage/master-thesis/models/it-nl-ro-en+de-en/tokenizers/it-nl-ro-en-de/en-it/valid.it: 929 sents, 23680 tokens, 0.0887% replaced by <unk>\n",
      "2022-01-11 01:14:37 | INFO | fairseq_cli.preprocess | [en] Dictionary: 29328 types\n",
      "2022-01-11 01:14:41 | INFO | fairseq_cli.preprocess | [en] /storage/master-thesis/models/it-nl-ro-en+de-en/tokenizers/it-nl-ro-en-de/en-it/train.en: 145105 sents, 3332751 tokens, 0.0239% replaced by <unk>\n",
      "2022-01-11 01:14:41 | INFO | fairseq_cli.preprocess | [en] Dictionary: 29328 types\n",
      "2022-01-11 01:14:41 | INFO | fairseq_cli.preprocess | [en] /storage/master-thesis/models/it-nl-ro-en+de-en/tokenizers/it-nl-ro-en-de/en-it/valid.en: 929 sents, 24225 tokens, 0.111% replaced by <unk>\n",
      "2022-01-11 01:14:41 | INFO | fairseq_cli.preprocess | Wrote preprocessed data to /storage/master-thesis/models/it-nl-ro-en+de-en/tokenizers/it-nl-ro-en-de/bin\n"
     ]
    }
   ],
   "source": [
    "! fairseq-preprocess --source-lang it --target-lang en \\\n",
    "    --trainpref $TOKENIZED_PATH_EN_IT/train --validpref $TOKENIZED_PATH_EN_IT/valid \\\n",
    "    --destdir $BIN_DIR \\\n",
    "    --srcdict $BIN_DIR/dict.all.txt \\\n",
    "    --tgtdict $BIN_DIR/dict.all.txt \\\n",
    "    --task translation_multi_simple_epoch \\\n",
    "    --workers 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-01-11 01:14:43 | INFO | fairseq_cli.preprocess | Namespace(align_suffix=None, alignfile=None, all_gather_list_size=16384, bf16=False, bpe=None, checkpoint_shard_count=1, checkpoint_suffix='', cpu=False, criterion='cross_entropy', dataset_impl='mmap', destdir='/storage/master-thesis/models/it-nl-ro-en+de-en/tokenizers/it-nl-ro-en-de/bin', empty_cache_freq=0, fp16=False, fp16_init_scale=128, fp16_no_flatten_grads=False, fp16_scale_tolerance=0.0, fp16_scale_window=None, joined_dictionary=False, log_format=None, log_interval=100, lr_scheduler='fixed', memory_efficient_bf16=False, memory_efficient_fp16=False, min_loss_scale=0.0001, model_parallel_size=1, no_progress_bar=False, nwordssrc=-1, nwordstgt=-1, only_source=False, optimizer=None, padding_factor=8, profile=False, quantization_config_path=None, scoring='bleu', seed=1, source_lang='en', srcdict='/storage/master-thesis/models/it-nl-ro-en+de-en/tokenizers/it-nl-ro-en-de/bin/dict.all.txt', target_lang='nl', task='translation_multi_simple_epoch', tensorboard_logdir=None, testpref=None, tgtdict='/storage/master-thesis/models/it-nl-ro-en+de-en/tokenizers/it-nl-ro-en-de/bin/dict.all.txt', threshold_loss_scale=None, thresholdsrc=0, thresholdtgt=0, tokenizer=None, tpu=False, trainpref='/storage/master-thesis/models/it-nl-ro-en+de-en/tokenizers/it-nl-ro-en-de/en-nl/train', user_dir=None, validpref='/storage/master-thesis/models/it-nl-ro-en+de-en/tokenizers/it-nl-ro-en-de/en-nl/valid', workers=20)\n",
      "2022-01-11 01:14:43 | INFO | fairseq_cli.preprocess | [en] Dictionary: 29328 types\n",
      "2022-01-11 01:14:47 | INFO | fairseq_cli.preprocess | [en] /storage/master-thesis/models/it-nl-ro-en+de-en/tokenizers/it-nl-ro-en-de/en-nl/train.en: 145105 sents, 3332751 tokens, 0.0239% replaced by <unk>\n",
      "2022-01-11 01:14:47 | INFO | fairseq_cli.preprocess | [en] Dictionary: 29328 types\n",
      "2022-01-11 01:14:47 | INFO | fairseq_cli.preprocess | [en] /storage/master-thesis/models/it-nl-ro-en+de-en/tokenizers/it-nl-ro-en-de/en-nl/valid.en: 1003 sents, 24300 tokens, 0.111% replaced by <unk>\n",
      "2022-01-11 01:14:47 | INFO | fairseq_cli.preprocess | [nl] Dictionary: 29328 types\n",
      "2022-01-11 01:14:51 | INFO | fairseq_cli.preprocess | [nl] /storage/master-thesis/models/it-nl-ro-en+de-en/tokenizers/it-nl-ro-en-de/en-nl/train.nl: 145105 sents, 3191574 tokens, 0.0444% replaced by <unk>\n",
      "2022-01-11 01:14:51 | INFO | fairseq_cli.preprocess | [nl] Dictionary: 29328 types\n",
      "2022-01-11 01:14:51 | INFO | fairseq_cli.preprocess | [nl] /storage/master-thesis/models/it-nl-ro-en+de-en/tokenizers/it-nl-ro-en-de/en-nl/valid.nl: 1003 sents, 22731 tokens, 0.0924% replaced by <unk>\n",
      "2022-01-11 01:14:51 | INFO | fairseq_cli.preprocess | Wrote preprocessed data to /storage/master-thesis/models/it-nl-ro-en+de-en/tokenizers/it-nl-ro-en-de/bin\n"
     ]
    }
   ],
   "source": [
    "! fairseq-preprocess --source-lang en --target-lang nl \\\n",
    "    --trainpref $TOKENIZED_PATH_EN_NL/train --validpref $TOKENIZED_PATH_EN_NL/valid \\\n",
    "    --destdir $BIN_DIR \\\n",
    "    --srcdict $BIN_DIR/dict.all.txt \\\n",
    "    --tgtdict $BIN_DIR/dict.all.txt \\\n",
    "    --task translation_multi_simple_epoch \\\n",
    "    --workers 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-01-11 01:14:53 | INFO | fairseq_cli.preprocess | Namespace(align_suffix=None, alignfile=None, all_gather_list_size=16384, bf16=False, bpe=None, checkpoint_shard_count=1, checkpoint_suffix='', cpu=False, criterion='cross_entropy', dataset_impl='mmap', destdir='/storage/master-thesis/models/it-nl-ro-en+de-en/tokenizers/it-nl-ro-en-de/bin', empty_cache_freq=0, fp16=False, fp16_init_scale=128, fp16_no_flatten_grads=False, fp16_scale_tolerance=0.0, fp16_scale_window=None, joined_dictionary=False, log_format=None, log_interval=100, lr_scheduler='fixed', memory_efficient_bf16=False, memory_efficient_fp16=False, min_loss_scale=0.0001, model_parallel_size=1, no_progress_bar=False, nwordssrc=-1, nwordstgt=-1, only_source=False, optimizer=None, padding_factor=8, profile=False, quantization_config_path=None, scoring='bleu', seed=1, source_lang='nl', srcdict='/storage/master-thesis/models/it-nl-ro-en+de-en/tokenizers/it-nl-ro-en-de/bin/dict.all.txt', target_lang='en', task='translation_multi_simple_epoch', tensorboard_logdir=None, testpref=None, tgtdict='/storage/master-thesis/models/it-nl-ro-en+de-en/tokenizers/it-nl-ro-en-de/bin/dict.all.txt', threshold_loss_scale=None, thresholdsrc=0, thresholdtgt=0, tokenizer=None, tpu=False, trainpref='/storage/master-thesis/models/it-nl-ro-en+de-en/tokenizers/it-nl-ro-en-de/en-nl/train', user_dir=None, validpref='/storage/master-thesis/models/it-nl-ro-en+de-en/tokenizers/it-nl-ro-en-de/en-nl/valid', workers=20)\n",
      "2022-01-11 01:14:53 | INFO | fairseq_cli.preprocess | [nl] Dictionary: 29328 types\n",
      "2022-01-11 01:14:56 | INFO | fairseq_cli.preprocess | [nl] /storage/master-thesis/models/it-nl-ro-en+de-en/tokenizers/it-nl-ro-en-de/en-nl/train.nl: 145105 sents, 3191574 tokens, 0.0444% replaced by <unk>\n",
      "2022-01-11 01:14:56 | INFO | fairseq_cli.preprocess | [nl] Dictionary: 29328 types\n",
      "2022-01-11 01:14:57 | INFO | fairseq_cli.preprocess | [nl] /storage/master-thesis/models/it-nl-ro-en+de-en/tokenizers/it-nl-ro-en-de/en-nl/valid.nl: 1003 sents, 22731 tokens, 0.0924% replaced by <unk>\n",
      "2022-01-11 01:14:57 | INFO | fairseq_cli.preprocess | [en] Dictionary: 29328 types\n",
      "2022-01-11 01:15:00 | INFO | fairseq_cli.preprocess | [en] /storage/master-thesis/models/it-nl-ro-en+de-en/tokenizers/it-nl-ro-en-de/en-nl/train.en: 145105 sents, 3332751 tokens, 0.0239% replaced by <unk>\n",
      "2022-01-11 01:15:00 | INFO | fairseq_cli.preprocess | [en] Dictionary: 29328 types\n",
      "2022-01-11 01:15:01 | INFO | fairseq_cli.preprocess | [en] /storage/master-thesis/models/it-nl-ro-en+de-en/tokenizers/it-nl-ro-en-de/en-nl/valid.en: 1003 sents, 24300 tokens, 0.111% replaced by <unk>\n",
      "2022-01-11 01:15:01 | INFO | fairseq_cli.preprocess | Wrote preprocessed data to /storage/master-thesis/models/it-nl-ro-en+de-en/tokenizers/it-nl-ro-en-de/bin\n"
     ]
    }
   ],
   "source": [
    "! fairseq-preprocess --source-lang nl --target-lang en \\\n",
    "    --trainpref $TOKENIZED_PATH_EN_NL/train --validpref $TOKENIZED_PATH_EN_NL/valid \\\n",
    "    --destdir $BIN_DIR \\\n",
    "    --srcdict $BIN_DIR/dict.all.txt \\\n",
    "    --tgtdict $BIN_DIR/dict.all.txt \\\n",
    "    --task translation_multi_simple_epoch \\\n",
    "    --workers 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-01-11 01:15:02 | INFO | fairseq_cli.preprocess | Namespace(align_suffix=None, alignfile=None, all_gather_list_size=16384, bf16=False, bpe=None, checkpoint_shard_count=1, checkpoint_suffix='', cpu=False, criterion='cross_entropy', dataset_impl='mmap', destdir='/storage/master-thesis/models/it-nl-ro-en+de-en/tokenizers/it-nl-ro-en-de/bin', empty_cache_freq=0, fp16=False, fp16_init_scale=128, fp16_no_flatten_grads=False, fp16_scale_tolerance=0.0, fp16_scale_window=None, joined_dictionary=False, log_format=None, log_interval=100, lr_scheduler='fixed', memory_efficient_bf16=False, memory_efficient_fp16=False, min_loss_scale=0.0001, model_parallel_size=1, no_progress_bar=False, nwordssrc=-1, nwordstgt=-1, only_source=False, optimizer=None, padding_factor=8, profile=False, quantization_config_path=None, scoring='bleu', seed=1, source_lang='en', srcdict='/storage/master-thesis/models/it-nl-ro-en+de-en/tokenizers/it-nl-ro-en-de/bin/dict.all.txt', target_lang='ro', task='translation_multi_simple_epoch', tensorboard_logdir=None, testpref=None, tgtdict='/storage/master-thesis/models/it-nl-ro-en+de-en/tokenizers/it-nl-ro-en-de/bin/dict.all.txt', threshold_loss_scale=None, thresholdsrc=0, thresholdtgt=0, tokenizer=None, tpu=False, trainpref='/storage/master-thesis/models/it-nl-ro-en+de-en/tokenizers/it-nl-ro-en-de/en-ro/train', user_dir=None, validpref='/storage/master-thesis/models/it-nl-ro-en+de-en/tokenizers/it-nl-ro-en-de/en-ro/valid', workers=20)\n",
      "2022-01-11 01:15:03 | INFO | fairseq_cli.preprocess | [en] Dictionary: 29328 types\n",
      "2022-01-11 01:15:06 | INFO | fairseq_cli.preprocess | [en] /storage/master-thesis/models/it-nl-ro-en+de-en/tokenizers/it-nl-ro-en-de/en-ro/train.en: 145105 sents, 3332751 tokens, 0.0239% replaced by <unk>\n",
      "2022-01-11 01:15:06 | INFO | fairseq_cli.preprocess | [en] Dictionary: 29328 types\n",
      "2022-01-11 01:15:06 | INFO | fairseq_cli.preprocess | [en] /storage/master-thesis/models/it-nl-ro-en+de-en/tokenizers/it-nl-ro-en-de/en-ro/valid.en: 914 sents, 24223 tokens, 0.111% replaced by <unk>\n",
      "2022-01-11 01:15:06 | INFO | fairseq_cli.preprocess | [ro] Dictionary: 29328 types\n",
      "2022-01-11 01:15:11 | INFO | fairseq_cli.preprocess | [ro] /storage/master-thesis/models/it-nl-ro-en+de-en/tokenizers/it-nl-ro-en-de/en-ro/train.ro: 145105 sents, 3342971 tokens, 0.0687% replaced by <unk>\n",
      "2022-01-11 01:15:11 | INFO | fairseq_cli.preprocess | [ro] Dictionary: 29328 types\n",
      "2022-01-11 01:15:11 | INFO | fairseq_cli.preprocess | [ro] /storage/master-thesis/models/it-nl-ro-en+de-en/tokenizers/it-nl-ro-en-de/en-ro/valid.ro: 914 sents, 25026 tokens, 0.104% replaced by <unk>\n",
      "2022-01-11 01:15:11 | INFO | fairseq_cli.preprocess | Wrote preprocessed data to /storage/master-thesis/models/it-nl-ro-en+de-en/tokenizers/it-nl-ro-en-de/bin\n"
     ]
    }
   ],
   "source": [
    "! fairseq-preprocess --source-lang en --target-lang ro \\\n",
    "    --trainpref $TOKENIZED_PATH_EN_RO/train --validpref $TOKENIZED_PATH_EN_RO/valid \\\n",
    "    --destdir $BIN_DIR \\\n",
    "    --srcdict $BIN_DIR/dict.all.txt \\\n",
    "    --tgtdict $BIN_DIR/dict.all.txt \\\n",
    "    --task translation_multi_simple_epoch \\\n",
    "    --workers 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-01-11 01:15:13 | INFO | fairseq_cli.preprocess | Namespace(align_suffix=None, alignfile=None, all_gather_list_size=16384, bf16=False, bpe=None, checkpoint_shard_count=1, checkpoint_suffix='', cpu=False, criterion='cross_entropy', dataset_impl='mmap', destdir='/storage/master-thesis/models/it-nl-ro-en+de-en/tokenizers/it-nl-ro-en-de/bin', empty_cache_freq=0, fp16=False, fp16_init_scale=128, fp16_no_flatten_grads=False, fp16_scale_tolerance=0.0, fp16_scale_window=None, joined_dictionary=False, log_format=None, log_interval=100, lr_scheduler='fixed', memory_efficient_bf16=False, memory_efficient_fp16=False, min_loss_scale=0.0001, model_parallel_size=1, no_progress_bar=False, nwordssrc=-1, nwordstgt=-1, only_source=False, optimizer=None, padding_factor=8, profile=False, quantization_config_path=None, scoring='bleu', seed=1, source_lang='ro', srcdict='/storage/master-thesis/models/it-nl-ro-en+de-en/tokenizers/it-nl-ro-en-de/bin/dict.all.txt', target_lang='en', task='translation_multi_simple_epoch', tensorboard_logdir=None, testpref=None, tgtdict='/storage/master-thesis/models/it-nl-ro-en+de-en/tokenizers/it-nl-ro-en-de/bin/dict.all.txt', threshold_loss_scale=None, thresholdsrc=0, thresholdtgt=0, tokenizer=None, tpu=False, trainpref='/storage/master-thesis/models/it-nl-ro-en+de-en/tokenizers/it-nl-ro-en-de/en-ro/train', user_dir=None, validpref='/storage/master-thesis/models/it-nl-ro-en+de-en/tokenizers/it-nl-ro-en-de/en-ro/valid', workers=20)\n",
      "2022-01-11 01:15:13 | INFO | fairseq_cli.preprocess | [ro] Dictionary: 29328 types\n",
      "2022-01-11 01:15:17 | INFO | fairseq_cli.preprocess | [ro] /storage/master-thesis/models/it-nl-ro-en+de-en/tokenizers/it-nl-ro-en-de/en-ro/train.ro: 145105 sents, 3342971 tokens, 0.0687% replaced by <unk>\n",
      "2022-01-11 01:15:17 | INFO | fairseq_cli.preprocess | [ro] Dictionary: 29328 types\n",
      "2022-01-11 01:15:17 | INFO | fairseq_cli.preprocess | [ro] /storage/master-thesis/models/it-nl-ro-en+de-en/tokenizers/it-nl-ro-en-de/en-ro/valid.ro: 914 sents, 25026 tokens, 0.104% replaced by <unk>\n",
      "2022-01-11 01:15:17 | INFO | fairseq_cli.preprocess | [en] Dictionary: 29328 types\n",
      "2022-01-11 01:15:21 | INFO | fairseq_cli.preprocess | [en] /storage/master-thesis/models/it-nl-ro-en+de-en/tokenizers/it-nl-ro-en-de/en-ro/train.en: 145105 sents, 3332751 tokens, 0.0239% replaced by <unk>\n",
      "2022-01-11 01:15:21 | INFO | fairseq_cli.preprocess | [en] Dictionary: 29328 types\n",
      "2022-01-11 01:15:21 | INFO | fairseq_cli.preprocess | [en] /storage/master-thesis/models/it-nl-ro-en+de-en/tokenizers/it-nl-ro-en-de/en-ro/valid.en: 914 sents, 24223 tokens, 0.111% replaced by <unk>\n",
      "2022-01-11 01:15:21 | INFO | fairseq_cli.preprocess | Wrote preprocessed data to /storage/master-thesis/models/it-nl-ro-en+de-en/tokenizers/it-nl-ro-en-de/bin\n"
     ]
    }
   ],
   "source": [
    "! fairseq-preprocess --source-lang ro --target-lang en \\\n",
    "    --trainpref $TOKENIZED_PATH_EN_RO/train --validpref $TOKENIZED_PATH_EN_RO/valid \\\n",
    "    --destdir $BIN_DIR \\\n",
    "    --srcdict $BIN_DIR/dict.all.txt \\\n",
    "    --tgtdict $BIN_DIR/dict.all.txt \\\n",
    "    --task translation_multi_simple_epoch \\\n",
    "    --workers 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-01-11 01:15:23 | INFO | fairseq_cli.preprocess | Namespace(align_suffix=None, alignfile=None, all_gather_list_size=16384, bf16=False, bpe=None, checkpoint_shard_count=1, checkpoint_suffix='', cpu=False, criterion='cross_entropy', dataset_impl='mmap', destdir='/storage/master-thesis/models/it-nl-ro-en+de-en/tokenizers/it-nl-ro-en-de/bin', empty_cache_freq=0, fp16=False, fp16_init_scale=128, fp16_no_flatten_grads=False, fp16_scale_tolerance=0.0, fp16_scale_window=None, joined_dictionary=False, log_format=None, log_interval=100, lr_scheduler='fixed', memory_efficient_bf16=False, memory_efficient_fp16=False, min_loss_scale=0.0001, model_parallel_size=1, no_progress_bar=False, nwordssrc=-1, nwordstgt=-1, only_source=False, optimizer=None, padding_factor=8, profile=False, quantization_config_path=None, scoring='bleu', seed=1, source_lang='en', srcdict='/storage/master-thesis/models/it-nl-ro-en+de-en/tokenizers/it-nl-ro-en-de/bin/dict.all.txt', target_lang='de', task='translation_multi_simple_epoch', tensorboard_logdir=None, testpref=None, tgtdict='/storage/master-thesis/models/it-nl-ro-en+de-en/tokenizers/it-nl-ro-en-de/bin/dict.all.txt', threshold_loss_scale=None, thresholdsrc=0, thresholdtgt=0, tokenizer=None, tpu=False, trainpref='/storage/master-thesis/models/it-nl-ro-en+de-en/tokenizers/it-nl-ro-en-de/de-en/train', user_dir=None, validpref='/storage/master-thesis/models/it-nl-ro-en+de-en/tokenizers/it-nl-ro-en-de/de-en/valid', workers=20)\n",
      "2022-01-11 01:15:23 | INFO | fairseq_cli.preprocess | [en] Dictionary: 29328 types\n",
      "2022-01-11 01:15:24 | INFO | fairseq_cli.preprocess | [en] /storage/master-thesis/models/it-nl-ro-en+de-en/tokenizers/it-nl-ro-en-de/de-en/train.en: 14510 sents, 332275 tokens, 0.0259% replaced by <unk>\n",
      "2022-01-11 01:15:24 | INFO | fairseq_cli.preprocess | [en] Dictionary: 29328 types\n",
      "2022-01-11 01:15:24 | INFO | fairseq_cli.preprocess | [en] /storage/master-thesis/models/it-nl-ro-en+de-en/tokenizers/it-nl-ro-en-de/de-en/valid.en: 1138 sents, 24977 tokens, 2.77% replaced by <unk>\n",
      "2022-01-11 01:15:24 | INFO | fairseq_cli.preprocess | [de] Dictionary: 29328 types\n",
      "2022-01-11 01:15:25 | INFO | fairseq_cli.preprocess | [de] /storage/master-thesis/models/it-nl-ro-en+de-en/tokenizers/it-nl-ro-en-de/de-en/train.de: 14510 sents, 403265 tokens, 0.951% replaced by <unk>\n",
      "2022-01-11 01:15:25 | INFO | fairseq_cli.preprocess | [de] Dictionary: 29328 types\n",
      "2022-01-11 01:15:25 | INFO | fairseq_cli.preprocess | [de] /storage/master-thesis/models/it-nl-ro-en+de-en/tokenizers/it-nl-ro-en-de/de-en/valid.de: 1138 sents, 31232 tokens, 3.5% replaced by <unk>\n",
      "2022-01-11 01:15:25 | INFO | fairseq_cli.preprocess | Wrote preprocessed data to /storage/master-thesis/models/it-nl-ro-en+de-en/tokenizers/it-nl-ro-en-de/bin\n"
     ]
    }
   ],
   "source": [
    "! fairseq-preprocess --source-lang en --target-lang de \\\n",
    "    --trainpref $TOKENIZED_PATH_DE_EN/train --validpref $TOKENIZED_PATH_DE_EN/valid \\\n",
    "    --destdir $BIN_DIR \\\n",
    "    --srcdict $BIN_DIR/dict.all.txt \\\n",
    "    --tgtdict $BIN_DIR/dict.all.txt \\\n",
    "    --task translation_multi_simple_epoch \\\n",
    "    --workers 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-01-11 01:15:27 | INFO | fairseq_cli.preprocess | Namespace(align_suffix=None, alignfile=None, all_gather_list_size=16384, bf16=False, bpe=None, checkpoint_shard_count=1, checkpoint_suffix='', cpu=False, criterion='cross_entropy', dataset_impl='mmap', destdir='/storage/master-thesis/models/it-nl-ro-en+de-en/tokenizers/it-nl-ro-en-de/bin', empty_cache_freq=0, fp16=False, fp16_init_scale=128, fp16_no_flatten_grads=False, fp16_scale_tolerance=0.0, fp16_scale_window=None, joined_dictionary=False, log_format=None, log_interval=100, lr_scheduler='fixed', memory_efficient_bf16=False, memory_efficient_fp16=False, min_loss_scale=0.0001, model_parallel_size=1, no_progress_bar=False, nwordssrc=-1, nwordstgt=-1, only_source=False, optimizer=None, padding_factor=8, profile=False, quantization_config_path=None, scoring='bleu', seed=1, source_lang='de', srcdict='/storage/master-thesis/models/it-nl-ro-en+de-en/tokenizers/it-nl-ro-en-de/bin/dict.all.txt', target_lang='en', task='translation_multi_simple_epoch', tensorboard_logdir=None, testpref=None, tgtdict='/storage/master-thesis/models/it-nl-ro-en+de-en/tokenizers/it-nl-ro-en-de/bin/dict.all.txt', threshold_loss_scale=None, thresholdsrc=0, thresholdtgt=0, tokenizer=None, tpu=False, trainpref='/storage/master-thesis/models/it-nl-ro-en+de-en/tokenizers/it-nl-ro-en-de/de-en/train', user_dir=None, validpref='/storage/master-thesis/models/it-nl-ro-en+de-en/tokenizers/it-nl-ro-en-de/de-en/valid', workers=20)\n",
      "2022-01-11 01:15:27 | INFO | fairseq_cli.preprocess | [de] Dictionary: 29328 types\n",
      "2022-01-11 01:15:27 | INFO | fairseq_cli.preprocess | [de] /storage/master-thesis/models/it-nl-ro-en+de-en/tokenizers/it-nl-ro-en-de/de-en/train.de: 14510 sents, 403265 tokens, 0.951% replaced by <unk>\n",
      "2022-01-11 01:15:27 | INFO | fairseq_cli.preprocess | [de] Dictionary: 29328 types\n",
      "2022-01-11 01:15:28 | INFO | fairseq_cli.preprocess | [de] /storage/master-thesis/models/it-nl-ro-en+de-en/tokenizers/it-nl-ro-en-de/de-en/valid.de: 1138 sents, 31232 tokens, 3.5% replaced by <unk>\n",
      "2022-01-11 01:15:28 | INFO | fairseq_cli.preprocess | [en] Dictionary: 29328 types\n",
      "2022-01-11 01:15:28 | INFO | fairseq_cli.preprocess | [en] /storage/master-thesis/models/it-nl-ro-en+de-en/tokenizers/it-nl-ro-en-de/de-en/train.en: 14510 sents, 332275 tokens, 0.0259% replaced by <unk>\n",
      "2022-01-11 01:15:28 | INFO | fairseq_cli.preprocess | [en] Dictionary: 29328 types\n",
      "2022-01-11 01:15:29 | INFO | fairseq_cli.preprocess | [en] /storage/master-thesis/models/it-nl-ro-en+de-en/tokenizers/it-nl-ro-en-de/de-en/valid.en: 1138 sents, 24977 tokens, 2.77% replaced by <unk>\n",
      "2022-01-11 01:15:29 | INFO | fairseq_cli.preprocess | Wrote preprocessed data to /storage/master-thesis/models/it-nl-ro-en+de-en/tokenizers/it-nl-ro-en-de/bin\n"
     ]
    }
   ],
   "source": [
    "! fairseq-preprocess --source-lang de --target-lang en \\\n",
    "    --trainpref $TOKENIZED_PATH_DE_EN/train --validpref $TOKENIZED_PATH_DE_EN/valid \\\n",
    "    --destdir $BIN_DIR \\\n",
    "    --srcdict $BIN_DIR/dict.all.txt \\\n",
    "    --tgtdict $BIN_DIR/dict.all.txt \\\n",
    "    --task translation_multi_simple_epoch \\\n",
    "    --workers 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/storage/master-thesis/models/it-nl-ro-en\n"
     ]
    }
   ],
   "source": [
    "cd /storage/master-thesis/models/it-nl-ro-en"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "rm ./*.pt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/storage/master-thesis/models/it-nl-ro-en+de-en/tokenizers/it-nl-ro-en-de/bin\n"
     ]
    }
   ],
   "source": [
    "! echo $BIN_DIR"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-09-14 13:27:50 | INFO | fairseq_cli.train | Namespace(activation_dropout=0.0, activation_fn='relu', adam_betas='(0.9, 0.98)', adam_eps=1e-08, adaptive_input=False, adaptive_softmax_cutoff=None, adaptive_softmax_dropout=0, all_gather_list_size=16384, arch='transformer', attention_dropout=0.0, batch_size=None, batch_size_valid=None, best_checkpoint_metric='loss', bf16=False, bpe=None, broadcast_buffers=False, bucket_cap_mb=25, checkpoint_shard_count=1, checkpoint_suffix='', clip_norm=0.0, cpu=False, criterion='label_smoothed_cross_entropy', cross_self_attention=False, curriculum=0, data='/storage/master-thesis/models/it-nl-ro-en+de-en/tokenizers/it-nl-ro-en-de/bin', data_buffer_size=10, dataset_impl=None, ddp_backend='c10d', decoder_attention_heads=8, decoder_embed_dim=512, decoder_embed_path=None, decoder_ffn_embed_dim=2048, decoder_input_dim=512, decoder_langtok=True, decoder_layerdrop=0, decoder_layers=6, decoder_layers_to_keep=None, decoder_learned_pos=False, decoder_normalize_before=False, decoder_output_dim=512, device_id=0, disable_validation=False, distributed_backend='nccl', distributed_init_method=None, distributed_no_spawn=False, distributed_num_procs=1, distributed_port=-1, distributed_rank=0, distributed_world_size=1, distributed_wrapper='DDP', dropout=0.3, empty_cache_freq=0, enable_lang_ids=False, enable_reservsed_directions_shared_datasets=False, encoder_attention_heads=8, encoder_embed_dim=512, encoder_embed_path=None, encoder_ffn_embed_dim=2048, encoder_langtok='src', encoder_layerdrop=0, encoder_layers=6, encoder_layers_to_keep=None, encoder_learned_pos=False, encoder_normalize_before=False, extra_data=None, extra_lang_pairs=None, fast_stat_sync=False, find_unused_parameters=False, finetune_from_model=None, fix_batches_to_gpus=False, fixed_dictionary=None, fixed_validation_seed=None, fp16=True, fp16_init_scale=128, fp16_no_flatten_grads=False, fp16_scale_tolerance=0.0, fp16_scale_window=None, gen_subset='test', ignore_prefix_size=0, keep_best_checkpoints=-1, keep_inference_langtok=False, keep_interval_updates=-1, keep_last_epochs=2, label_smoothing=0.1, lang_dict=None, lang_pairs='en-it,it-en,en-nl,nl-en,en-ro,ro-en,de-en,en-de', lang_tok_replacing_bos_eos=False, lang_tok_style='multilingual', langs=None, langtoks=None, langtoks_specs=['main'], layernorm_embedding=False, left_pad_source='True', left_pad_target='False', load_alignments=False, localsgd_frequency=3, log_format=None, log_interval=100, lr=[5e-05], lr_scheduler='inverse_sqrt', max_epoch=200, max_source_positions=1024, max_target_positions=1024, max_tokens=4096, max_tokens_valid=4096, max_update=0, maximize_best_checkpoint_metric=False, memory_efficient_bf16=False, memory_efficient_fp16=False, min_loss_scale=0.0001, min_lr=-1.0, model_parallel_size=1, no_cross_attention=False, no_epoch_checkpoints=False, no_last_checkpoints=False, no_progress_bar=False, no_save=False, no_save_optimizer_state=False, no_scale_embedding=False, no_seed_provided=False, no_token_positional_embeddings=False, nprocs_per_node=1, num_shards=1, num_workers=1, optimizer='adam', optimizer_overrides='{}', patience=-1, pipeline_balance=None, pipeline_checkpoint='never', pipeline_chunks=0, pipeline_decoder_balance=None, pipeline_decoder_devices=None, pipeline_devices=None, pipeline_encoder_balance=None, pipeline_encoder_devices=None, pipeline_model_parallel=False, profile=False, quant_noise_pq=0, quant_noise_pq_block_size=8, quant_noise_scalar=0, quantization_config_path=None, report_accuracy=False, required_batch_size_multiple=8, required_seq_len_multiple=1, reset_dataloader=False, reset_lr_scheduler=False, reset_meters=False, reset_optimizer=True, restore_file='/storage/master-thesis/models/it-nl-ro-en+de-en/checkpoint_last.pt', sampling_method='concat', sampling_temperature=1.5, sampling_weights=None, sampling_weights_from_file=None, save_dir='/storage/master-thesis/models/it-nl-ro-en+de-en/', save_interval=1, save_interval_updates=0, scoring='bleu', seed=1, sentence_avg=False, shard_id=0, share_all_embeddings=True, share_decoder_input_output_embed=False, skip_invalid_size_inputs_valid_test=False, slowmo_algorithm='LocalSGD', slowmo_momentum=None, source_lang=None, stop_time_hours=0, target_lang=None, task='translation_multi_simple_epoch', tensorboard_logdir=None, threshold_loss_scale=None, tie_adaptive_weights=False, tokenizer=None, tpu=False, train_subset='train', truncate_source=False, update_freq=[1], upsample_primary=1, use_bmuf=False, use_old_adam=False, user_dir=None, valid_subset='valid', validate_after_updates=0, validate_interval=1, validate_interval_updates=0, virtual_data_size=None, virtual_epoch_size=1000000, warmup_init_lr=-1, warmup_updates=4000, weight_decay=0.0001, zero_sharding='none')\n",
      "2022-09-14 13:27:50 | WARNING | fairseq.data.multilingual.multilingual_data_manager | External language dictionary is not provided; use lang-pairs to infer the set of supported languages. The language ordering is not stable which might cause misalignment in pretraining and finetuning.\n",
      "2022-09-14 13:27:50 | INFO | fairseq.data.multilingual.multilingual_data_manager | inferred language list: ['de', 'en', 'it', 'nl', 'ro']\n",
      "2022-09-14 13:27:50 | INFO | fairseq.data.multilingual.multilingual_data_manager | [de] dictionary: 29333 types\n",
      "2022-09-14 13:27:51 | INFO | fairseq.data.multilingual.multilingual_data_manager | [en] dictionary: 29333 types\n",
      "2022-09-14 13:27:51 | INFO | fairseq.data.multilingual.multilingual_data_manager | [it] dictionary: 29333 types\n",
      "2022-09-14 13:27:51 | INFO | fairseq.data.multilingual.multilingual_data_manager | [nl] dictionary: 29333 types\n",
      "2022-09-14 13:27:51 | INFO | fairseq.data.multilingual.multilingual_data_manager | [ro] dictionary: 29333 types\n",
      "2022-09-14 13:27:51 | INFO | fairseq.tasks.translation_multi_simple_epoch | loading data for valid epoch=1/None\n",
      "2022-09-14 13:27:51 | INFO | fairseq.tasks.translation_multi_simple_epoch | mem usage: N/A\n",
      "2022-09-14 13:27:51 | INFO | fairseq.data.multilingual.multilingual_data_manager | langtoks settings: {'main': ('src', 'tgt')}\n",
      "2022-09-14 13:27:51 | INFO | fairseq.data.multilingual.multilingual_data_manager | [valid] num of shards: {'main:en-it': 1, 'main:it-en': 1, 'main:en-nl': 1, 'main:nl-en': 1, 'main:en-ro': 1, 'main:ro-en': 1, 'main:de-en': 1, 'main:en-de': 1}\n",
      "2022-09-14 13:27:51 | INFO | fairseq.data.multilingual.multilingual_data_manager | main:en-it src_langtok: 29329; tgt_langtok: 29330\n",
      "2022-09-14 13:27:51 | INFO | fairseq.data.data_utils | loaded 929 examples from: /storage/master-thesis/models/it-nl-ro-en+de-en/tokenizers/it-nl-ro-en-de/bin/valid.en-it.en\n",
      "2022-09-14 13:27:51 | INFO | fairseq.data.data_utils | loaded 929 examples from: /storage/master-thesis/models/it-nl-ro-en+de-en/tokenizers/it-nl-ro-en-de/bin/valid.en-it.it\n",
      "2022-09-14 13:27:51 | INFO | fairseq.data.multilingual.multilingual_data_manager | /storage/master-thesis/models/it-nl-ro-en+de-en/tokenizers/it-nl-ro-en-de/bin valid en-it 929 examples\n",
      "2022-09-14 13:27:51 | INFO | fairseq.data.multilingual.multilingual_data_manager | main:it-en src_langtok: 29330; tgt_langtok: 29329\n",
      "2022-09-14 13:27:51 | INFO | fairseq.data.data_utils | loaded 929 examples from: /storage/master-thesis/models/it-nl-ro-en+de-en/tokenizers/it-nl-ro-en-de/bin/valid.it-en.it\n",
      "2022-09-14 13:27:51 | INFO | fairseq.data.data_utils | loaded 929 examples from: /storage/master-thesis/models/it-nl-ro-en+de-en/tokenizers/it-nl-ro-en-de/bin/valid.it-en.en\n",
      "2022-09-14 13:27:51 | INFO | fairseq.data.multilingual.multilingual_data_manager | /storage/master-thesis/models/it-nl-ro-en+de-en/tokenizers/it-nl-ro-en-de/bin valid it-en 929 examples\n",
      "2022-09-14 13:27:51 | INFO | fairseq.data.multilingual.multilingual_data_manager | main:en-nl src_langtok: 29329; tgt_langtok: 29331\n",
      "2022-09-14 13:27:51 | INFO | fairseq.data.data_utils | loaded 1003 examples from: /storage/master-thesis/models/it-nl-ro-en+de-en/tokenizers/it-nl-ro-en-de/bin/valid.en-nl.en\n",
      "2022-09-14 13:27:51 | INFO | fairseq.data.data_utils | loaded 1003 examples from: /storage/master-thesis/models/it-nl-ro-en+de-en/tokenizers/it-nl-ro-en-de/bin/valid.en-nl.nl\n",
      "2022-09-14 13:27:51 | INFO | fairseq.data.multilingual.multilingual_data_manager | /storage/master-thesis/models/it-nl-ro-en+de-en/tokenizers/it-nl-ro-en-de/bin valid en-nl 1003 examples\n",
      "2022-09-14 13:27:51 | INFO | fairseq.data.multilingual.multilingual_data_manager | main:nl-en src_langtok: 29331; tgt_langtok: 29329\n",
      "2022-09-14 13:27:51 | INFO | fairseq.data.data_utils | loaded 1003 examples from: /storage/master-thesis/models/it-nl-ro-en+de-en/tokenizers/it-nl-ro-en-de/bin/valid.nl-en.nl\n",
      "2022-09-14 13:27:51 | INFO | fairseq.data.data_utils | loaded 1003 examples from: /storage/master-thesis/models/it-nl-ro-en+de-en/tokenizers/it-nl-ro-en-de/bin/valid.nl-en.en\n",
      "2022-09-14 13:27:51 | INFO | fairseq.data.multilingual.multilingual_data_manager | /storage/master-thesis/models/it-nl-ro-en+de-en/tokenizers/it-nl-ro-en-de/bin valid nl-en 1003 examples\n",
      "2022-09-14 13:27:51 | INFO | fairseq.data.multilingual.multilingual_data_manager | main:en-ro src_langtok: 29329; tgt_langtok: 29332\n",
      "2022-09-14 13:27:51 | INFO | fairseq.data.data_utils | loaded 914 examples from: /storage/master-thesis/models/it-nl-ro-en+de-en/tokenizers/it-nl-ro-en-de/bin/valid.en-ro.en\n",
      "2022-09-14 13:27:51 | INFO | fairseq.data.data_utils | loaded 914 examples from: /storage/master-thesis/models/it-nl-ro-en+de-en/tokenizers/it-nl-ro-en-de/bin/valid.en-ro.ro\n",
      "2022-09-14 13:27:51 | INFO | fairseq.data.multilingual.multilingual_data_manager | /storage/master-thesis/models/it-nl-ro-en+de-en/tokenizers/it-nl-ro-en-de/bin valid en-ro 914 examples\n",
      "2022-09-14 13:27:51 | INFO | fairseq.data.multilingual.multilingual_data_manager | main:ro-en src_langtok: 29332; tgt_langtok: 29329\n",
      "2022-09-14 13:27:51 | INFO | fairseq.data.data_utils | loaded 914 examples from: /storage/master-thesis/models/it-nl-ro-en+de-en/tokenizers/it-nl-ro-en-de/bin/valid.ro-en.ro\n",
      "2022-09-14 13:27:51 | INFO | fairseq.data.data_utils | loaded 914 examples from: /storage/master-thesis/models/it-nl-ro-en+de-en/tokenizers/it-nl-ro-en-de/bin/valid.ro-en.en\n",
      "2022-09-14 13:27:51 | INFO | fairseq.data.multilingual.multilingual_data_manager | /storage/master-thesis/models/it-nl-ro-en+de-en/tokenizers/it-nl-ro-en-de/bin valid ro-en 914 examples\n",
      "2022-09-14 13:27:51 | INFO | fairseq.data.multilingual.multilingual_data_manager | main:de-en src_langtok: 29328; tgt_langtok: 29329\n",
      "2022-09-14 13:27:51 | INFO | fairseq.data.data_utils | loaded 1138 examples from: /storage/master-thesis/models/it-nl-ro-en+de-en/tokenizers/it-nl-ro-en-de/bin/valid.de-en.de\n",
      "2022-09-14 13:27:51 | INFO | fairseq.data.data_utils | loaded 1138 examples from: /storage/master-thesis/models/it-nl-ro-en+de-en/tokenizers/it-nl-ro-en-de/bin/valid.de-en.en\n",
      "2022-09-14 13:27:51 | INFO | fairseq.data.multilingual.multilingual_data_manager | /storage/master-thesis/models/it-nl-ro-en+de-en/tokenizers/it-nl-ro-en-de/bin valid de-en 1138 examples\n",
      "2022-09-14 13:27:51 | INFO | fairseq.data.multilingual.multilingual_data_manager | main:en-de src_langtok: 29329; tgt_langtok: 29328\n",
      "2022-09-14 13:27:51 | INFO | fairseq.data.data_utils | loaded 1138 examples from: /storage/master-thesis/models/it-nl-ro-en+de-en/tokenizers/it-nl-ro-en-de/bin/valid.en-de.en\n",
      "2022-09-14 13:27:51 | INFO | fairseq.data.data_utils | loaded 1138 examples from: /storage/master-thesis/models/it-nl-ro-en+de-en/tokenizers/it-nl-ro-en-de/bin/valid.en-de.de\n",
      "2022-09-14 13:27:51 | INFO | fairseq.data.multilingual.multilingual_data_manager | /storage/master-thesis/models/it-nl-ro-en+de-en/tokenizers/it-nl-ro-en-de/bin valid en-de 1138 examples\n",
      "2022-09-14 13:27:52 | INFO | fairseq_cli.train | TransformerModel(\n",
      "  (encoder): TransformerEncoder(\n",
      "    (dropout_module): FairseqDropout()\n",
      "    (embed_tokens): Embedding(29333, 512, padding_idx=1)\n",
      "    (embed_positions): SinusoidalPositionalEmbedding()\n",
      "    (layers): ModuleList(\n",
      "      (0): TransformerEncoderLayer(\n",
      "        (self_attn): MultiheadAttention(\n",
      "          (dropout_module): FairseqDropout()\n",
      "          (k_proj): Linear(in_features=512, out_features=512, bias=True)\n",
      "          (v_proj): Linear(in_features=512, out_features=512, bias=True)\n",
      "          (q_proj): Linear(in_features=512, out_features=512, bias=True)\n",
      "          (out_proj): Linear(in_features=512, out_features=512, bias=True)\n",
      "        )\n",
      "        (self_attn_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)\n",
      "        (dropout_module): FairseqDropout()\n",
      "        (activation_dropout_module): FairseqDropout()\n",
      "        (fc1): Linear(in_features=512, out_features=2048, bias=True)\n",
      "        (fc2): Linear(in_features=2048, out_features=512, bias=True)\n",
      "        (final_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)\n",
      "      )\n",
      "      (1): TransformerEncoderLayer(\n",
      "        (self_attn): MultiheadAttention(\n",
      "          (dropout_module): FairseqDropout()\n",
      "          (k_proj): Linear(in_features=512, out_features=512, bias=True)\n",
      "          (v_proj): Linear(in_features=512, out_features=512, bias=True)\n",
      "          (q_proj): Linear(in_features=512, out_features=512, bias=True)\n",
      "          (out_proj): Linear(in_features=512, out_features=512, bias=True)\n",
      "        )\n",
      "        (self_attn_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)\n",
      "        (dropout_module): FairseqDropout()\n",
      "        (activation_dropout_module): FairseqDropout()\n",
      "        (fc1): Linear(in_features=512, out_features=2048, bias=True)\n",
      "        (fc2): Linear(in_features=2048, out_features=512, bias=True)\n",
      "        (final_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)\n",
      "      )\n",
      "      (2): TransformerEncoderLayer(\n",
      "        (self_attn): MultiheadAttention(\n",
      "          (dropout_module): FairseqDropout()\n",
      "          (k_proj): Linear(in_features=512, out_features=512, bias=True)\n",
      "          (v_proj): Linear(in_features=512, out_features=512, bias=True)\n",
      "          (q_proj): Linear(in_features=512, out_features=512, bias=True)\n",
      "          (out_proj): Linear(in_features=512, out_features=512, bias=True)\n",
      "        )\n",
      "        (self_attn_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)\n",
      "        (dropout_module): FairseqDropout()\n",
      "        (activation_dropout_module): FairseqDropout()\n",
      "        (fc1): Linear(in_features=512, out_features=2048, bias=True)\n",
      "        (fc2): Linear(in_features=2048, out_features=512, bias=True)\n",
      "        (final_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)\n",
      "      )\n",
      "      (3): TransformerEncoderLayer(\n",
      "        (self_attn): MultiheadAttention(\n",
      "          (dropout_module): FairseqDropout()\n",
      "          (k_proj): Linear(in_features=512, out_features=512, bias=True)\n",
      "          (v_proj): Linear(in_features=512, out_features=512, bias=True)\n",
      "          (q_proj): Linear(in_features=512, out_features=512, bias=True)\n",
      "          (out_proj): Linear(in_features=512, out_features=512, bias=True)\n",
      "        )\n",
      "        (self_attn_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)\n",
      "        (dropout_module): FairseqDropout()\n",
      "        (activation_dropout_module): FairseqDropout()\n",
      "        (fc1): Linear(in_features=512, out_features=2048, bias=True)\n",
      "        (fc2): Linear(in_features=2048, out_features=512, bias=True)\n",
      "        (final_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)\n",
      "      )\n",
      "      (4): TransformerEncoderLayer(\n",
      "        (self_attn): MultiheadAttention(\n",
      "          (dropout_module): FairseqDropout()\n",
      "          (k_proj): Linear(in_features=512, out_features=512, bias=True)\n",
      "          (v_proj): Linear(in_features=512, out_features=512, bias=True)\n",
      "          (q_proj): Linear(in_features=512, out_features=512, bias=True)\n",
      "          (out_proj): Linear(in_features=512, out_features=512, bias=True)\n",
      "        )\n",
      "        (self_attn_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)\n",
      "        (dropout_module): FairseqDropout()\n",
      "        (activation_dropout_module): FairseqDropout()\n",
      "        (fc1): Linear(in_features=512, out_features=2048, bias=True)\n",
      "        (fc2): Linear(in_features=2048, out_features=512, bias=True)\n",
      "        (final_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)\n",
      "      )\n",
      "      (5): TransformerEncoderLayer(\n",
      "        (self_attn): MultiheadAttention(\n",
      "          (dropout_module): FairseqDropout()\n",
      "          (k_proj): Linear(in_features=512, out_features=512, bias=True)\n",
      "          (v_proj): Linear(in_features=512, out_features=512, bias=True)\n",
      "          (q_proj): Linear(in_features=512, out_features=512, bias=True)\n",
      "          (out_proj): Linear(in_features=512, out_features=512, bias=True)\n",
      "        )\n",
      "        (self_attn_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)\n",
      "        (dropout_module): FairseqDropout()\n",
      "        (activation_dropout_module): FairseqDropout()\n",
      "        (fc1): Linear(in_features=512, out_features=2048, bias=True)\n",
      "        (fc2): Linear(in_features=2048, out_features=512, bias=True)\n",
      "        (final_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (decoder): TransformerDecoder(\n",
      "    (dropout_module): FairseqDropout()\n",
      "    (embed_tokens): Embedding(29333, 512, padding_idx=1)\n",
      "    (embed_positions): SinusoidalPositionalEmbedding()\n",
      "    (layers): ModuleList(\n",
      "      (0): TransformerDecoderLayer(\n",
      "        (dropout_module): FairseqDropout()\n",
      "        (self_attn): MultiheadAttention(\n",
      "          (dropout_module): FairseqDropout()\n",
      "          (k_proj): Linear(in_features=512, out_features=512, bias=True)\n",
      "          (v_proj): Linear(in_features=512, out_features=512, bias=True)\n",
      "          (q_proj): Linear(in_features=512, out_features=512, bias=True)\n",
      "          (out_proj): Linear(in_features=512, out_features=512, bias=True)\n",
      "        )\n",
      "        (activation_dropout_module): FairseqDropout()\n",
      "        (self_attn_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)\n",
      "        (encoder_attn): MultiheadAttention(\n",
      "          (dropout_module): FairseqDropout()\n",
      "          (k_proj): Linear(in_features=512, out_features=512, bias=True)\n",
      "          (v_proj): Linear(in_features=512, out_features=512, bias=True)\n",
      "          (q_proj): Linear(in_features=512, out_features=512, bias=True)\n",
      "          (out_proj): Linear(in_features=512, out_features=512, bias=True)\n",
      "        )\n",
      "        (encoder_attn_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)\n",
      "        (fc1): Linear(in_features=512, out_features=2048, bias=True)\n",
      "        (fc2): Linear(in_features=2048, out_features=512, bias=True)\n",
      "        (final_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)\n",
      "      )\n",
      "      (1): TransformerDecoderLayer(\n",
      "        (dropout_module): FairseqDropout()\n",
      "        (self_attn): MultiheadAttention(\n",
      "          (dropout_module): FairseqDropout()\n",
      "          (k_proj): Linear(in_features=512, out_features=512, bias=True)\n",
      "          (v_proj): Linear(in_features=512, out_features=512, bias=True)\n",
      "          (q_proj): Linear(in_features=512, out_features=512, bias=True)\n",
      "          (out_proj): Linear(in_features=512, out_features=512, bias=True)\n",
      "        )\n",
      "        (activation_dropout_module): FairseqDropout()\n",
      "        (self_attn_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)\n",
      "        (encoder_attn): MultiheadAttention(\n",
      "          (dropout_module): FairseqDropout()\n",
      "          (k_proj): Linear(in_features=512, out_features=512, bias=True)\n",
      "          (v_proj): Linear(in_features=512, out_features=512, bias=True)\n",
      "          (q_proj): Linear(in_features=512, out_features=512, bias=True)\n",
      "          (out_proj): Linear(in_features=512, out_features=512, bias=True)\n",
      "        )\n",
      "        (encoder_attn_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)\n",
      "        (fc1): Linear(in_features=512, out_features=2048, bias=True)\n",
      "        (fc2): Linear(in_features=2048, out_features=512, bias=True)\n",
      "        (final_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)\n",
      "      )\n",
      "      (2): TransformerDecoderLayer(\n",
      "        (dropout_module): FairseqDropout()\n",
      "        (self_attn): MultiheadAttention(\n",
      "          (dropout_module): FairseqDropout()\n",
      "          (k_proj): Linear(in_features=512, out_features=512, bias=True)\n",
      "          (v_proj): Linear(in_features=512, out_features=512, bias=True)\n",
      "          (q_proj): Linear(in_features=512, out_features=512, bias=True)\n",
      "          (out_proj): Linear(in_features=512, out_features=512, bias=True)\n",
      "        )\n",
      "        (activation_dropout_module): FairseqDropout()\n",
      "        (self_attn_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)\n",
      "        (encoder_attn): MultiheadAttention(\n",
      "          (dropout_module): FairseqDropout()\n",
      "          (k_proj): Linear(in_features=512, out_features=512, bias=True)\n",
      "          (v_proj): Linear(in_features=512, out_features=512, bias=True)\n",
      "          (q_proj): Linear(in_features=512, out_features=512, bias=True)\n",
      "          (out_proj): Linear(in_features=512, out_features=512, bias=True)\n",
      "        )\n",
      "        (encoder_attn_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)\n",
      "        (fc1): Linear(in_features=512, out_features=2048, bias=True)\n",
      "        (fc2): Linear(in_features=2048, out_features=512, bias=True)\n",
      "        (final_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)\n",
      "      )\n",
      "      (3): TransformerDecoderLayer(\n",
      "        (dropout_module): FairseqDropout()\n",
      "        (self_attn): MultiheadAttention(\n",
      "          (dropout_module): FairseqDropout()\n",
      "          (k_proj): Linear(in_features=512, out_features=512, bias=True)\n",
      "          (v_proj): Linear(in_features=512, out_features=512, bias=True)\n",
      "          (q_proj): Linear(in_features=512, out_features=512, bias=True)\n",
      "          (out_proj): Linear(in_features=512, out_features=512, bias=True)\n",
      "        )\n",
      "        (activation_dropout_module): FairseqDropout()\n",
      "        (self_attn_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)\n",
      "        (encoder_attn): MultiheadAttention(\n",
      "          (dropout_module): FairseqDropout()\n",
      "          (k_proj): Linear(in_features=512, out_features=512, bias=True)\n",
      "          (v_proj): Linear(in_features=512, out_features=512, bias=True)\n",
      "          (q_proj): Linear(in_features=512, out_features=512, bias=True)\n",
      "          (out_proj): Linear(in_features=512, out_features=512, bias=True)\n",
      "        )\n",
      "        (encoder_attn_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)\n",
      "        (fc1): Linear(in_features=512, out_features=2048, bias=True)\n",
      "        (fc2): Linear(in_features=2048, out_features=512, bias=True)\n",
      "        (final_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)\n",
      "      )\n",
      "      (4): TransformerDecoderLayer(\n",
      "        (dropout_module): FairseqDropout()\n",
      "        (self_attn): MultiheadAttention(\n",
      "          (dropout_module): FairseqDropout()\n",
      "          (k_proj): Linear(in_features=512, out_features=512, bias=True)\n",
      "          (v_proj): Linear(in_features=512, out_features=512, bias=True)\n",
      "          (q_proj): Linear(in_features=512, out_features=512, bias=True)\n",
      "          (out_proj): Linear(in_features=512, out_features=512, bias=True)\n",
      "        )\n",
      "        (activation_dropout_module): FairseqDropout()\n",
      "        (self_attn_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)\n",
      "        (encoder_attn): MultiheadAttention(\n",
      "          (dropout_module): FairseqDropout()\n",
      "          (k_proj): Linear(in_features=512, out_features=512, bias=True)\n",
      "          (v_proj): Linear(in_features=512, out_features=512, bias=True)\n",
      "          (q_proj): Linear(in_features=512, out_features=512, bias=True)\n",
      "          (out_proj): Linear(in_features=512, out_features=512, bias=True)\n",
      "        )\n",
      "        (encoder_attn_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)\n",
      "        (fc1): Linear(in_features=512, out_features=2048, bias=True)\n",
      "        (fc2): Linear(in_features=2048, out_features=512, bias=True)\n",
      "        (final_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)\n",
      "      )\n",
      "      (5): TransformerDecoderLayer(\n",
      "        (dropout_module): FairseqDropout()\n",
      "        (self_attn): MultiheadAttention(\n",
      "          (dropout_module): FairseqDropout()\n",
      "          (k_proj): Linear(in_features=512, out_features=512, bias=True)\n",
      "          (v_proj): Linear(in_features=512, out_features=512, bias=True)\n",
      "          (q_proj): Linear(in_features=512, out_features=512, bias=True)\n",
      "          (out_proj): Linear(in_features=512, out_features=512, bias=True)\n",
      "        )\n",
      "        (activation_dropout_module): FairseqDropout()\n",
      "        (self_attn_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)\n",
      "        (encoder_attn): MultiheadAttention(\n",
      "          (dropout_module): FairseqDropout()\n",
      "          (k_proj): Linear(in_features=512, out_features=512, bias=True)\n",
      "          (v_proj): Linear(in_features=512, out_features=512, bias=True)\n",
      "          (q_proj): Linear(in_features=512, out_features=512, bias=True)\n",
      "          (out_proj): Linear(in_features=512, out_features=512, bias=True)\n",
      "        )\n",
      "        (encoder_attn_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)\n",
      "        (fc1): Linear(in_features=512, out_features=2048, bias=True)\n",
      "        (fc2): Linear(in_features=2048, out_features=512, bias=True)\n",
      "        (final_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)\n",
      "      )\n",
      "    )\n",
      "    (output_projection): Linear(in_features=512, out_features=29333, bias=False)\n",
      "  )\n",
      ")\n",
      "2022-09-14 13:27:52 | INFO | fairseq_cli.train | task: translation_multi_simple_epoch (TranslationMultiSimpleEpochTask)\n",
      "2022-09-14 13:27:52 | INFO | fairseq_cli.train | model: transformer (TransformerModel)\n",
      "2022-09-14 13:27:52 | INFO | fairseq_cli.train | criterion: label_smoothed_cross_entropy (LabelSmoothedCrossEntropyCriterion)\n",
      "2022-09-14 13:27:52 | INFO | fairseq_cli.train | num. model params: 59156992 (num. trained: 59156992)\n",
      "2022-09-14 13:27:56 | INFO | fairseq.trainer | detected shared parameter: encoder.embed_tokens.weight <- decoder.embed_tokens.weight\n",
      "2022-09-14 13:27:56 | INFO | fairseq.trainer | detected shared parameter: encoder.embed_tokens.weight <- decoder.output_projection.weight\n",
      "2022-09-14 13:27:56 | INFO | fairseq.utils | ***********************CUDA enviroments for all 1 workers***********************\n",
      "2022-09-14 13:27:56 | INFO | fairseq.utils | rank   0: capabilities =  7.5  ; total memory = 7.795 GB ; name = Quadro RTX 4000                         \n",
      "2022-09-14 13:27:56 | INFO | fairseq.utils | ***********************CUDA enviroments for all 1 workers***********************\n",
      "2022-09-14 13:27:56 | INFO | fairseq_cli.train | training on 1 devices (GPUs/TPUs)\n",
      "2022-09-14 13:27:56 | INFO | fairseq_cli.train | max tokens per GPU = 4096 and max sentences per GPU = None\n",
      "2022-09-14 13:27:59 | INFO | fairseq.trainer | loaded checkpoint /storage/master-thesis/models/it-nl-ro-en+de-en/checkpoint_last.pt (epoch 194 @ 0 updates)\n",
      "2022-09-14 13:27:59 | INFO | fairseq.optim.adam | using FusedAdam\n",
      "2022-09-14 13:27:59 | INFO | fairseq.trainer | loading train data for epoch 194\n",
      "2022-09-14 13:27:59 | INFO | fairseq.tasks.translation_multi_simple_epoch | loading data for train epoch=194/None\n",
      "2022-09-14 13:27:59 | INFO | fairseq.tasks.translation_multi_simple_epoch | mem usage: N/A\n",
      "2022-09-14 13:27:59 | INFO | fairseq.data.multilingual.multilingual_data_manager | langtoks settings: {'main': ('src', 'tgt')}\n",
      "2022-09-14 13:27:59 | INFO | fairseq.data.multilingual.multilingual_data_manager | [train] num of shards: {'main:en-it': 1, 'main:it-en': 1, 'main:en-nl': 1, 'main:nl-en': 1, 'main:en-ro': 1, 'main:ro-en': 1, 'main:de-en': 1, 'main:en-de': 1}\n",
      "2022-09-14 13:27:59 | INFO | fairseq.data.multilingual.multilingual_data_manager | main:en-it src_langtok: 29329; tgt_langtok: 29330\n",
      "2022-09-14 13:27:59 | INFO | fairseq.data.data_utils | loaded 145105 examples from: /storage/master-thesis/models/it-nl-ro-en+de-en/tokenizers/it-nl-ro-en-de/bin/train.en-it.en\n",
      "2022-09-14 13:27:59 | INFO | fairseq.data.data_utils | loaded 145105 examples from: /storage/master-thesis/models/it-nl-ro-en+de-en/tokenizers/it-nl-ro-en-de/bin/train.en-it.it\n",
      "2022-09-14 13:27:59 | INFO | fairseq.data.multilingual.multilingual_data_manager | /storage/master-thesis/models/it-nl-ro-en+de-en/tokenizers/it-nl-ro-en-de/bin train en-it 145105 examples\n",
      "2022-09-14 13:27:59 | INFO | fairseq.data.multilingual.multilingual_data_manager | main:it-en src_langtok: 29330; tgt_langtok: 29329\n",
      "2022-09-14 13:27:59 | INFO | fairseq.data.data_utils | loaded 145105 examples from: /storage/master-thesis/models/it-nl-ro-en+de-en/tokenizers/it-nl-ro-en-de/bin/train.it-en.it\n",
      "2022-09-14 13:27:59 | INFO | fairseq.data.data_utils | loaded 145105 examples from: /storage/master-thesis/models/it-nl-ro-en+de-en/tokenizers/it-nl-ro-en-de/bin/train.it-en.en\n",
      "2022-09-14 13:27:59 | INFO | fairseq.data.multilingual.multilingual_data_manager | /storage/master-thesis/models/it-nl-ro-en+de-en/tokenizers/it-nl-ro-en-de/bin train it-en 145105 examples\n",
      "2022-09-14 13:27:59 | INFO | fairseq.data.multilingual.multilingual_data_manager | main:en-nl src_langtok: 29329; tgt_langtok: 29331\n",
      "2022-09-14 13:27:59 | INFO | fairseq.data.data_utils | loaded 145105 examples from: /storage/master-thesis/models/it-nl-ro-en+de-en/tokenizers/it-nl-ro-en-de/bin/train.en-nl.en\n",
      "2022-09-14 13:27:59 | INFO | fairseq.data.data_utils | loaded 145105 examples from: /storage/master-thesis/models/it-nl-ro-en+de-en/tokenizers/it-nl-ro-en-de/bin/train.en-nl.nl\n",
      "2022-09-14 13:27:59 | INFO | fairseq.data.multilingual.multilingual_data_manager | /storage/master-thesis/models/it-nl-ro-en+de-en/tokenizers/it-nl-ro-en-de/bin train en-nl 145105 examples\n",
      "2022-09-14 13:27:59 | INFO | fairseq.data.multilingual.multilingual_data_manager | main:nl-en src_langtok: 29331; tgt_langtok: 29329\n",
      "2022-09-14 13:27:59 | INFO | fairseq.data.data_utils | loaded 145105 examples from: /storage/master-thesis/models/it-nl-ro-en+de-en/tokenizers/it-nl-ro-en-de/bin/train.nl-en.nl\n",
      "2022-09-14 13:27:59 | INFO | fairseq.data.data_utils | loaded 145105 examples from: /storage/master-thesis/models/it-nl-ro-en+de-en/tokenizers/it-nl-ro-en-de/bin/train.nl-en.en\n",
      "2022-09-14 13:27:59 | INFO | fairseq.data.multilingual.multilingual_data_manager | /storage/master-thesis/models/it-nl-ro-en+de-en/tokenizers/it-nl-ro-en-de/bin train nl-en 145105 examples\n",
      "2022-09-14 13:27:59 | INFO | fairseq.data.multilingual.multilingual_data_manager | main:en-ro src_langtok: 29329; tgt_langtok: 29332\n",
      "2022-09-14 13:27:59 | INFO | fairseq.data.data_utils | loaded 145105 examples from: /storage/master-thesis/models/it-nl-ro-en+de-en/tokenizers/it-nl-ro-en-de/bin/train.en-ro.en\n",
      "2022-09-14 13:27:59 | INFO | fairseq.data.data_utils | loaded 145105 examples from: /storage/master-thesis/models/it-nl-ro-en+de-en/tokenizers/it-nl-ro-en-de/bin/train.en-ro.ro\n",
      "2022-09-14 13:27:59 | INFO | fairseq.data.multilingual.multilingual_data_manager | /storage/master-thesis/models/it-nl-ro-en+de-en/tokenizers/it-nl-ro-en-de/bin train en-ro 145105 examples\n",
      "2022-09-14 13:27:59 | INFO | fairseq.data.multilingual.multilingual_data_manager | main:ro-en src_langtok: 29332; tgt_langtok: 29329\n",
      "2022-09-14 13:27:59 | INFO | fairseq.data.data_utils | loaded 145105 examples from: /storage/master-thesis/models/it-nl-ro-en+de-en/tokenizers/it-nl-ro-en-de/bin/train.ro-en.ro\n",
      "2022-09-14 13:27:59 | INFO | fairseq.data.data_utils | loaded 145105 examples from: /storage/master-thesis/models/it-nl-ro-en+de-en/tokenizers/it-nl-ro-en-de/bin/train.ro-en.en\n",
      "2022-09-14 13:27:59 | INFO | fairseq.data.multilingual.multilingual_data_manager | /storage/master-thesis/models/it-nl-ro-en+de-en/tokenizers/it-nl-ro-en-de/bin train ro-en 145105 examples\n",
      "2022-09-14 13:27:59 | INFO | fairseq.data.multilingual.multilingual_data_manager | main:de-en src_langtok: 29328; tgt_langtok: 29329\n",
      "2022-09-14 13:27:59 | INFO | fairseq.data.data_utils | loaded 14510 examples from: /storage/master-thesis/models/it-nl-ro-en+de-en/tokenizers/it-nl-ro-en-de/bin/train.de-en.de\n",
      "2022-09-14 13:27:59 | INFO | fairseq.data.data_utils | loaded 14510 examples from: /storage/master-thesis/models/it-nl-ro-en+de-en/tokenizers/it-nl-ro-en-de/bin/train.de-en.en\n",
      "2022-09-14 13:27:59 | INFO | fairseq.data.multilingual.multilingual_data_manager | /storage/master-thesis/models/it-nl-ro-en+de-en/tokenizers/it-nl-ro-en-de/bin train de-en 14510 examples\n",
      "2022-09-14 13:27:59 | INFO | fairseq.data.multilingual.multilingual_data_manager | main:en-de src_langtok: 29329; tgt_langtok: 29328\n",
      "2022-09-14 13:27:59 | INFO | fairseq.data.data_utils | loaded 14510 examples from: /storage/master-thesis/models/it-nl-ro-en+de-en/tokenizers/it-nl-ro-en-de/bin/train.en-de.en\n",
      "2022-09-14 13:27:59 | INFO | fairseq.data.data_utils | loaded 14510 examples from: /storage/master-thesis/models/it-nl-ro-en+de-en/tokenizers/it-nl-ro-en-de/bin/train.en-de.de\n",
      "2022-09-14 13:27:59 | INFO | fairseq.data.multilingual.multilingual_data_manager | /storage/master-thesis/models/it-nl-ro-en+de-en/tokenizers/it-nl-ro-en-de/bin train en-de 14510 examples\n",
      "2022-09-14 13:27:59 | INFO | fairseq.data.multilingual.multilingual_data_manager | estimated total data sizes of all shards used in sampling ratios: [('main:en-it', 145105), ('main:it-en', 145105), ('main:en-nl', 145105), ('main:nl-en', 145105), ('main:en-ro', 145105), ('main:ro-en', 145105), ('main:de-en', 14510), ('main:en-de', 14510)]. Note that if the data a shard has not been loaded yet, use the max known data size to approximate\n",
      "2022-09-14 13:27:59 | INFO | fairseq.data.multilingual.sampling_method | selected sampler: concat\n",
      "2022-09-14 13:27:59 | WARNING | fairseq.data.multilingual.sampled_multi_epoch_dataset | virtual epoch size 1000000 is greater than virtual dataset size 899650\n",
      "2022-09-14 13:27:59 | INFO | fairseq.data.multilingual.sampled_multi_epoch_dataset | virtual epoch size 899650; virtual dataset size 899650\n",
      "2022-09-14 13:27:59 | INFO | fairseq.data.multilingual.sampled_multi_epoch_dataset | establishing a new set of global virtual indices for epoch=194/shard_epoch=1\n",
      "2022-09-14 13:27:59 | INFO | fairseq.data.multilingual.sampled_multi_dataset | [train] Raw sizes: {'main:en-it': 145105, 'main:it-en': 145105, 'main:en-nl': 145105, 'main:nl-en': 145105, 'main:en-ro': 145105, 'main:ro-en': 145105, 'main:de-en': 14510, 'main:en-de': 14510}; raw total size: 899650\n",
      "2022-09-14 13:27:59 | INFO | fairseq.data.multilingual.sampled_multi_dataset | [train] Resampled sizes: {'main:en-it': 145105, 'main:it-en': 145105, 'main:en-nl': 145105, 'main:nl-en': 145105, 'main:en-ro': 145105, 'main:ro-en': 145105, 'main:de-en': 14510, 'main:en-de': 14510}; resampled total size: 899650\n",
      "2022-09-14 13:27:59 | INFO | fairseq.data.multilingual.sampled_multi_dataset | [train] A concat dataset\n",
      "2022-09-14 13:27:59 | INFO | fairseq.data.multilingual.sampled_multi_dataset | [train] virtual dataset established time: 0:00:00.095908\n",
      "2022-09-14 13:27:59 | INFO | fairseq.tasks.translation_multi_simple_epoch | start batch sampler: mem usage: N/A\n",
      "2022-09-14 13:27:59 | INFO | fairseq.data.multilingual.sampled_multi_dataset | sizes() calling time: 0:00:00.012788\n",
      "2022-09-14 13:28:00 | INFO | fairseq.tasks.translation_multi_simple_epoch | [train] @batch_sampler order indices time: 0:00:00.350875\n",
      "2022-09-14 13:28:00 | INFO | fairseq.tasks.translation_multi_simple_epoch | mem usage: N/A\n",
      "2022-09-14 13:28:00 | INFO | fairseq.tasks.translation_multi_simple_epoch | [train] @batch_sampler filter_by_size time: 0:00:00.017511\n",
      "2022-09-14 13:28:00 | INFO | fairseq.tasks.translation_multi_simple_epoch | mem usage: N/A\n",
      "2022-09-14 13:28:03 | INFO | fairseq.tasks.translation_multi_simple_epoch | [train] @batch_sampler batch_by_size time: 0:00:02.931027\n",
      "2022-09-14 13:28:03 | INFO | fairseq.tasks.translation_multi_simple_epoch | [train] per epoch batch_sampler set-up time: 0:00:03.300562\n",
      "2022-09-14 13:28:03 | INFO | fairseq.tasks.translation_multi_simple_epoch | mem usage: N/A\n",
      "2022-09-14 13:28:03 | INFO | fairseq.tasks.translation_multi_simple_epoch | start batch sampler: mem usage: N/A\n",
      "2022-09-14 13:28:03 | INFO | fairseq.tasks.translation_multi_simple_epoch | [train] @batch_sampler order indices time: 0:00:00.284163\n",
      "2022-09-14 13:28:03 | INFO | fairseq.tasks.translation_multi_simple_epoch | mem usage: N/A\n",
      "2022-09-14 13:28:03 | INFO | fairseq.tasks.translation_multi_simple_epoch | [train] @batch_sampler filter_by_size time: 0:00:00.017642\n",
      "2022-09-14 13:28:03 | INFO | fairseq.tasks.translation_multi_simple_epoch | mem usage: N/A\n",
      "2022-09-14 13:28:06 | INFO | fairseq.tasks.translation_multi_simple_epoch | [train] @batch_sampler batch_by_size time: 0:00:02.908281\n",
      "2022-09-14 13:28:06 | INFO | fairseq.tasks.translation_multi_simple_epoch | [train] per epoch batch_sampler set-up time: 0:00:03.211199\n",
      "2022-09-14 13:28:06 | INFO | fairseq.tasks.translation_multi_simple_epoch | mem usage: N/A\n",
      "epoch 194:   0%|                                       | 0/5920 [00:00<?, ?it/s]2022-09-14 13:28:06 | INFO | fairseq.trainer | begin training epoch 194\n",
      "epoch 194:   0%|1                             | 20/5920 [00:03<15:21,  6.40it/s]2022-09-14 13:28:09 | INFO | fairseq.trainer | NOTE: overflow detected, setting loss scale to: 64.0\n",
      "epoch 194:   4%| | 243/5920 [00:36<14:49,  6.38it/s, loss=3.518, nll_loss=1.839,2022-09-14 13:28:43 | INFO | fairseq.trainer | NOTE: overflow detected, setting loss scale to: 32.0\n",
      "epoch 194:  18%|1| 1081/5920 [02:45<12:08,  6.64it/s, loss=3.532, nll_loss=1.8542022-09-14 13:30:52 | INFO | fairseq.trainer | NOTE: overflow detected, setting loss scale to: 16.0\n",
      "epoch 194:  31%|3| 1808/5920 [04:38<10:39,  6.43it/s, loss=3.573, nll_loss=1.901^C\n",
      "Traceback (most recent call last):                                              \n",
      "  File \"/usr/local/bin/fairseq-train\", line 8, in <module>\n",
      "    sys.exit(cli_main())\n",
      "  File \"/usr/local/lib/python3.6/dist-packages/fairseq_cli/train.py\", line 352, in cli_main\n",
      "    distributed_utils.call_main(args, main)\n",
      "  File \"/usr/local/lib/python3.6/dist-packages/fairseq/distributed_utils.py\", line 301, in call_main\n",
      "    main(args, **kwargs)\n",
      "  File \"/usr/local/lib/python3.6/dist-packages/fairseq_cli/train.py\", line 125, in main\n",
      "    valid_losses, should_stop = train(args, trainer, task, epoch_itr)\n",
      "  File \"/usr/lib/python3.6/contextlib.py\", line 52, in inner\n",
      "    return func(*args, **kwds)\n",
      "  File \"/usr/local/lib/python3.6/dist-packages/fairseq_cli/train.py\", line 208, in train\n",
      "    log_output = trainer.train_step(samples)\n",
      "  File \"/usr/lib/python3.6/contextlib.py\", line 52, in inner\n",
      "    return func(*args, **kwds)\n",
      "  File \"/usr/local/lib/python3.6/dist-packages/fairseq/trainer.py\", line 486, in train_step\n",
      "    ignore_grad=is_dummy_batch,\n",
      "  File \"/usr/local/lib/python3.6/dist-packages/fairseq/tasks/fairseq_task.py\", line 416, in train_step\n",
      "    loss, sample_size, logging_output = criterion(model, sample)\n",
      "  File \"/usr/local/lib/python3.6/dist-packages/torch/nn/modules/module.py\", line 1051, in _call_impl\n",
      "    return forward_call(*input, **kwargs)\n",
      "  File \"/usr/local/lib/python3.6/dist-packages/fairseq/criterions/label_smoothed_cross_entropy.py\", line 69, in forward\n",
      "    net_output = model(**sample[\"net_input\"])\n",
      "  File \"/usr/local/lib/python3.6/dist-packages/torch/nn/modules/module.py\", line 1051, in _call_impl\n",
      "    return forward_call(*input, **kwargs)\n",
      "  File \"/usr/local/lib/python3.6/dist-packages/fairseq/models/transformer.py\", line 270, in forward\n",
      "    src_tokens, src_lengths=src_lengths, return_all_hiddens=return_all_hiddens\n",
      "  File \"/usr/local/lib/python3.6/dist-packages/torch/nn/modules/module.py\", line 1051, in _call_impl\n",
      "    return forward_call(*input, **kwargs)\n",
      "  File \"/usr/local/lib/python3.6/dist-packages/fairseq/models/transformer.py\", line 425, in forward\n",
      "    x = layer(x, encoder_padding_mask)\n",
      "  File \"/usr/local/lib/python3.6/dist-packages/torch/nn/modules/module.py\", line 1051, in _call_impl\n",
      "    return forward_call(*input, **kwargs)\n",
      "  File \"/usr/local/lib/python3.6/dist-packages/fairseq/modules/transformer_layer.py\", line 137, in forward\n",
      "    attn_mask=attn_mask,\n",
      "  File \"/usr/local/lib/python3.6/dist-packages/torch/nn/modules/module.py\", line 1051, in _call_impl\n",
      "    return forward_call(*input, **kwargs)\n",
      "  File \"/usr/local/lib/python3.6/dist-packages/fairseq/modules/multihead_attention.py\", line 186, in forward\n",
      "    v_proj_weight=self.v_proj.weight,\n",
      "  File \"/usr/local/lib/python3.6/dist-packages/torch/nn/functional.py\", line 5084, in multi_head_attention_forward\n",
      "    attn_output = linear(attn_output, out_proj_weight, out_proj_bias)\n",
      "  File \"/usr/local/lib/python3.6/dist-packages/torch/nn/functional.py\", line 1847, in linear\n",
      "    return torch._C._nn.linear(input, weight, bias)\n",
      "KeyboardInterrupt\n"
     ]
    }
   ],
   "source": [
    "! fairseq-train $BIN_DIR \\\n",
    "    --arch=transformer --share-all-embeddings \\\n",
    "    --task translation_multi_simple_epoch --lang-pairs en-it,it-en,en-nl,nl-en,en-ro,ro-en,de-en,en-de \\\n",
    "    --optimizer adam --adam-betas '(0.9, 0.98)' --clip-norm 0.0 \\\n",
    "    --lr 5e-5 --lr-scheduler inverse_sqrt --warmup-updates 4000 \\\n",
    "    --dropout 0.3 --weight-decay 0.0001 \\\n",
    "    --criterion label_smoothed_cross_entropy --label-smoothing 0.1 \\\n",
    "    --max-tokens 4096 \\\n",
    "    --restore-file $MODEL_DIR/checkpoint_last.pt \\\n",
    "    --save-dir $MODEL_DIR/ \\\n",
    "    --keep-last-epochs 2 \\\n",
    "    --reset-optimizer \\\n",
    "    --encoder-langtok \"src\" \\\n",
    "    --decoder-langtok \\\n",
    "    --fp16 \\\n",
    "    --max-epoch 200\n",
    "    #--update-freq 2\n",
    "    #original lr: 5e-4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/storage/master-thesis/models/quy-es+es-en\n"
     ]
    }
   ],
   "source": [
    "! echo $MODEL_DIR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/storage/master-thesis/models/quy-es+es-en\n"
     ]
    }
   ],
   "source": [
    "cd /storage/master-thesis/models/quy-es+es-en"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "! rm checkpoint108.pt\n",
    "! rm checkpoint109.pt\n",
    "! rm checkpoint_best.pt\n",
    "! rm checkpoint_last.pt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "! rm dict.en.txt\n",
    "! rm dict.es.txt\n",
    "! rm dict.quy.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.5K\t/notebooks/CITATION.cff\n",
      "5.5K\t/notebooks/CODE_OF_CONDUCT.md\n",
      "15K\t/notebooks/CONTRIBUTING.md\n",
      "19K\t/notebooks/ISSUES.md\n",
      "12K\t/notebooks/LICENSE\n",
      "512\t/notebooks/MANIFEST.in\n",
      "3.5K\t/notebooks/Makefile\n",
      "41K\t/notebooks/README.md\n",
      "41K\t/notebooks/README_zh-hans.md\n",
      "42K\t/notebooks/README_zh-hant.md\n",
      "12K\t/notebooks/docker\n",
      "4.6M\t/notebooks/docs\n",
      "5.0M\t/notebooks/examples\n",
      "8.5K\t/notebooks/hubconf.py\n",
      "7.8G\t/notebooks/master-thesis\n",
      "1.5K\t/notebooks/model_cards\n",
      "9.5K\t/notebooks/notebooks\n",
      "512\t/notebooks/pyproject.toml\n",
      "64K\t/notebooks/scripts\n",
      "1.0K\t/notebooks/setup.cfg\n",
      "13K\t/notebooks/setup.py\n",
      "13M\t/notebooks/src\n",
      "731K\t/notebooks/templates\n",
      "4.5K\t/notebooks/test quy-es -> es-en model.ipynb\n",
      "6.8M\t/notebooks/tests\n",
      "147K\t/notebooks/train es-en model.ipynb\n",
      "158K\t/notebooks/train quy-es + es-en model.ipynb\n",
      "160K\t/notebooks/utils\n",
      "3.5K\t/notebooks/valohai.yaml\n",
      "7.9G\ttotal\n"
     ]
    }
   ],
   "source": [
    "! du -shc /notebooks/*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "512\t/notebooks/master-thesis/Untitled.ipynb\n",
      "362M\t/notebooks/master-thesis/corpora\n",
      "7.5G\t/notebooks/master-thesis/models\n",
      "7.8G\ttotal\n"
     ]
    }
   ],
   "source": [
    "! du -shc /notebooks/master-thesis/*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.6G\t/notebooks/master-thesis/models/es-en\n",
      "802M\t/notebooks/master-thesis/models/quy-es\n",
      "5.2G\t/notebooks/master-thesis/models/quy-es+es-en\n",
      "7.5G\ttotal\n"
     ]
    }
   ],
   "source": [
    "! du -shc /notebooks/master-thesis/models/*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19M\t/apex\n",
      "5.0M\t/bin\n",
      "4.0K\t/boot\n",
      "24K\t/content\n",
      "^C\n"
     ]
    }
   ],
   "source": [
    "! du -shc /*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " CITATION.cff         \u001b[0m\u001b[01;34mdocker\u001b[0m/          setup.py\n",
      " CODE_OF_CONDUCT.md   \u001b[01;34mdocs\u001b[0m/            \u001b[01;34msrc\u001b[0m/\n",
      " CONTRIBUTING.md      \u001b[01;34mexamples\u001b[0m/        \u001b[01;34mtemplates\u001b[0m/\n",
      " ISSUES.md            hubconf.py      'test quy-es -> es-en model.ipynb'\n",
      " LICENSE              \u001b[01;34mmaster-thesis\u001b[0m/   \u001b[01;34mtests\u001b[0m/\n",
      " MANIFEST.in          \u001b[01;34mmodel_cards\u001b[0m/    'train es-en model.ipynb'\n",
      " Makefile             \u001b[01;34mnotebooks\u001b[0m/      'train quy-es + es-en model.ipynb'\n",
      " README.md            pyproject.toml   \u001b[01;34mutils\u001b[0m/\n",
      " README_zh-hans.md    \u001b[01;34mscripts\u001b[0m/         valohai.yaml\n",
      " README_zh-hant.md    setup.cfg\n"
     ]
    }
   ],
   "source": [
    "ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/storage/master-thesis\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
