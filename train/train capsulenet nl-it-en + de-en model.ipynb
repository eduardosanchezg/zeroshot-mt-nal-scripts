{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "gradient": {
     "editing": false
    }
   },
   "source": [
    "## ENVIRONMENT VARIABLES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "gradient": {
     "editing": false
    }
   },
   "outputs": [],
   "source": [
    "EN_ES_CORPUS_DIR = \"/notebooks/master-thesis/corpora/tatoeba-challenge/en-es/\" #NOT MODIFIED YET"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "gradient": {
     "editing": false
    }
   },
   "outputs": [],
   "source": [
    "QUY_ES_CORPUS_DIR = \"/notebooks/master-thesis/corpora/americasnlp2021/data/quechua-spanish\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "gradient": {
     "editing": false
    }
   },
   "outputs": [],
   "source": [
    "tokenizer_path = \"/storage/master-thesis/models/caps_quy-es+es-en/tokenizers/quy-es-en/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "gradient": {
     "editing": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "env: TOKENIZER_PATH=/storage/master-thesis/models/caps_quy-es+es-en/tokenizers/quy-es-en\n"
     ]
    }
   ],
   "source": [
    "%env TOKENIZER_PATH = /storage/master-thesis/models/caps_quy-es+es-en/tokenizers/quy-es-en"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "gradient": {
     "editing": false
    }
   },
   "outputs": [],
   "source": [
    "tokenized_path_es_en = \"/storage/master-thesis/models/caps_quy-es+es-en/tokenizers/quy-es-en/es-en/\"\n",
    "tokenized_path_quy_es = \"/storage/master-thesis/models/caps_quy-es+es-en/tokenizers/quy-es-en/quy-es/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "gradient": {
     "editing": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "env: TOKENIZED_PATH_ES_EN=/storage/master-thesis/models/caps_quy-es+es-en/tokenizers/quy-es-en/es-en\n",
      "env: TOKENIZED_PATH_QUY_ES=/storage/master-thesis/models/caps_quy-es+es-en/tokenizers/quy-es-en/quy-es\n"
     ]
    }
   ],
   "source": [
    "%env TOKENIZED_PATH_ES_EN = /storage/master-thesis/models/caps_quy-es+es-en/tokenizers/quy-es-en/es-en\n",
    "%env TOKENIZED_PATH_QUY_ES = /storage/master-thesis/models/caps_quy-es+es-en/tokenizers/quy-es-en/quy-es"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "gradient": {
     "editing": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "env: BIN_DIR=/storage/master-thesis/models/caps_quy-es+es-en/tokenizers/quy-es-en/bin\n"
     ]
    }
   ],
   "source": [
    "%env BIN_DIR = /storage/master-thesis/models/caps_quy-es+es-en/tokenizers/quy-es-en/bin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "gradient": {
     "editing": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "env: MODEL_DIR=/storage/master-thesis/models/caps_quy-es+es-en\n"
     ]
    }
   ],
   "source": [
    "%env MODEL_DIR = /storage/master-thesis/models/caps_quy-es+es-en"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "gradient": {
     "editing": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "env: CODE_STORAGE=/storage/code/\n"
     ]
    }
   ],
   "source": [
    "%env CODE_STORAGE = /storage/code/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "gradient": {
     "editing": false
    }
   },
   "outputs": [],
   "source": [
    "quy_es_en_tokenizer_dir = \"/storage/master-thesis/models/caps_quy-es+es-en/tokenizers/quy-es-en/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "gradient": {
     "editing": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "locale: Cannot set LC_CTYPE to default locale: No such file or directory\n",
      "locale: Cannot set LC_MESSAGES to default locale: No such file or directory\n",
      "locale: Cannot set LC_ALL to default locale: No such file or directory\n",
      "LANG=en_US.UTF-8\n",
      "LANGUAGE=\n",
      "LC_CTYPE=\"en_US.UTF-8\"\n",
      "LC_NUMERIC=\"en_US.UTF-8\"\n",
      "LC_TIME=\"en_US.UTF-8\"\n",
      "LC_COLLATE=\"en_US.UTF-8\"\n",
      "LC_MONETARY=\"en_US.UTF-8\"\n",
      "LC_MESSAGES=\"en_US.UTF-8\"\n",
      "LC_PAPER=\"en_US.UTF-8\"\n",
      "LC_NAME=\"en_US.UTF-8\"\n",
      "LC_ADDRESS=\"en_US.UTF-8\"\n",
      "LC_TELEPHONE=\"en_US.UTF-8\"\n",
      "LC_MEASUREMENT=\"en_US.UTF-8\"\n",
      "LC_IDENTIFICATION=\"en_US.UTF-8\"\n",
      "LC_ALL=en_US.UTF-8\n"
     ]
    }
   ],
   "source": [
    "! locale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "gradient": {
     "editing": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/bin/sh: 1: update-locale: not found\n",
      "env: LANG=en_US.UTF-8\n",
      "env: LC_CTYPE=en_US.UTF-8\n",
      "env: LC_ALL=en_US.UTF-8\n"
     ]
    }
   ],
   "source": [
    "! update-locale LANG=en_US.UTF-8 LANGUAGE=en.UTF-8\n",
    "\n",
    "%env LANG=en_US.UTF-8\n",
    "%env LC_CTYPE=en_US.UTF-8\n",
    "%env LC_ALL=en_US.UTF-8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "gradient": {}
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cat: /etc/rc.conf: No such file or directory\n"
     ]
    }
   ],
   "source": [
    "! cat /etc/rc.conf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "gradient": {}
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: tokenizers==0.10.3 in /usr/local/lib/python3.6/dist-packages (0.10.3)\n",
      "\u001b[33mWARNING: You are using pip version 20.2.4; however, version 21.3 is available.\n",
      "You should consider upgrading via the '/usr/bin/python3 -m pip install --upgrade pip' command.\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install tokenizers==0.10.3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "gradient": {}
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: fairseq in /usr/local/lib/python3.6/dist-packages (0.10.2)\n",
      "Requirement already satisfied: sacrebleu>=1.4.12 in /usr/local/lib/python3.6/dist-packages (from fairseq) (2.0.0)\n",
      "Requirement already satisfied: cffi in /usr/local/lib/python3.6/dist-packages (from fairseq) (1.14.3)\n",
      "Requirement already satisfied: torch in /usr/local/lib/python3.6/dist-packages (from fairseq) (1.6.0)\n",
      "Requirement already satisfied: cython in /usr/local/lib/python3.6/dist-packages (from fairseq) (0.29.24)\n",
      "Requirement already satisfied: tqdm in /usr/local/lib/python3.6/dist-packages (from fairseq) (4.51.0)\n",
      "Requirement already satisfied: regex in /usr/local/lib/python3.6/dist-packages (from fairseq) (2020.11.13)\n",
      "Requirement already satisfied: dataclasses in /usr/local/lib/python3.6/dist-packages (from fairseq) (0.8)\n",
      "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from fairseq) (1.18.5)\n",
      "Requirement already satisfied: hydra-core in /usr/local/lib/python3.6/dist-packages (from fairseq) (1.1.1)\n",
      "Requirement already satisfied: colorama in /usr/local/lib/python3.6/dist-packages (from sacrebleu>=1.4.12->fairseq) (0.4.4)\n",
      "Requirement already satisfied: portalocker in /usr/local/lib/python3.6/dist-packages (from sacrebleu>=1.4.12->fairseq) (2.3.2)\n",
      "Requirement already satisfied: tabulate>=0.8.9 in /usr/local/lib/python3.6/dist-packages (from sacrebleu>=1.4.12->fairseq) (0.8.9)\n",
      "Requirement already satisfied: pycparser in /usr/local/lib/python3.6/dist-packages (from cffi->fairseq) (2.20)\n",
      "Requirement already satisfied: future in /usr/local/lib/python3.6/dist-packages (from torch->fairseq) (0.18.2)\n",
      "Requirement already satisfied: antlr4-python3-runtime==4.8 in /usr/local/lib/python3.6/dist-packages (from hydra-core->fairseq) (4.8)\n",
      "Requirement already satisfied: importlib-resources; python_version < \"3.9\" in /usr/local/lib/python3.6/dist-packages (from hydra-core->fairseq) (5.2.2)\n",
      "Requirement already satisfied: omegaconf==2.1.* in /usr/local/lib/python3.6/dist-packages (from hydra-core->fairseq) (2.1.1)\n",
      "Requirement already satisfied: zipp>=3.1.0; python_version < \"3.10\" in /usr/local/lib/python3.6/dist-packages (from importlib-resources; python_version < \"3.9\"->hydra-core->fairseq) (3.4.0)\n",
      "Requirement already satisfied: PyYAML>=5.1.0 in /usr/local/lib/python3.6/dist-packages (from omegaconf==2.1.*->hydra-core->fairseq) (5.4.1)\n",
      "\u001b[33mWARNING: You are using pip version 20.2.4; however, version 21.3 is available.\n",
      "You should consider upgrading via the '/usr/bin/python3 -m pip install --upgrade pip' command.\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install fairseq"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Converting tatoeba format to standard format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "gradient": {}
   },
   "outputs": [],
   "source": [
    "import csv\n",
    "\n",
    "with open(EN_ES_CORPUS_DIR + \"original/valid.txt\", encoding='utf8') as f:\n",
    "    es = open(EN_ES_CORPUS_DIR + \"dev.es\", 'w', encoding='utf8')\n",
    "    en = open(EN_ES_CORPUS_DIR + \"dev.en\", 'w', encoding='utf8')\n",
    "    for line in csv.reader(f, delimiter=\"\\t\"):\n",
    "        es.write(line[3] + \"\\n\")\n",
    "        en.write(line[2] + \"\\n\")\n",
    "    en.close()\n",
    "    es.close()\n",
    "    \n",
    "with open(EN_ES_CORPUS_DIR + \"original/dev.txt\", encoding='utf8') as f:\n",
    "    es = open(EN_ES_CORPUS_DIR + \"train.es\", 'w', encoding='utf8')\n",
    "    en = open(EN_ES_CORPUS_DIR + \"train.en\", 'w', encoding='utf8')\n",
    "    for line in csv.reader(f, delimiter=\"\\t\"):\n",
    "        if \"\\n\" in line[2] or \"\\n\" in line[3]:\n",
    "            continue\n",
    "        if len(line) != 4:\n",
    "            continue\n",
    "            \n",
    "        es.write(line[3] + \"\\n\")\n",
    "        en.write(line[2] + \"\\n\")\n",
    "        \n",
    "    en.close()\n",
    "    es.close()\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tokenizing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "gradient": {}
   },
   "outputs": [],
   "source": [
    "from tokenizers import Tokenizer\n",
    "from tokenizers.models import WordPiece\n",
    "\n",
    "en_es_quy_tokenizer = Tokenizer(WordPiece(unk_token=\"[UNK]\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "gradient": {}
   },
   "outputs": [],
   "source": [
    "from tokenizers.trainers import WordPieceTrainer\n",
    "\n",
    "en_es_quy_trainer = WordPieceTrainer(special_tokens=[\"[UNK]\", \"[CLS]\", \"[SEP]\", \"[PAD]\", \"[MASK]\"], vocab_size=30000, show_progress=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "gradient": {}
   },
   "outputs": [],
   "source": [
    "from tokenizers.pre_tokenizers import Whitespace\n",
    "\n",
    "en_es_quy_tokenizer.pre_tokenizer = Whitespace()\n",
    "\n",
    "en_files = [f\"/notebooks/master-thesis/corpora/tatoeba-challenge/en-es/{split}.en\" for split in [\"dev\", \"train\"]]\n",
    "es_files = [f\"/notebooks/master-thesis/corpora/tatoeba-challenge/en-es/{split}.es\" for split in [\"dev\", \"train\"]]\n",
    "quy_files = [f\"/notebooks/master-thesis/corpora/americasnlp2021/data/quechua-spanish/{split}.quy\" for split in [\"dev\", \"dict\", \"train\"]]\n",
    "es2_files = [f\"/notebooks/master-thesis/corpora/americasnlp2021/data/quechua-spanish/{split}.es\" for split in [\"dev\", \"dict\", \"train\"]]\n",
    "\n",
    "files = en_files + es_files + es2_files + quy_files\n",
    "en_es_quy_tokenizer.train(files= files, trainer=en_es_quy_trainer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "gradient": {}
   },
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "\n",
    "\n",
    "def tokenize_files(tokenizer, files, extension, output_path):\n",
    "    for file in files:\n",
    "        print(f\"Reading file {file}\")\n",
    "        with open(file, encoding='utf8') as f:\n",
    "          lines = f.readlines()\n",
    "          tokenized_lines = tokenizer.encode_batch(lines)\n",
    "          tokenized_name = Path(file).stem\n",
    "          tokenized_name = output_path + tokenized_name + \".\" + extension\n",
    "          print(tokenized_name)\n",
    "          with open(tokenized_name, 'w', encoding='utf8') as wf:\n",
    "\n",
    "            wf.writelines([\" \".join(t.tokens) + \"\\n\" for t in tokenized_lines])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "! mkdir bin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "gradient": {}
   },
   "outputs": [],
   "source": [
    "en_es_quy_tokenizer.save(tokenizer_path + \"quy-es-en-tokenizer.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "gradient": {}
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<tokenizers.Tokenizer object at 0x7ff74401a510>\n"
     ]
    }
   ],
   "source": [
    "print(en_es_quy_tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "gradient": {}
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['we', 'hold', 'this', 'truth', 'to', 'be', 'self', 'evid', '##ent', 'that', 'everyone', 'is', 'created', 'equal', '?']\n"
     ]
    }
   ],
   "source": [
    "tok = en_es_quy_tokenizer.encode(\"we hold this truth to be self evident that everyone is created equal?\")\n",
    "print(tok.tokens)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "gradient": {}
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading file /notebooks/master-thesis/corpora/tatoeba-challenge/en-es/dev.en\n",
      "/storage/master-thesis/models/caps_quy-es+es-en/tokenizers/quy-es-en/es-en/dev.en\n",
      "Reading file /notebooks/master-thesis/corpora/tatoeba-challenge/en-es/train.en\n",
      "/storage/master-thesis/models/caps_quy-es+es-en/tokenizers/quy-es-en/es-en/train.en\n",
      "Reading file /notebooks/master-thesis/corpora/tatoeba-challenge/en-es/dev.es\n",
      "/storage/master-thesis/models/caps_quy-es+es-en/tokenizers/quy-es-en/es-en/dev.es\n",
      "Reading file /notebooks/master-thesis/corpora/tatoeba-challenge/en-es/train.es\n",
      "/storage/master-thesis/models/caps_quy-es+es-en/tokenizers/quy-es-en/es-en/train.es\n",
      "Reading file /notebooks/master-thesis/corpora/americasnlp2021/data/quechua-spanish/dev.quy\n",
      "/storage/master-thesis/models/caps_quy-es+es-en/tokenizers/quy-es-en/quy-es/dev.quy\n",
      "Reading file /notebooks/master-thesis/corpora/americasnlp2021/data/quechua-spanish/dict.quy\n",
      "/storage/master-thesis/models/caps_quy-es+es-en/tokenizers/quy-es-en/quy-es/dict.quy\n",
      "Reading file /notebooks/master-thesis/corpora/americasnlp2021/data/quechua-spanish/train.quy\n",
      "/storage/master-thesis/models/caps_quy-es+es-en/tokenizers/quy-es-en/quy-es/train.quy\n",
      "Reading file /notebooks/master-thesis/corpora/americasnlp2021/data/quechua-spanish/dev.es\n",
      "/storage/master-thesis/models/caps_quy-es+es-en/tokenizers/quy-es-en/quy-es/dev.es\n",
      "Reading file /notebooks/master-thesis/corpora/americasnlp2021/data/quechua-spanish/dict.es\n",
      "/storage/master-thesis/models/caps_quy-es+es-en/tokenizers/quy-es-en/quy-es/dict.es\n",
      "Reading file /notebooks/master-thesis/corpora/americasnlp2021/data/quechua-spanish/train.es\n",
      "/storage/master-thesis/models/caps_quy-es+es-en/tokenizers/quy-es-en/quy-es/train.es\n"
     ]
    }
   ],
   "source": [
    "tokenize_files(en_es_quy_tokenizer, en_files, \"en\", tokenized_path_es_en)\n",
    "tokenize_files(en_es_quy_tokenizer, es_files, \"es\", tokenized_path_es_en)\n",
    "\n",
    "tokenize_files(en_es_quy_tokenizer, quy_files, \"quy\", tokenized_path_quy_es)\n",
    "tokenize_files(en_es_quy_tokenizer, es2_files, \"es\", tokenized_path_quy_es)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "gradient": {}
   },
   "outputs": [],
   "source": [
    "! cat /storage/master-thesis/models/quy-es+es-en/tokenizers/quy-es-en/es-en/dev.en\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Binarizing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "gradient": {}
   },
   "outputs": [],
   "source": [
    "### Removing previous dict files\n",
    "! rm $BIN_DIR/dict.quy.txt\n",
    "! rm $BIN_DIR/dict.es.txt\n",
    "! rm $BIN_DIR/dict.en.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "gradient": {}
   },
   "outputs": [],
   "source": [
    "## Concatenating all training data\n",
    "! cat $TOKENIZED_PATH_QUY_ES/train.quy $TOKENIZED_PATH_QUY_ES/train.es $TOKENIZED_PATH_ES_EN/train.es $TOKENIZED_PATH_ES_EN/train.en > $BIN_DIR/train.all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "gradient": {}
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[0m\u001b[01;34mfairseq\u001b[0m/  \u001b[01;34mfairseq-dynamic-routing-plugin\u001b[0m/\n"
     ]
    }
   ],
   "source": [
    "ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "gradient": {}
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-10-15 17:16:11 | INFO | fairseq_cli.preprocess | Namespace(align_suffix=None, alignfile=None, all_gather_list_size=16384, bf16=False, bpe=None, checkpoint_shard_count=1, checkpoint_suffix='', cpu=False, criterion='cross_entropy', dataset_impl='mmap', destdir='/storage/master-thesis/models/caps_quy-es+es-en/tokenizers/quy-es-en/bin', empty_cache_freq=0, fp16=False, fp16_init_scale=128, fp16_no_flatten_grads=False, fp16_scale_tolerance=0.0, fp16_scale_window=None, joined_dictionary=False, log_format=None, log_interval=100, lr_scheduler='fixed', memory_efficient_bf16=False, memory_efficient_fp16=False, min_loss_scale=0.0001, model_parallel_size=1, no_progress_bar=False, nwordssrc=-1, nwordstgt=-1, only_source=True, optimizer=None, padding_factor=8, profile=False, quantization_config_path=None, scoring='bleu', seed=1, source_lang='all', srcdict=None, target_lang=None, task='translation', tensorboard_logdir=None, testpref=None, tgtdict=None, threshold_loss_scale=None, thresholdsrc=0, thresholdtgt=0, tokenizer=None, tpu=False, trainpref='/storage/master-thesis/models/caps_quy-es+es-en/tokenizers/quy-es-en/bin/train', user_dir=None, validpref=None, workers=20)\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/bin/fairseq-preprocess\", line 8, in <module>\n",
      "    sys.exit(cli_main())\n",
      "  File \"/usr/local/lib/python3.6/dist-packages/fairseq_cli/preprocess.py\", line 394, in cli_main\n",
      "    main(args)\n",
      "  File \"/usr/local/lib/python3.6/dist-packages/fairseq_cli/preprocess.py\", line 74, in main\n",
      "    raise FileExistsError(dict_path(args.source_lang))\n",
      "FileExistsError: /storage/master-thesis/models/caps_quy-es+es-en/tokenizers/quy-es-en/bin/dict.all.txt\n"
     ]
    }
   ],
   "source": [
    "! fairseq-preprocess --source-lang all \\\n",
    "    --trainpref $BIN_DIR/train \\\n",
    "    --destdir $BIN_DIR \\\n",
    "    --workers 20 \\\n",
    "    --only-source"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "gradient": {}
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-10-15 17:16:15 | INFO | fairseq_cli.preprocess | Namespace(align_suffix=None, alignfile=None, all_gather_list_size=16384, bf16=False, bpe=None, checkpoint_shard_count=1, checkpoint_suffix='', cpu=False, criterion='cross_entropy', dataset_impl='mmap', destdir='/storage/master-thesis/models/caps_quy-es+es-en/tokenizers/quy-es-en/bin', empty_cache_freq=0, fp16=False, fp16_init_scale=128, fp16_no_flatten_grads=False, fp16_scale_tolerance=0.0, fp16_scale_window=None, joined_dictionary=False, log_format=None, log_interval=100, lr_scheduler='fixed', memory_efficient_bf16=False, memory_efficient_fp16=False, min_loss_scale=0.0001, model_parallel_size=1, no_progress_bar=False, nwordssrc=-1, nwordstgt=-1, only_source=False, optimizer=None, padding_factor=8, profile=False, quantization_config_path=None, scoring='bleu', seed=1, source_lang='quy', srcdict='/storage/master-thesis/models/caps_quy-es+es-en/tokenizers/quy-es-en/bin/dict.all.txt', target_lang='es', task='translation', tensorboard_logdir=None, testpref=None, tgtdict='/storage/master-thesis/models/caps_quy-es+es-en/tokenizers/quy-es-en/bin/dict.all.txt', threshold_loss_scale=None, thresholdsrc=0, thresholdtgt=0, tokenizer=None, tpu=False, trainpref='/storage/master-thesis/models/caps_quy-es+es-en/tokenizers/quy-es-en/quy-es/train', user_dir=None, validpref='/storage/master-thesis/models/caps_quy-es+es-en/tokenizers/quy-es-en/quy-es/dev', workers=20)\n",
      "2021-10-15 17:16:15 | INFO | fairseq_cli.preprocess | [quy] Dictionary: 28976 types\n",
      "2021-10-15 17:16:19 | INFO | fairseq_cli.preprocess | [quy] /storage/master-thesis/models/caps_quy-es+es-en/tokenizers/quy-es-en/quy-es/train.quy: 125008 sents, 1922581 tokens, 0.0% replaced by <unk>\n",
      "2021-10-15 17:16:19 | INFO | fairseq_cli.preprocess | [quy] Dictionary: 28976 types\n",
      "2021-10-15 17:16:19 | INFO | fairseq_cli.preprocess | [quy] /storage/master-thesis/models/caps_quy-es+es-en/tokenizers/quy-es-en/quy-es/dev.quy: 996 sents, 14488 tokens, 0.456% replaced by <unk>\n",
      "2021-10-15 17:16:19 | INFO | fairseq_cli.preprocess | [es] Dictionary: 28976 types\n",
      "2021-10-15 17:16:24 | INFO | fairseq_cli.preprocess | [es] /storage/master-thesis/models/caps_quy-es+es-en/tokenizers/quy-es-en/quy-es/train.es: 125008 sents, 2452298 tokens, 0.0% replaced by <unk>\n",
      "2021-10-15 17:16:24 | INFO | fairseq_cli.preprocess | [es] Dictionary: 28976 types\n",
      "2021-10-15 17:16:25 | INFO | fairseq_cli.preprocess | [es] /storage/master-thesis/models/caps_quy-es+es-en/tokenizers/quy-es-en/quy-es/dev.es: 996 sents, 15303 tokens, 0.242% replaced by <unk>\n",
      "2021-10-15 17:16:25 | INFO | fairseq_cli.preprocess | Wrote preprocessed data to /storage/master-thesis/models/caps_quy-es+es-en/tokenizers/quy-es-en/bin\n"
     ]
    }
   ],
   "source": [
    "! fairseq-preprocess --source-lang quy --target-lang es \\\n",
    "    --trainpref $TOKENIZED_PATH_QUY_ES/train --validpref $TOKENIZED_PATH_QUY_ES/dev \\\n",
    "    --destdir $BIN_DIR \\\n",
    "    --srcdict $BIN_DIR/dict.all.txt \\\n",
    "    --tgtdict $BIN_DIR/dict.all.txt \\\n",
    "    --workers 20"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reusing es dict from quy-es preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "gradient": {}
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-10-15 17:16:26 | INFO | fairseq_cli.preprocess | Namespace(align_suffix=None, alignfile=None, all_gather_list_size=16384, bf16=False, bpe=None, checkpoint_shard_count=1, checkpoint_suffix='', cpu=False, criterion='cross_entropy', dataset_impl='mmap', destdir='/storage/master-thesis/models/caps_quy-es+es-en/tokenizers/quy-es-en/bin', empty_cache_freq=0, fp16=False, fp16_init_scale=128, fp16_no_flatten_grads=False, fp16_scale_tolerance=0.0, fp16_scale_window=None, joined_dictionary=False, log_format=None, log_interval=100, lr_scheduler='fixed', memory_efficient_bf16=False, memory_efficient_fp16=False, min_loss_scale=0.0001, model_parallel_size=1, no_progress_bar=False, nwordssrc=-1, nwordstgt=-1, only_source=False, optimizer=None, padding_factor=8, profile=False, quantization_config_path=None, scoring='bleu', seed=1, source_lang='es', srcdict='/storage/master-thesis/models/caps_quy-es+es-en/tokenizers/quy-es-en/bin/dict.all.txt', target_lang='en', task='translation', tensorboard_logdir=None, testpref=None, tgtdict='/storage/master-thesis/models/caps_quy-es+es-en/tokenizers/quy-es-en/bin/dict.all.txt', threshold_loss_scale=None, thresholdsrc=0, thresholdtgt=0, tokenizer=None, tpu=False, trainpref='/storage/master-thesis/models/caps_quy-es+es-en/tokenizers/quy-es-en/es-en/train', user_dir=None, validpref='/storage/master-thesis/models/caps_quy-es+es-en/tokenizers/quy-es-en/es-en/dev', workers=20)\n",
      "2021-10-15 17:16:27 | INFO | fairseq_cli.preprocess | [es] Dictionary: 28976 types\n",
      "2021-10-15 17:16:31 | INFO | fairseq_cli.preprocess | [es] /storage/master-thesis/models/caps_quy-es+es-en/tokenizers/quy-es-en/es-en/train.es: 197297 sents, 1894674 tokens, 0.0% replaced by <unk>\n",
      "2021-10-15 17:16:31 | INFO | fairseq_cli.preprocess | [es] Dictionary: 28976 types\n",
      "2021-10-15 17:16:32 | INFO | fairseq_cli.preprocess | [es] /storage/master-thesis/models/caps_quy-es+es-en/tokenizers/quy-es-en/es-en/dev.es: 4643 sents, 51839 tokens, 0.0405% replaced by <unk>\n",
      "2021-10-15 17:16:32 | INFO | fairseq_cli.preprocess | [en] Dictionary: 28976 types\n",
      "2021-10-15 17:16:36 | INFO | fairseq_cli.preprocess | [en] /storage/master-thesis/models/caps_quy-es+es-en/tokenizers/quy-es-en/es-en/train.en: 197297 sents, 1994137 tokens, 0.0% replaced by <unk>\n",
      "2021-10-15 17:16:36 | INFO | fairseq_cli.preprocess | [en] Dictionary: 28976 types\n",
      "2021-10-15 17:16:36 | INFO | fairseq_cli.preprocess | [en] /storage/master-thesis/models/caps_quy-es+es-en/tokenizers/quy-es-en/es-en/dev.en: 4643 sents, 54416 tokens, 0.0404% replaced by <unk>\n",
      "2021-10-15 17:16:36 | INFO | fairseq_cli.preprocess | Wrote preprocessed data to /storage/master-thesis/models/caps_quy-es+es-en/tokenizers/quy-es-en/bin\n"
     ]
    }
   ],
   "source": [
    "! fairseq-preprocess --source-lang es --target-lang en \\\n",
    "    --trainpref $TOKENIZED_PATH_ES_EN/train --validpref $TOKENIZED_PATH_ES_EN/dev \\\n",
    "    --destdir $BIN_DIR \\\n",
    "    --srcdict $BIN_DIR/dict.all.txt \\\n",
    "    --tgtdict $BIN_DIR/dict.all.txt \\\n",
    "    --workers 20"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[0m\u001b[01;34mfairseq\u001b[0m/\n"
     ]
    }
   ],
   "source": [
    "ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: torch==1.9.1 in /usr/local/lib/python3.6/dist-packages (1.9.1)\n",
      "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.6/dist-packages (from torch==1.9.1) (3.10.0.2)\n",
      "Requirement already satisfied: dataclasses; python_version < \"3.7\" in /usr/local/lib/python3.6/dist-packages (from torch==1.9.1) (0.8)\n",
      "\u001b[33mWARNING: You are using pip version 20.2.4; however, version 21.3 is available.\n",
      "You should consider upgrading via the '/usr/bin/python3 -m pip install --upgrade pip' command.\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install torch==1.9.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "gradient": {}
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/storage/code\n"
     ]
    }
   ],
   "source": [
    "cd /storage/code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cloning into 'apex'...\n",
      "remote: Enumerating objects: 8453, done.\u001b[K\n",
      "remote: Counting objects: 100% (540/540), done.\u001b[K\n",
      "remote: Compressing objects: 100% (336/336), done.\u001b[K\n",
      "remote: Total 8453 (delta 307), reused 355 (delta 192), pack-reused 7913\u001b[K\n",
      "Receiving objects: 100% (8453/8453), 14.38 MiB | 2.87 MiB/s, done.\n",
      "Resolving deltas: 100% (5706/5706), done.\n",
      "/usr/local/lib/python3.6/dist-packages/pip/_internal/commands/install.py:235: UserWarning: Disabling all use of wheels due to the use of --build-option / --global-option / --install-option.\n",
      "  cmdoptions.check_install_build_global(options)\n",
      "Using pip 20.2.4 from /usr/local/lib/python3.6/dist-packages/pip (python 3.6)\n",
      "Non-user install because site-packages writeable\n",
      "Created temporary directory: /tmp/pip-ephem-wheel-cache-rkfd15ek\n",
      "Created temporary directory: /tmp/pip-req-tracker-i_7liawc\n",
      "Initialized build tracking at /tmp/pip-req-tracker-i_7liawc\n",
      "Created build tracker: /tmp/pip-req-tracker-i_7liawc\n",
      "Entered build tracker: /tmp/pip-req-tracker-i_7liawc\n",
      "Created temporary directory: /tmp/pip-install-9lheeini\n",
      "\u001b[31mERROR: Directory './' is not installable. Neither 'setup.py' nor 'pyproject.toml' found.\u001b[0m\n",
      "Exception information:\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/lib/python3.6/dist-packages/pip/_internal/cli/base_command.py\", line 228, in _main\n",
      "    status = self.run(options, args)\n",
      "  File \"/usr/local/lib/python3.6/dist-packages/pip/_internal/cli/req_command.py\", line 182, in wrapper\n",
      "    return func(self, options, args)\n",
      "  File \"/usr/local/lib/python3.6/dist-packages/pip/_internal/commands/install.py\", line 294, in run\n",
      "    reqs = self.get_requirements(args, options, finder, session)\n",
      "  File \"/usr/local/lib/python3.6/dist-packages/pip/_internal/cli/req_command.py\", line 319, in get_requirements\n",
      "    user_supplied=True,\n",
      "  File \"/usr/local/lib/python3.6/dist-packages/pip/_internal/req/constructors.py\", line 409, in install_req_from_line\n",
      "    parts = parse_req_from_line(name, line_source)\n",
      "  File \"/usr/local/lib/python3.6/dist-packages/pip/_internal/req/constructors.py\", line 326, in parse_req_from_line\n",
      "    url = _get_url_from_path(p, name)\n",
      "  File \"/usr/local/lib/python3.6/dist-packages/pip/_internal/req/constructors.py\", line 282, in _get_url_from_path\n",
      "    \"nor 'pyproject.toml' found.\".format(**locals())\n",
      "pip._internal.exceptions.InstallationError: Directory './' is not installable. Neither 'setup.py' nor 'pyproject.toml' found.\n",
      "Removed build tracker: '/tmp/pip-req-tracker-i_7liawc'\n"
     ]
    }
   ],
   "source": [
    "! git clone https://github.com/NVIDIA/apex\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/storage/code/apex\n"
     ]
    }
   ],
   "source": [
    "cd apex"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install -v --disable-pip-version-check --no-cache-dir --global-option=\"--cpp_ext\" --global-option=\"--cuda_ext\" ./"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mWARNING: Skipping apex as it is not installed.\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip uninstall apex"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/storage/code\n"
     ]
    }
   ],
   "source": [
    "cd ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "rm -r ~/.nv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gc\n",
    "import torch\n",
    "\n",
    "gc.collect()\n",
    "\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting torchsummary\n",
      "  Downloading torchsummary-1.5.1-py3-none-any.whl (2.8 kB)\n",
      "Installing collected packages: torchsummary\n",
      "Successfully installed torchsummary-1.5.1\n",
      "\u001b[33mWARNING: You are using pip version 20.2.4; however, version 21.3.1 is available.\n",
      "You should consider upgrading via the '/usr/bin/python3 -m pip install --upgrade pip' command.\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install torchsummary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch.autograd.anomaly_mode.set_detect_anomaly at 0x7f793894f710>"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.autograd.set_detect_anomaly(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/storage/master-thesis/models/caps_quy-es+es-en\n"
     ]
    }
   ],
   "source": [
    "cd /storage/master-thesis/models/caps_quy-es+es-en"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "rm ./*.pt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "rm ./*.pt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/storage/code\n"
     ]
    }
   ],
   "source": [
    "cd /storage/code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "rm -r fairseq-dynamic-routing-plugin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "gradient": {}
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cloning into 'fairseq-dynamic-routing-plugin'...\n",
      "remote: Enumerating objects: 32858, done.\u001b[K\n",
      "remote: Counting objects: 100% (3968/3968), done.\u001b[K\n",
      "remote: Compressing objects: 100% (1861/1861), done.\u001b[K\n",
      "remote: Total 32858 (delta 2587), reused 3327 (delta 2018), pack-reused 28890\u001b[K\n",
      "Receiving objects: 100% (32858/32858), 13.77 MiB | 6.47 MiB/s, done.\n",
      "Resolving deltas: 100% (24294/24294), done.\n",
      "Checking out files: 100% (1166/1166), done.\n"
     ]
    }
   ],
   "source": [
    "! git clone https://github.com/eduardosanchezg/fairseq-dynamic-routing-plugin.git"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "gradient": {}
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-12-14 08:22:21 | INFO | fairseq_cli.train | Namespace(activation_dropout=0.0, activation_fn='relu', adam_betas='(0.9, 0.98)', adam_eps=1e-08, adaptive_input=False, adaptive_softmax_cutoff=None, adaptive_softmax_dropout=0, all_gather_list_size=16384, arch='capsnet_transformer', attention_dropout=0.0, batch_size=None, batch_size_valid=None, best_checkpoint_metric='loss', bf16=False, bpe=None, broadcast_buffers=False, bucket_cap_mb=25, checkpoint_shard_count=1, checkpoint_suffix='', clip_norm=0.0, cpu=False, criterion='label_smoothed_cross_entropy', cross_self_attention=False, curriculum=0, data='/storage/master-thesis/models/caps_quy-es+es-en/tokenizers/quy-es-en/bin', data_buffer_size=10, dataset_impl=None, ddp_backend='c10d', decoder_attention_heads=8, decoder_embed_dim=512, decoder_embed_path=None, decoder_ffn_embed_dim=2048, decoder_input_dim=512, decoder_langtok=True, decoder_layerdrop=0, decoder_layers=6, decoder_layers_to_keep=None, decoder_learned_pos=False, decoder_normalize_before=False, decoder_output_dim=512, device_id=0, disable_validation=False, distributed_backend='nccl', distributed_init_method=None, distributed_no_spawn=False, distributed_num_procs=1, distributed_port=-1, distributed_rank=0, distributed_world_size=1, distributed_wrapper='DDP', dropout=0.3, empty_cache_freq=0, enable_lang_ids=False, enable_reservsed_directions_shared_datasets=False, encoder_attention_heads=8, encoder_embed_dim=512, encoder_embed_path=None, encoder_ffn_embed_dim=2048, encoder_langtok='src', encoder_layerdrop=0, encoder_layers=6, encoder_layers_to_keep=None, encoder_learned_pos=False, encoder_normalize_before=False, extra_data=None, extra_lang_pairs=None, fast_stat_sync=False, find_unused_parameters=False, finetune_from_model=None, fix_batches_to_gpus=False, fixed_dictionary=None, fixed_validation_seed=None, fp16=False, fp16_init_scale=128, fp16_no_flatten_grads=False, fp16_scale_tolerance=0.0, fp16_scale_window=None, gen_subset='test', ignore_prefix_size=0, keep_best_checkpoints=-1, keep_inference_langtok=False, keep_interval_updates=-1, keep_last_epochs=2, label_smoothing=0.1, lang_dict=None, lang_pairs='quy-es,es-en', lang_tok_replacing_bos_eos=False, lang_tok_style='multilingual', langs=None, langtoks=None, langtoks_specs=['main'], layernorm_embedding=False, left_pad_source='True', left_pad_target='False', load_alignments=False, localsgd_frequency=3, log_format=None, log_interval=100, lr=[0.0005], lr_scheduler='inverse_sqrt', max_epoch=0, max_source_positions=1024, max_target_positions=1024, max_tokens=4096, max_tokens_valid=4096, max_update=0, maximize_best_checkpoint_metric=False, memory_efficient_bf16=False, memory_efficient_fp16=False, min_loss_scale=0.0001, min_lr=-1.0, model_parallel_size=1, no_cross_attention=False, no_epoch_checkpoints=False, no_last_checkpoints=False, no_progress_bar=False, no_save=False, no_save_optimizer_state=False, no_scale_embedding=False, no_seed_provided=False, no_token_positional_embeddings=False, nprocs_per_node=1, num_shards=1, num_workers=1, optimizer='adam', optimizer_overrides='{}', patience=-1, pipeline_balance=None, pipeline_checkpoint='never', pipeline_chunks=0, pipeline_decoder_balance=None, pipeline_decoder_devices=None, pipeline_devices=None, pipeline_encoder_balance=None, pipeline_encoder_devices=None, pipeline_model_parallel=False, profile=False, quant_noise_pq=0, quant_noise_pq_block_size=8, quant_noise_scalar=0, quantization_config_path=None, report_accuracy=False, required_batch_size_multiple=8, required_seq_len_multiple=1, reset_dataloader=False, reset_lr_scheduler=False, reset_meters=False, reset_optimizer=True, restore_file='/storage/master-thesis/models/caps_quy-es+es-en/checkpoint_last.pt', sampling_method='concat', sampling_temperature=1.5, sampling_weights=None, sampling_weights_from_file=None, save_dir='/storage/master-thesis/models/caps_quy-es+es-en/', save_interval=1, save_interval_updates=0, scoring='bleu', seed=1, sentence_avg=False, shard_id=0, share_all_embeddings=True, share_decoder_input_output_embed=False, skip_invalid_size_inputs_valid_test=False, slowmo_algorithm='LocalSGD', slowmo_momentum=None, source_lang=None, stop_time_hours=0, target_lang=None, task='translation_multi_simple_epoch', tensorboard_logdir=None, threshold_loss_scale=None, tie_adaptive_weights=False, tokenizer=None, tpu=False, train_subset='train', truncate_source=False, update_freq=[1], upsample_primary=1, use_bmuf=False, use_old_adam=False, user_dir='/storage/code//fairseq-dynamic-routing-plugin/examples/dynamic_routing/dynamic_routing_src/', valid_subset='valid', validate_after_updates=0, validate_interval=1, validate_interval_updates=0, virtual_data_size=None, virtual_epoch_size=1000000, warmup_init_lr=-1, warmup_updates=4000, weight_decay=0.0001, zero_sharding='none')\n",
      "2021-12-14 08:22:21 | WARNING | fairseq.data.multilingual.multilingual_data_manager | External language dictionary is not provided; use lang-pairs to infer the set of supported languages. The language ordering is not stable which might cause misalignment in pretraining and finetuning.\n",
      "2021-12-14 08:22:21 | INFO | fairseq.data.multilingual.multilingual_data_manager | inferred language list: ['en', 'es', 'quy']\n",
      "2021-12-14 08:22:21 | INFO | fairseq.data.multilingual.multilingual_data_manager | [en] dictionary: 28979 types\n",
      "2021-12-14 08:22:21 | INFO | fairseq.data.multilingual.multilingual_data_manager | [es] dictionary: 28979 types\n",
      "2021-12-14 08:22:21 | INFO | fairseq.data.multilingual.multilingual_data_manager | [quy] dictionary: 28979 types\n",
      "2021-12-14 08:22:21 | INFO | fairseq.tasks.translation_multi_simple_epoch | loading data for valid epoch=1/None\n",
      "2021-12-14 08:22:21 | INFO | fairseq.tasks.translation_multi_simple_epoch | mem usage: N/A\n",
      "2021-12-14 08:22:21 | INFO | fairseq.data.multilingual.multilingual_data_manager | langtoks settings: {'main': ('src', 'tgt')}\n",
      "2021-12-14 08:22:21 | INFO | fairseq.data.multilingual.multilingual_data_manager | [valid] num of shards: {'main:quy-es': 1, 'main:es-en': 1}\n",
      "2021-12-14 08:22:21 | INFO | fairseq.data.multilingual.multilingual_data_manager | main:quy-es src_langtok: 28978; tgt_langtok: 28977\n",
      "2021-12-14 08:22:21 | INFO | fairseq.data.data_utils | loaded 996 examples from: /storage/master-thesis/models/caps_quy-es+es-en/tokenizers/quy-es-en/bin/valid.quy-es.quy\n",
      "2021-12-14 08:22:21 | INFO | fairseq.data.data_utils | loaded 996 examples from: /storage/master-thesis/models/caps_quy-es+es-en/tokenizers/quy-es-en/bin/valid.quy-es.es\n",
      "2021-12-14 08:22:21 | INFO | fairseq.data.multilingual.multilingual_data_manager | /storage/master-thesis/models/caps_quy-es+es-en/tokenizers/quy-es-en/bin valid quy-es 996 examples\n",
      "2021-12-14 08:22:21 | INFO | fairseq.data.multilingual.multilingual_data_manager | main:es-en src_langtok: 28977; tgt_langtok: 28976\n",
      "2021-12-14 08:22:21 | INFO | fairseq.data.data_utils | loaded 4643 examples from: /storage/master-thesis/models/caps_quy-es+es-en/tokenizers/quy-es-en/bin/valid.es-en.es\n",
      "2021-12-14 08:22:21 | INFO | fairseq.data.data_utils | loaded 4643 examples from: /storage/master-thesis/models/caps_quy-es+es-en/tokenizers/quy-es-en/bin/valid.es-en.en\n",
      "2021-12-14 08:22:21 | INFO | fairseq.data.multilingual.multilingual_data_manager | /storage/master-thesis/models/caps_quy-es+es-en/tokenizers/quy-es-en/bin valid es-en 4643 examples\n",
      "INITIALIZED!!!!!!\n",
      "2021-12-14 08:22:22 | INFO | fairseq_cli.train | CapsNetTransformerModel(\n",
      "  (encoder): CapsNetTransformerEncoder(\n",
      "    (dropout_module): FairseqDropout()\n",
      "    (embed_tokens): Embedding(28979, 512, padding_idx=1)\n",
      "    (embed_positions): SinusoidalPositionalEmbedding()\n",
      "    (layers): ModuleList(\n",
      "      (0): CapsNetTransformerEncoderLayer(\n",
      "        (self_attn): MultiheadAttention(\n",
      "          (dropout_module): FairseqDropout()\n",
      "          (k_proj): Linear(in_features=512, out_features=512, bias=True)\n",
      "          (v_proj): Linear(in_features=512, out_features=512, bias=True)\n",
      "          (q_proj): Linear(in_features=512, out_features=512, bias=True)\n",
      "          (out_proj): Linear(in_features=512, out_features=512, bias=True)\n",
      "        )\n",
      "        (self_attn_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)\n",
      "        (dropout_module): FairseqDropout()\n",
      "        (activation_dropout_module): FairseqDropout()\n",
      "        (fc1): Linear(in_features=512, out_features=2048, bias=True)\n",
      "        (fc2): Linear(in_features=2048, out_features=512, bias=True)\n",
      "        (final_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)\n",
      "        (self_attn_layer): ModifiedMultiheadAttention(\n",
      "          (dropout_module): FairseqDropout()\n",
      "          (k_proj): Linear(in_features=512, out_features=512, bias=True)\n",
      "          (v_proj): Linear(in_features=512, out_features=512, bias=True)\n",
      "          (q_proj): Linear(in_features=512, out_features=512, bias=True)\n",
      "          (out_proj): Linear(in_features=512, out_features=512, bias=True)\n",
      "        )\n",
      "      )\n",
      "      (1): TransformerEncoderLayer(\n",
      "        (self_attn): MultiheadAttention(\n",
      "          (dropout_module): FairseqDropout()\n",
      "          (k_proj): Linear(in_features=512, out_features=512, bias=True)\n",
      "          (v_proj): Linear(in_features=512, out_features=512, bias=True)\n",
      "          (q_proj): Linear(in_features=512, out_features=512, bias=True)\n",
      "          (out_proj): Linear(in_features=512, out_features=512, bias=True)\n",
      "        )\n",
      "        (self_attn_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)\n",
      "        (dropout_module): FairseqDropout()\n",
      "        (activation_dropout_module): FairseqDropout()\n",
      "        (fc1): Linear(in_features=512, out_features=2048, bias=True)\n",
      "        (fc2): Linear(in_features=2048, out_features=512, bias=True)\n",
      "        (final_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)\n",
      "      )\n",
      "      (2): TransformerEncoderLayer(\n",
      "        (self_attn): MultiheadAttention(\n",
      "          (dropout_module): FairseqDropout()\n",
      "          (k_proj): Linear(in_features=512, out_features=512, bias=True)\n",
      "          (v_proj): Linear(in_features=512, out_features=512, bias=True)\n",
      "          (q_proj): Linear(in_features=512, out_features=512, bias=True)\n",
      "          (out_proj): Linear(in_features=512, out_features=512, bias=True)\n",
      "        )\n",
      "        (self_attn_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)\n",
      "        (dropout_module): FairseqDropout()\n",
      "        (activation_dropout_module): FairseqDropout()\n",
      "        (fc1): Linear(in_features=512, out_features=2048, bias=True)\n",
      "        (fc2): Linear(in_features=2048, out_features=512, bias=True)\n",
      "        (final_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)\n",
      "      )\n",
      "      (3): TransformerEncoderLayer(\n",
      "        (self_attn): MultiheadAttention(\n",
      "          (dropout_module): FairseqDropout()\n",
      "          (k_proj): Linear(in_features=512, out_features=512, bias=True)\n",
      "          (v_proj): Linear(in_features=512, out_features=512, bias=True)\n",
      "          (q_proj): Linear(in_features=512, out_features=512, bias=True)\n",
      "          (out_proj): Linear(in_features=512, out_features=512, bias=True)\n",
      "        )\n",
      "        (self_attn_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)\n",
      "        (dropout_module): FairseqDropout()\n",
      "        (activation_dropout_module): FairseqDropout()\n",
      "        (fc1): Linear(in_features=512, out_features=2048, bias=True)\n",
      "        (fc2): Linear(in_features=2048, out_features=512, bias=True)\n",
      "        (final_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)\n",
      "      )\n",
      "      (4): TransformerEncoderLayer(\n",
      "        (self_attn): MultiheadAttention(\n",
      "          (dropout_module): FairseqDropout()\n",
      "          (k_proj): Linear(in_features=512, out_features=512, bias=True)\n",
      "          (v_proj): Linear(in_features=512, out_features=512, bias=True)\n",
      "          (q_proj): Linear(in_features=512, out_features=512, bias=True)\n",
      "          (out_proj): Linear(in_features=512, out_features=512, bias=True)\n",
      "        )\n",
      "        (self_attn_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)\n",
      "        (dropout_module): FairseqDropout()\n",
      "        (activation_dropout_module): FairseqDropout()\n",
      "        (fc1): Linear(in_features=512, out_features=2048, bias=True)\n",
      "        (fc2): Linear(in_features=2048, out_features=512, bias=True)\n",
      "        (final_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)\n",
      "      )\n",
      "      (5): TransformerEncoderLayer(\n",
      "        (self_attn): MultiheadAttention(\n",
      "          (dropout_module): FairseqDropout()\n",
      "          (k_proj): Linear(in_features=512, out_features=512, bias=True)\n",
      "          (v_proj): Linear(in_features=512, out_features=512, bias=True)\n",
      "          (q_proj): Linear(in_features=512, out_features=512, bias=True)\n",
      "          (out_proj): Linear(in_features=512, out_features=512, bias=True)\n",
      "        )\n",
      "        (self_attn_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)\n",
      "        (dropout_module): FairseqDropout()\n",
      "        (activation_dropout_module): FairseqDropout()\n",
      "        (fc1): Linear(in_features=512, out_features=2048, bias=True)\n",
      "        (fc2): Linear(in_features=2048, out_features=512, bias=True)\n",
      "        (final_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (decoder): TransformerDecoder(\n",
      "    (dropout_module): FairseqDropout()\n",
      "    (embed_tokens): Embedding(28979, 512, padding_idx=1)\n",
      "    (embed_positions): SinusoidalPositionalEmbedding()\n",
      "    (layers): ModuleList(\n",
      "      (0): TransformerDecoderLayer(\n",
      "        (dropout_module): FairseqDropout()\n",
      "        (self_attn): MultiheadAttention(\n",
      "          (dropout_module): FairseqDropout()\n",
      "          (k_proj): Linear(in_features=512, out_features=512, bias=True)\n",
      "          (v_proj): Linear(in_features=512, out_features=512, bias=True)\n",
      "          (q_proj): Linear(in_features=512, out_features=512, bias=True)\n",
      "          (out_proj): Linear(in_features=512, out_features=512, bias=True)\n",
      "        )\n",
      "        (activation_dropout_module): FairseqDropout()\n",
      "        (self_attn_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)\n",
      "        (encoder_attn): MultiheadAttention(\n",
      "          (dropout_module): FairseqDropout()\n",
      "          (k_proj): Linear(in_features=512, out_features=512, bias=True)\n",
      "          (v_proj): Linear(in_features=512, out_features=512, bias=True)\n",
      "          (q_proj): Linear(in_features=512, out_features=512, bias=True)\n",
      "          (out_proj): Linear(in_features=512, out_features=512, bias=True)\n",
      "        )\n",
      "        (encoder_attn_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)\n",
      "        (fc1): Linear(in_features=512, out_features=2048, bias=True)\n",
      "        (fc2): Linear(in_features=2048, out_features=512, bias=True)\n",
      "        (final_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)\n",
      "      )\n",
      "      (1): TransformerDecoderLayer(\n",
      "        (dropout_module): FairseqDropout()\n",
      "        (self_attn): MultiheadAttention(\n",
      "          (dropout_module): FairseqDropout()\n",
      "          (k_proj): Linear(in_features=512, out_features=512, bias=True)\n",
      "          (v_proj): Linear(in_features=512, out_features=512, bias=True)\n",
      "          (q_proj): Linear(in_features=512, out_features=512, bias=True)\n",
      "          (out_proj): Linear(in_features=512, out_features=512, bias=True)\n",
      "        )\n",
      "        (activation_dropout_module): FairseqDropout()\n",
      "        (self_attn_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)\n",
      "        (encoder_attn): MultiheadAttention(\n",
      "          (dropout_module): FairseqDropout()\n",
      "          (k_proj): Linear(in_features=512, out_features=512, bias=True)\n",
      "          (v_proj): Linear(in_features=512, out_features=512, bias=True)\n",
      "          (q_proj): Linear(in_features=512, out_features=512, bias=True)\n",
      "          (out_proj): Linear(in_features=512, out_features=512, bias=True)\n",
      "        )\n",
      "        (encoder_attn_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)\n",
      "        (fc1): Linear(in_features=512, out_features=2048, bias=True)\n",
      "        (fc2): Linear(in_features=2048, out_features=512, bias=True)\n",
      "        (final_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)\n",
      "      )\n",
      "      (2): TransformerDecoderLayer(\n",
      "        (dropout_module): FairseqDropout()\n",
      "        (self_attn): MultiheadAttention(\n",
      "          (dropout_module): FairseqDropout()\n",
      "          (k_proj): Linear(in_features=512, out_features=512, bias=True)\n",
      "          (v_proj): Linear(in_features=512, out_features=512, bias=True)\n",
      "          (q_proj): Linear(in_features=512, out_features=512, bias=True)\n",
      "          (out_proj): Linear(in_features=512, out_features=512, bias=True)\n",
      "        )\n",
      "        (activation_dropout_module): FairseqDropout()\n",
      "        (self_attn_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)\n",
      "        (encoder_attn): MultiheadAttention(\n",
      "          (dropout_module): FairseqDropout()\n",
      "          (k_proj): Linear(in_features=512, out_features=512, bias=True)\n",
      "          (v_proj): Linear(in_features=512, out_features=512, bias=True)\n",
      "          (q_proj): Linear(in_features=512, out_features=512, bias=True)\n",
      "          (out_proj): Linear(in_features=512, out_features=512, bias=True)\n",
      "        )\n",
      "        (encoder_attn_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)\n",
      "        (fc1): Linear(in_features=512, out_features=2048, bias=True)\n",
      "        (fc2): Linear(in_features=2048, out_features=512, bias=True)\n",
      "        (final_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)\n",
      "      )\n",
      "      (3): TransformerDecoderLayer(\n",
      "        (dropout_module): FairseqDropout()\n",
      "        (self_attn): MultiheadAttention(\n",
      "          (dropout_module): FairseqDropout()\n",
      "          (k_proj): Linear(in_features=512, out_features=512, bias=True)\n",
      "          (v_proj): Linear(in_features=512, out_features=512, bias=True)\n",
      "          (q_proj): Linear(in_features=512, out_features=512, bias=True)\n",
      "          (out_proj): Linear(in_features=512, out_features=512, bias=True)\n",
      "        )\n",
      "        (activation_dropout_module): FairseqDropout()\n",
      "        (self_attn_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)\n",
      "        (encoder_attn): MultiheadAttention(\n",
      "          (dropout_module): FairseqDropout()\n",
      "          (k_proj): Linear(in_features=512, out_features=512, bias=True)\n",
      "          (v_proj): Linear(in_features=512, out_features=512, bias=True)\n",
      "          (q_proj): Linear(in_features=512, out_features=512, bias=True)\n",
      "          (out_proj): Linear(in_features=512, out_features=512, bias=True)\n",
      "        )\n",
      "        (encoder_attn_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)\n",
      "        (fc1): Linear(in_features=512, out_features=2048, bias=True)\n",
      "        (fc2): Linear(in_features=2048, out_features=512, bias=True)\n",
      "        (final_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)\n",
      "      )\n",
      "      (4): TransformerDecoderLayer(\n",
      "        (dropout_module): FairseqDropout()\n",
      "        (self_attn): MultiheadAttention(\n",
      "          (dropout_module): FairseqDropout()\n",
      "          (k_proj): Linear(in_features=512, out_features=512, bias=True)\n",
      "          (v_proj): Linear(in_features=512, out_features=512, bias=True)\n",
      "          (q_proj): Linear(in_features=512, out_features=512, bias=True)\n",
      "          (out_proj): Linear(in_features=512, out_features=512, bias=True)\n",
      "        )\n",
      "        (activation_dropout_module): FairseqDropout()\n",
      "        (self_attn_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)\n",
      "        (encoder_attn): MultiheadAttention(\n",
      "          (dropout_module): FairseqDropout()\n",
      "          (k_proj): Linear(in_features=512, out_features=512, bias=True)\n",
      "          (v_proj): Linear(in_features=512, out_features=512, bias=True)\n",
      "          (q_proj): Linear(in_features=512, out_features=512, bias=True)\n",
      "          (out_proj): Linear(in_features=512, out_features=512, bias=True)\n",
      "        )\n",
      "        (encoder_attn_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)\n",
      "        (fc1): Linear(in_features=512, out_features=2048, bias=True)\n",
      "        (fc2): Linear(in_features=2048, out_features=512, bias=True)\n",
      "        (final_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)\n",
      "      )\n",
      "      (5): TransformerDecoderLayer(\n",
      "        (dropout_module): FairseqDropout()\n",
      "        (self_attn): MultiheadAttention(\n",
      "          (dropout_module): FairseqDropout()\n",
      "          (k_proj): Linear(in_features=512, out_features=512, bias=True)\n",
      "          (v_proj): Linear(in_features=512, out_features=512, bias=True)\n",
      "          (q_proj): Linear(in_features=512, out_features=512, bias=True)\n",
      "          (out_proj): Linear(in_features=512, out_features=512, bias=True)\n",
      "        )\n",
      "        (activation_dropout_module): FairseqDropout()\n",
      "        (self_attn_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)\n",
      "        (encoder_attn): MultiheadAttention(\n",
      "          (dropout_module): FairseqDropout()\n",
      "          (k_proj): Linear(in_features=512, out_features=512, bias=True)\n",
      "          (v_proj): Linear(in_features=512, out_features=512, bias=True)\n",
      "          (q_proj): Linear(in_features=512, out_features=512, bias=True)\n",
      "          (out_proj): Linear(in_features=512, out_features=512, bias=True)\n",
      "        )\n",
      "        (encoder_attn_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)\n",
      "        (fc1): Linear(in_features=512, out_features=2048, bias=True)\n",
      "        (fc2): Linear(in_features=2048, out_features=512, bias=True)\n",
      "        (final_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)\n",
      "      )\n",
      "    )\n",
      "    (output_projection): Linear(in_features=512, out_features=28979, bias=False)\n",
      "  )\n",
      ")\n",
      "2021-12-14 08:22:22 | INFO | fairseq_cli.train | task: translation_multi_simple_epoch (TranslationMultiSimpleEpochTask)\n",
      "2021-12-14 08:22:22 | INFO | fairseq_cli.train | model: capsnet_transformer (CapsNetTransformerModel)\n",
      "2021-12-14 08:22:22 | INFO | fairseq_cli.train | criterion: label_smoothed_cross_entropy (LabelSmoothedCrossEntropyCriterion)\n",
      "2021-12-14 08:22:22 | INFO | fairseq_cli.train | num. model params: 60288512 (num. trained: 60288512)\n",
      "2021-12-14 08:22:27 | INFO | fairseq.trainer | detected shared parameter: encoder.embed_tokens.weight <- decoder.embed_tokens.weight\n",
      "2021-12-14 08:22:27 | INFO | fairseq.trainer | detected shared parameter: encoder.embed_tokens.weight <- decoder.output_projection.weight\n",
      "2021-12-14 08:22:27 | INFO | fairseq.trainer | detected shared parameter: encoder.layers.0.dynamic_routing_weights <- encoder.layers.0.self_attn_layer.dynamic_routing_weights\n",
      "2021-12-14 08:22:27 | INFO | fairseq.utils | ***********************CUDA enviroments for all 1 workers***********************\n",
      "2021-12-14 08:22:27 | INFO | fairseq.utils | rank   0: capabilities =  7.5  ; total memory = 7.795 GB ; name = Quadro RTX 4000                         \n",
      "2021-12-14 08:22:27 | INFO | fairseq.utils | ***********************CUDA enviroments for all 1 workers***********************\n",
      "2021-12-14 08:22:27 | INFO | fairseq_cli.train | training on 1 devices (GPUs/TPUs)\n",
      "2021-12-14 08:22:27 | INFO | fairseq_cli.train | max tokens per GPU = 4096 and max sentences per GPU = None\n",
      "2021-12-14 08:23:03 | INFO | fairseq.trainer | loaded checkpoint /storage/master-thesis/models/caps_quy-es+es-en/checkpoint_last.pt (epoch 201 @ 0 updates)\n",
      "2021-12-14 08:23:03 | INFO | fairseq.trainer | NOTE: your device may support faster training with --fp16\n",
      "2021-12-14 08:23:03 | INFO | fairseq.optim.adam | using FusedAdam\n",
      "2021-12-14 08:23:03 | INFO | fairseq.trainer | loading train data for epoch 201\n",
      "2021-12-14 08:23:03 | INFO | fairseq.tasks.translation_multi_simple_epoch | loading data for train epoch=201/None\n",
      "2021-12-14 08:23:03 | INFO | fairseq.tasks.translation_multi_simple_epoch | mem usage: N/A\n",
      "2021-12-14 08:23:03 | INFO | fairseq.data.multilingual.multilingual_data_manager | langtoks settings: {'main': ('src', 'tgt')}\n",
      "2021-12-14 08:23:03 | INFO | fairseq.data.multilingual.multilingual_data_manager | [train] num of shards: {'main:quy-es': 1, 'main:es-en': 1}\n",
      "2021-12-14 08:23:03 | INFO | fairseq.data.multilingual.multilingual_data_manager | main:quy-es src_langtok: 28978; tgt_langtok: 28977\n",
      "2021-12-14 08:23:04 | INFO | fairseq.data.data_utils | loaded 125008 examples from: /storage/master-thesis/models/caps_quy-es+es-en/tokenizers/quy-es-en/bin/train.quy-es.quy\n",
      "2021-12-14 08:23:04 | INFO | fairseq.data.data_utils | loaded 125008 examples from: /storage/master-thesis/models/caps_quy-es+es-en/tokenizers/quy-es-en/bin/train.quy-es.es\n",
      "2021-12-14 08:23:04 | INFO | fairseq.data.multilingual.multilingual_data_manager | /storage/master-thesis/models/caps_quy-es+es-en/tokenizers/quy-es-en/bin train quy-es 125008 examples\n",
      "2021-12-14 08:23:04 | INFO | fairseq.data.multilingual.multilingual_data_manager | main:es-en src_langtok: 28977; tgt_langtok: 28976\n",
      "2021-12-14 08:23:04 | INFO | fairseq.data.data_utils | loaded 197297 examples from: /storage/master-thesis/models/caps_quy-es+es-en/tokenizers/quy-es-en/bin/train.es-en.es\n",
      "2021-12-14 08:23:05 | INFO | fairseq.data.data_utils | loaded 197297 examples from: /storage/master-thesis/models/caps_quy-es+es-en/tokenizers/quy-es-en/bin/train.es-en.en\n",
      "2021-12-14 08:23:05 | INFO | fairseq.data.multilingual.multilingual_data_manager | /storage/master-thesis/models/caps_quy-es+es-en/tokenizers/quy-es-en/bin train es-en 197297 examples\n",
      "2021-12-14 08:23:05 | INFO | fairseq.data.multilingual.multilingual_data_manager | estimated total data sizes of all shards used in sampling ratios: [('main:quy-es', 125008), ('main:es-en', 197297)]. Note that if the data a shard has not been loaded yet, use the max known data size to approximate\n",
      "2021-12-14 08:23:05 | INFO | fairseq.data.multilingual.sampling_method | selected sampler: concat\n",
      "2021-12-14 08:23:05 | WARNING | fairseq.data.multilingual.sampled_multi_epoch_dataset | virtual epoch size 1000000 is greater than virtual dataset size 322305\n",
      "2021-12-14 08:23:05 | INFO | fairseq.data.multilingual.sampled_multi_epoch_dataset | virtual epoch size 322305; virtual dataset size 322305\n",
      "2021-12-14 08:23:05 | INFO | fairseq.data.multilingual.sampled_multi_epoch_dataset | establishing a new set of global virtual indices for epoch=201/shard_epoch=1\n",
      "2021-12-14 08:23:05 | INFO | fairseq.data.multilingual.sampled_multi_dataset | [train] Raw sizes: {'main:quy-es': 125008, 'main:es-en': 197297}; raw total size: 322305\n",
      "2021-12-14 08:23:05 | INFO | fairseq.data.multilingual.sampled_multi_dataset | [train] Resampled sizes: {'main:quy-es': 125008, 'main:es-en': 197297}; resampled total size: 322305\n",
      "2021-12-14 08:23:05 | INFO | fairseq.data.multilingual.sampled_multi_dataset | [train] A concat dataset\n",
      "2021-12-14 08:23:05 | INFO | fairseq.data.multilingual.sampled_multi_dataset | [train] virtual dataset established time: 0:00:00.033539\n",
      "2021-12-14 08:23:05 | INFO | fairseq.tasks.translation_multi_simple_epoch | start batch sampler: mem usage: N/A\n",
      "2021-12-14 08:23:05 | INFO | fairseq.data.multilingual.sampled_multi_dataset | sizes() calling time: 0:00:00.004322\n",
      "2021-12-14 08:23:05 | INFO | fairseq.tasks.translation_multi_simple_epoch | [train] @batch_sampler order indices time: 0:00:00.098370\n",
      "2021-12-14 08:23:05 | INFO | fairseq.tasks.translation_multi_simple_epoch | mem usage: N/A\n",
      "2021-12-14 08:23:05 | WARNING | fairseq.tasks.fairseq_task | 1 samples have invalid sizes and will be skipped, max_positions=(1024, 1024), first few sample ids=[68283]\n",
      "2021-12-14 08:23:05 | INFO | fairseq.tasks.translation_multi_simple_epoch | [train] @batch_sampler filter_by_size time: 0:00:00.007477\n",
      "2021-12-14 08:23:05 | INFO | fairseq.tasks.translation_multi_simple_epoch | mem usage: N/A\n",
      "2021-12-14 08:23:06 | INFO | fairseq.tasks.translation_multi_simple_epoch | [train] @batch_sampler batch_by_size time: 0:00:00.966111\n",
      "2021-12-14 08:23:06 | INFO | fairseq.tasks.translation_multi_simple_epoch | [train] per epoch batch_sampler set-up time: 0:00:01.072937\n",
      "2021-12-14 08:23:06 | INFO | fairseq.tasks.translation_multi_simple_epoch | mem usage: N/A\n",
      "2021-12-14 08:23:06 | INFO | fairseq.tasks.translation_multi_simple_epoch | start batch sampler: mem usage: N/A\n",
      "2021-12-14 08:23:06 | INFO | fairseq.tasks.translation_multi_simple_epoch | [train] @batch_sampler order indices time: 0:00:00.081527\n",
      "2021-12-14 08:23:06 | INFO | fairseq.tasks.translation_multi_simple_epoch | mem usage: N/A\n",
      "2021-12-14 08:23:06 | WARNING | fairseq.tasks.fairseq_task | 1 samples have invalid sizes and will be skipped, max_positions=(1024, 1024), first few sample ids=[68283]\n",
      "2021-12-14 08:23:06 | INFO | fairseq.tasks.translation_multi_simple_epoch | [train] @batch_sampler filter_by_size time: 0:00:00.007337\n",
      "2021-12-14 08:23:06 | INFO | fairseq.tasks.translation_multi_simple_epoch | mem usage: N/A\n",
      "2021-12-14 08:23:07 | INFO | fairseq.tasks.translation_multi_simple_epoch | [train] @batch_sampler batch_by_size time: 0:00:00.978179\n",
      "2021-12-14 08:23:07 | INFO | fairseq.tasks.translation_multi_simple_epoch | [train] per epoch batch_sampler set-up time: 0:00:01.067977\n",
      "2021-12-14 08:23:07 | INFO | fairseq.tasks.translation_multi_simple_epoch | mem usage: N/A\n",
      "epoch 201:   0%|                                       | 0/1290 [00:00<?, ?it/s]2021-12-14 08:23:07 | INFO | fairseq.trainer | begin training epoch 201\n",
      "epoch 201:  14%|1| 176/1290 [01:33<09:44,  1.91it/s, loss=2.78, nll_loss=0.942, ^C\n"
     ]
    }
   ],
   "source": [
    "! fairseq-train $BIN_DIR \\\n",
    "    --user-dir $CODE_STORAGE/fairseq-dynamic-routing-plugin/examples/dynamic_routing/dynamic_routing_src/ \\\n",
    "    --arch=capsnet_transformer --share-all-embeddings \\\n",
    "    --task translation_multi_simple_epoch --lang-pairs quy-es,es-en \\\n",
    "    --optimizer adam --adam-betas '(0.9, 0.98)' --clip-norm 0.0 \\\n",
    "    --lr 5e-4 --lr-scheduler inverse_sqrt --warmup-updates 4000 \\\n",
    "    --dropout 0.3 --weight-decay 0.0001 \\\n",
    "    --criterion label_smoothed_cross_entropy --label-smoothing 0.1 \\\n",
    "    --max-tokens 4096 \\\n",
    "    --restore-file $MODEL_DIR/checkpoint_last.pt \\\n",
    "    --save-dir $MODEL_DIR/ \\\n",
    "    --keep-last-epochs 2 \\\n",
    "    --reset-optimizer \\\n",
    "    --encoder-langtok \"src\" \\\n",
    "    --decoder-langtok #\\\n",
    "    #--fp16\n",
    "    #--update-freq 64\n",
    "    \n",
    "    #--fp16-scale-tolerance=0.25\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "gradient": {}
   },
   "outputs": [],
   "source": [
    "cp *.pt /notebooks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[0m\u001b[01;34mapex\u001b[0m/         den.pt    \u001b[01;34mfairseq-dynamic-routing-plugin\u001b[0m/  num.pt  vj.pt\n",
      "\u001b[01;34mcheckpoints\u001b[0m/  \u001b[01;34mfairseq\u001b[0m/  norm.pt                          sj.pt\n"
     ]
    }
   ],
   "source": [
    "ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "gradient": {}
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/storage/master-thesis/models/quy-es+es-en\n"
     ]
    }
   ],
   "source": [
    "cd /storage/master-thesis/models/quy-es+es-en"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "gradient": {}
   },
   "outputs": [],
   "source": [
    "! rm checkpoint108.pt\n",
    "! rm checkpoint109.pt\n",
    "! rm checkpoint_best.pt\n",
    "! rm checkpoint_last.pt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "gradient": {}
   },
   "outputs": [],
   "source": [
    "! rm dict.en.txt\n",
    "! rm dict.es.txt\n",
    "! rm dict.quy.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "gradient": {}
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.5K\t/notebooks/CITATION.cff\n",
      "5.5K\t/notebooks/CODE_OF_CONDUCT.md\n",
      "15K\t/notebooks/CONTRIBUTING.md\n",
      "19K\t/notebooks/ISSUES.md\n",
      "12K\t/notebooks/LICENSE\n",
      "512\t/notebooks/MANIFEST.in\n",
      "3.5K\t/notebooks/Makefile\n",
      "41K\t/notebooks/README.md\n",
      "41K\t/notebooks/README_zh-hans.md\n",
      "42K\t/notebooks/README_zh-hant.md\n",
      "12K\t/notebooks/docker\n",
      "4.6M\t/notebooks/docs\n",
      "5.0M\t/notebooks/examples\n",
      "8.5K\t/notebooks/hubconf.py\n",
      "7.8G\t/notebooks/master-thesis\n",
      "1.5K\t/notebooks/model_cards\n",
      "9.5K\t/notebooks/notebooks\n",
      "512\t/notebooks/pyproject.toml\n",
      "64K\t/notebooks/scripts\n",
      "1.0K\t/notebooks/setup.cfg\n",
      "13K\t/notebooks/setup.py\n",
      "13M\t/notebooks/src\n",
      "731K\t/notebooks/templates\n",
      "4.5K\t/notebooks/test quy-es -> es-en model.ipynb\n",
      "6.8M\t/notebooks/tests\n",
      "147K\t/notebooks/train es-en model.ipynb\n",
      "158K\t/notebooks/train quy-es + es-en model.ipynb\n",
      "160K\t/notebooks/utils\n",
      "3.5K\t/notebooks/valohai.yaml\n",
      "7.9G\ttotal\n"
     ]
    }
   ],
   "source": [
    "! du -shc /notebooks/*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "gradient": {}
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "512\t/notebooks/master-thesis/Untitled.ipynb\n",
      "362M\t/notebooks/master-thesis/corpora\n",
      "7.5G\t/notebooks/master-thesis/models\n",
      "7.8G\ttotal\n"
     ]
    }
   ],
   "source": [
    "! du -shc /notebooks/master-thesis/*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "gradient": {}
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.6G\t/notebooks/master-thesis/models/es-en\n",
      "802M\t/notebooks/master-thesis/models/quy-es\n",
      "5.2G\t/notebooks/master-thesis/models/quy-es+es-en\n",
      "7.5G\ttotal\n"
     ]
    }
   ],
   "source": [
    "! du -shc /notebooks/master-thesis/models/*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "gradient": {}
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19M\t/apex\n",
      "5.0M\t/bin\n",
      "4.0K\t/boot\n",
      "24K\t/content\n",
      "^C\n"
     ]
    }
   ],
   "source": [
    "! du -shc /*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "gradient": {}
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " CITATION.cff         \u001b[0m\u001b[01;34mdocker\u001b[0m/          setup.py\n",
      " CODE_OF_CONDUCT.md   \u001b[01;34mdocs\u001b[0m/            \u001b[01;34msrc\u001b[0m/\n",
      " CONTRIBUTING.md      \u001b[01;34mexamples\u001b[0m/        \u001b[01;34mtemplates\u001b[0m/\n",
      " ISSUES.md            hubconf.py      'test quy-es -> es-en model.ipynb'\n",
      " LICENSE              \u001b[01;34mmaster-thesis\u001b[0m/   \u001b[01;34mtests\u001b[0m/\n",
      " MANIFEST.in          \u001b[01;34mmodel_cards\u001b[0m/    'train es-en model.ipynb'\n",
      " Makefile             \u001b[01;34mnotebooks\u001b[0m/      'train quy-es + es-en model.ipynb'\n",
      " README.md            pyproject.toml   \u001b[01;34mutils\u001b[0m/\n",
      " README_zh-hans.md    \u001b[01;34mscripts\u001b[0m/         valohai.yaml\n",
      " README_zh-hant.md    setup.cfg\n"
     ]
    }
   ],
   "source": [
    "ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "gradient": {}
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "gradient": {}
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "gradient": {}
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "gradient": {}
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "gradient": {}
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/storage/master-thesis\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "gradient": {}
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
